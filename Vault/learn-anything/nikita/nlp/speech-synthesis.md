# Speech synthesis

[TorToiSe](https://github.com/neonbjb/tortoise-tts) & [15.ai](https://15.ai/) are nice.

## Links

- [Deepvoice3 PyTorch](https://github.com/r9y9/deepvoice3_pytorch) - PyTorch implementation of convolutional neural networks-based text-to-speech synthesis models.
- [WaveNet vocoder](https://github.com/r9y9/wavenet_vocoder) - Can generate high quality raw speech samples conditioned on linguistic or acoustic features.
- [Papercup](https://www.papercup.com/) - Translate your content into other languages with a voice that sounds like yours.
- [WaveNet implementation in Keras](https://github.com/basveeling/wavenet)
- [nv-wavenet](https://github.com/NVIDIA/nv-wavenet) - CUDA reference implementation of autoregressive WaveNet inference.
- [PyTorch implementation of Tacotron speech synthesis model](https://github.com/r9y9/tacotron_pytorch)
- [Yet another WaveNet implementation in PyTorch](https://github.com/golbin/WaveNet)
- [Flowtron](https://github.com/NVIDIA/flowtron) - Auto-regressive flow-based generative network for text to speech synthesis.
- [A highly efficient, real-time text-to-speech system deployed on CPUs (2020)](https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/) ([HN](https://news.ycombinator.com/item?id=23193967))
- [Sonatic](https://www.sonantic.io/) - Emotionally Expressive Text to Speech.
- [GAN-based Mel-Spectrogram Inversion Network for Text-to-Speech Synthesis](https://github.com/descriptinc/melgan-neurips)
- [Ask HN: My wife might lose the ability to speak in 3 weeks â€“ how to prepare? (2020)](https://news.ycombinator.com/item?id=23490115)
- [DiffWave](https://github.com/lmnt-com/diffwave) - Fast, high-quality neural vocoder and waveform synthesizer.
- [Voice Conversion with Non-Parallel Data](https://github.com/andabi/deep-voice-conversion)
- [Speech Synthesis Papers](https://github.com/xcmyz/speech-synthesis-paper)
- [VoiceFilter](https://github.com/mindslab-ai/voicefilter) - Unofficial PyTorch implementation of Google AI's VoiceFilter system. ([Web](http://swpark.me/voicefilter/))
- [ForwardTacotron](https://github.com/as-ideas/ForwardTacotron) - Generating speech in a single forward pass without any attention. ([Web](https://as-ideas.github.io/ForwardTacotron/))
- [HiFi-GAN](https://github.com/jik876/hifi-gan) - Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.
- [Parakeet](https://github.com/PaddlePaddle/Parakeet) - Text-to-speech toolKIT (supporting WaveFlow, ClariNet, WaveNet, Deep Voice 3, Transformer TTS and FastSpeech).
- [pyttsx3](https://github.com/nateshmbhat/pyttsx3) - Offline Text To Speech synthesis for python.
- [SOVA TTS](https://github.com/sovaai/sova-tts) - Speech syntthesis solution based on Tacotron 2 architecture.
- [eSpeak NG](https://github.com/espeak-ng/espeak-ng) - Open source speech synthesizer that supports more than hundred languages and accents.
- [PRiSM SampleRNN](https://github.com/rncm-prism/prism-samplernn) - Neural sound synthesis with TensorFlow 2.
- [Flite](https://github.com/festvox/flite) - Small fast portable speech synthesis system.
- [FastSpeech 2: Fast and High-Quality End-to-End Text to Speech (2020)](https://arxiv.org/abs/2006.04558) ([Code](https://github.com/rishikksh20/FastSpeech2)) ([Code](https://github.com/AppleHolic/FastSpeech2))
- [Neural Granular Sound Synthesis](https://adrienchaton.github.io/neural_granular_synthesis/) ([Code](https://github.com/adrienchaton/neural_granular_synthesis))
- [CLEESE](https://github.com/creamlab/cleese) - Combinatorial Expressive Speech Engine.
- [LVCNet: Efficient Condition-Dependent Modeling Network for Waveform Generation](https://github.com/ZENGZHEN-TTS/LVCNet)
- [LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search (2021)](https://arxiv.org/abs/2102.04040) ([Code](https://github.com/rishikksh20/LightSpeech))
- [A Survey on Neural Speech Synthesis (2021)](https://arxiv.org/abs/2106.15561) ([Code](https://github.com/tts-tutorial/survey))
- [Binaural Speech Synthesis](https://github.com/facebookresearch/BinauralSpeechSynthesis) - Code to train a mono-to-binaural neural sound renderer.
- [NN-SVS](https://github.com/r9y9/nnsvs) - Neural network-based singing voice synthesis library for research.
- [Larynx](https://github.com/rhasspy/larynx) - End to end text to speech system using gruut and onnx, 50 voices, 9 languages.
- [WellSaid Labs](https://wellsaidlabs.com/) - Voice Narration. Simplified.
- [Neural Wave shaping Synthesis](https://github.com/ben-hayes/neural-waveshaping-synthesis) - Efficient neural audio synthesis in the waveform domain. ([Article](https://benhayes.net/projects/nws/))
- [Catch-A-Waveform: Learning to Generate Audio from a Single Short Example](https://galgreshler.github.io/Catch-A-Waveform/) ([Code](https://github.com/galgreshler/Catch-A-Waveform))
- [TFGAN: Time and Frequency Domain Based Generative Adversarial Network for High-fidelity Speech Synthesis (2020)](https://arxiv.org/abs/2011.12206) ([Code](https://github.com/rishikksh20/TFGAN))
- [EdiTTS: Score-based Editing for Controllable Text-to-Speech](https://github.com/neosapience/EdiTTS)
- [PortaSpeech: Portable and High-Quality Generative Text-to-Speech (2021)](https://arxiv.org/abs/2109.15166) ([Code](https://github.com/keonlee9420/PortaSpeech))
- [Speech Resynthesis from Discrete Disentangled Self-Supervised Representations (2021)](https://arxiv.org/abs/2104.00355) ([Code](https://github.com/facebookresearch/speech-resynthesis))
- [Neural Lexicon Reader: Reduce Pronunciation Errors in End-to-end TTS by Leveraging External Textual Knowledge (2021)](https://arxiv.org/abs/2110.09698) ([Code](https://github.com/mutiann/neural-lexicon-reader))
- [Grail-rs](https://github.com/Dimev/grail-rs) - Rust speech synth.
- [RAVE: A variational autoencoder for fast and high-quality neural audio synthesis (2021)](https://arxiv.org/abs/2111.05011) ([Code](https://github.com/caillonantoine/RAVE))
- [WaveFlow: A Compact Flow-based Model for Raw Audio (2020)](https://arxiv.org/abs/1912.01219) ([Code](https://github.com/L0SG/WaveFlow))
- [VoiceFixer](https://github.com/haoheliu/voicefixer_main) - Framework for general speech restoration.
- [TTS-RS](https://github.com/ndarilek/tts-rs) - High-level Text-To-Speech (TTS) interface supporting various backends.
- [Speech synthesis using AVSpeechSynthesizer (2021)](https://cornerbit.tech/speech-synthesis-using-avspeechsynthesizer/)
- [Towards Lightweight Controllable Audio Synthesis with Conditional Implicit Neural Representations (2021)](https://arxiv.org/abs/2111.08462) ([Code](https://github.com/janzuiderveld/continuous-audio-representations))
- [TTS](https://github.com/coqui-ai/TTS) - Library for advanced Text-to-Speech generation. ([Web](https://coqui.ai/)) ([HN](https://news.ycombinator.com/item?id=29786132))
- [YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone](https://github.com/Edresson/YourTTS)
- [SubSync](https://github.com/sc0ty/subsync) - Subtitle Speech Synchronizer. ([Overview](http://sc0ty.pl/2019/04/subsync-synchronize-movie-subtitles-with-audio-track/)) ([HN](https://news.ycombinator.com/item?id=29794153))
- [Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation (2021)](https://arxiv.org/abs/2106.03153) ([Code](https://github.com/keonlee9420/StyleSpeech))
- [NATSpeech](https://github.com/NATSpeech/NATSpeech) - Non-Autoregressive Text-to-Speech Framework.
- [VocBench: A Neural Vocoder Benchmark for Speech Synthesis (2021)](https://arxiv.org/abs/2112.03099) ([Code](https://github.com/facebookresearch/vocoder-benchmark))
- [TransformerTTS](https://github.com/as-ideas/TransformerTTS) - Text-to-Speech Transformer in TensorFlow 2.
- [Awesome Speech Recognition Speech Synthesis Papers](https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers)
- [Neural Instrument Cloning from very few samples (2022)](https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6) ([Code](https://github.com/erl-j/neural-instrument-cloning))
- [MLP Singer: Towards Rapid Parallel Korean Singing Voice Synthesis (2021)](https://arxiv.org/abs/2106.07886) ([Code](https://github.com/neosapience/mlp-singer))
- [IMS Toucan](https://github.com/DigitalPhonetics/IMS-Toucan) - Toolkit to train state-of-the-art Speech Synthesis models.
- [BDDM: Bilateral Denoising Diffusion Models for Fast and High-quality Speech Synthesis (2022)](https://github.com/tencent-ailab/bddm)
- [Deep Learning for Emotional Text-to-speech](https://github.com/Emotional-Text-to-Speech/dl-for-emo-tts) - Summary on our attempts at using Deep Learning approaches for Emotional Text to Speech.
- [Nix-TTS](https://github.com/rendchevi/nix-tts) - Incredibly Lightweight End-to-End Text-to-Speech Model via Non End-to-End Distillation.
- [xVA Synth](https://github.com/DanRuta/xVA-Synth) - Machine learning based speech synthesis Electron app, with voices from specific characters from video games.
- [Bandwidth Extension is All You Need (2021)](https://ieeexplore.ieee.org/document/9413575) ([Code](https://github.com/brentspell/hifi-gan-bwe))
- [TorToiSe](https://github.com/neonbjb/tortoise-tts) - Multi-voice TTS system trained with an emphasis on quality. ([Demos](https://nonint.com/static/tortoise_v2_examples.html))
- [Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech (2020)](https://arxiv.org/abs/2005.05106) ([Code](https://github.com/AppleHolic/multiband_melgan))
- [UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation (2021)](https://arxiv.org/abs/2106.07889) ([Code](https://github.com/mindslab-ai/univnet))
- [TikTok TTS](https://weilbyte.github.io/tiktok-tts/) - Generate the funny TiKTok lady voice (& more) in your browser. ([Code](https://github.com/Weilbyte/tiktok-tts))
- [TikTok Text-to-speech API](https://github.com/oscie57/tiktok-voice) - Simple Python script to interact with the TikTok TTS API.
- [Unreal Speech](https://unrealspeech.com/) - Text-to-Speech API. Better & 8x Cheaper than AWS.
- [15.ai](https://15.ai/) - Natural TTS with minimal viable data. ([HN](https://news.ycombinator.com/item?id=31711118))
- [JDC-PitchExtractor](https://github.com/yl4579/PitchExtractor) - Deep Neural Pitch Extractor for Voice Conversion and TTS Training.
- [Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech (2021)](https://arxiv.org/abs/2105.06337) ([Code](https://github.com/WelkinYang/GradTTS))
- [Publicly Available Emotional Speech Dataset (ESD) for Speech Synthesis and Voice Conversion](https://github.com/HLTSingapore/Emotional-Speech-Data)
- [Mimic 3](https://github.com/MycroftAI/mimic3) - Fast local neural text to speech engine for Mycroft. ([Intro](https://mycroft.ai/blog/introducing-mimic-3/)) ([HN](https://news.ycombinator.com/item?id=31926813))
- [DiffWave: A Versatile Diffusion Model for Audio Synthesis (2021)](https://arxiv.org/abs/2009.09761) ([Code](https://github.com/albertfgu/diffwave-sashimi))
- [FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis](https://github.com/Rongjiehuang/FastDiff)
- [HiFi-GAN](https://github.com/bshall/hifigan) - Training and inference scripts for the vocoder models in A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion.
- [Acoustic-Model](https://github.com/bshall/acoustic-model) - Training and inference scripts for the acoustic models in A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion.
- [HuBERT](https://github.com/bshall/hubert) - Training and inference scripts for the HuBERT content encoders in A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion.
- [Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech (2021)](https://arxiv.org/abs/2106.06103) ([Code](https://github.com/jaywalnut310/vits))
- [Diffsound: Discrete Diffusion Model for Text-to-sound Generation](http://dongchaoyang.top/text-to-sound-synthesis-demo/) ([Code](https://github.com/yangdongchao/Text-to-sound-Synthesis))
- [DDSP-based Singing Vocoders: A New Subtractive-based Synthesizer and A Comprehensive Evaluation (2022)](https://ddspvocoder.github.io/ismir-demo/) ([Code](https://github.com/YatingMusic/ddsp-singing-vocoders))
- [ProDiff: Progressive Fast Diffusion Model For High-Quality Text-to-Speech](https://github.com/Rongjiehuang/ProDiff)
- [AudioLM: Language Modeling Approach to Audio Generation](https://google-research.github.io/seanet/audiolm/examples/) ([Code](https://github.com/lucidrains/audiolm-pytorch))
- [Awesome Singing Voice Synthesis and Singing Voice Conversion](https://github.com/guan-yuan/Awesome-Singing-Voice-Synthesis-and-Singing-Voice-Conversion)
- [LPCNet](https://github.com/xiph/LPCNet) - Efficient neural speech synthesis.
- [AudioGen: Textually Guided Audio Generation](https://felixkreuk.github.io/text2audio_arxiv_samples/) ([HN](https://news.ycombinator.com/item?id=33039203))
- [Ask HN: Best free text-to-speech plugins for browsers? (2022)](https://news.ycombinator.com/item?id=33163751)
- [Neural Speech Synthesis Tutorial (2022)](https://github.com/tts-tutorial/interspeech2022)
- [PhaseAug: Differentiable Augmentation for Speech Synthesis to Simulate One-to-Many Mapping (2022)](https://github.com/mindslab-ai/phaseaug)
- [VIC-20 text-to-speech synthesizer using the iconic voice of SAM (2021)](https://www.youtube.com/watch?v=_YioAfmzkQc) ([Article](https://janderogee.com/projects/SerialSpeechSynthesisSAM/SerialSpeechSynthesisSAM.htm))
- [PyTorch implementation of the Perceptual Evaluation of Speech Quality](https://github.com/audiolabs/torch-pesq)
- [Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform (2022)](https://github.com/MasayaKawamura/MB-iSTFT-VITS)
- [GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech (2022)](https://arxiv.org/abs/2205.07211) ([Code](https://github.com/Rongjiehuang/GenerSpeech))
- [AERO](https://github.com/m-mandel/aero) - Audio Super Resolution in the Spectral Domain.
- [Enhance Speech from Adobe](https://podcast.adobe.com/enhance) - Free AI filter for cleaning up spoken audio. ([HN](https://news.ycombinator.com/item?id=34047976))
- [Incorporating AutoVocoder to MB-iSTFT-VITS](https://github.com/hcy71o/MB-iSTFT-VITS-with-AutoVocoder)
- [Automatic Prosody Annotation with Pre-Trained Text-Speech Model](https://github.com/Daisyqk/Automatic-Prosody-Annotation)
- [Ask HN: Are there any good open source text-to-speech tools? (2023)](https://news.ycombinator.com/item?id=34211457)
- [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers (2023)](https://arxiv.org/abs/2301.02111) ([Web](https://valle-demo.github.io/)) ([HN](https://news.ycombinator.com/item?id=34270311)) ([HN](https://news.ycombinator.com/item?id=34309306)) ([Code](https://github.com/enhuiz/vall-e)) ([Code](https://github.com/lifeiteng/vall-e))
- [This Voice Doesn't Exist â€“ Generative Voice AI (2023)](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/) ([HN](https://news.ycombinator.com/item?id=34361651))
- [Autotone](https://github.com/alexcrist/autotone) - Vocal pitch correction web application, like Autotune. ([HN](https://news.ycombinator.com/item?id=34396303))
- [Voice Cloning Model with Zero-Shot Attention-Based TTS](https://github.com/MartinMashalov/VoiceCloning)
- [ElevenLabs | Speech Synthesis](https://beta.elevenlabs.io/speech-synthesis)
- [Praat](https://github.com/praat/praat) - Speech analysis tool used for doing phonetics by computer. ([Web](https://www.fon.hum.uva.nl/praat/))
- [Audio AI Timeline](https://github.com/archinetai/audio-ai-timeline) - Timeline of the latest AI models for audio generation.
- [AudioLDM](https://github.com/haoheliu/AudioLDM) - Text-to-Audio Generation with Latent Diffusion Models.
- [Speaking Style Conversion With Discrete Self-Supervised Units (2022)](https://arxiv.org/abs/2212.09730) ([Code](https://github.com/gallilmaimon/DISSC))
- [StoRM: A Diffusion-based Stochastic Regeneration Model for Speech Enhancement and Dereverberation (2022)](https://arxiv.org/abs/2212.11851) ([Code](https://github.com/sp-uhh/storm))
- [TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement (2023)](https://arxiv.org/abs/2302.08088) ([Code](https://github.com/YunyangZeng/TAPLoss))
- [StyleTTS-VC: One-Shot Voice Conversion by Knowledge Transfer from Style-Based TTS Models (2022)](https://arxiv.org/abs/2212.14227) ([Code](https://github.com/yl4579/StyleTTS-VC))
- [PITS: Variational Pitch Inference without Fundamental Frequency for End-to-End Pitch-controllable TTS](https://github.com/anonymous-pits/pits)
- [Improving Few-shot Learning for Talking Face System with TTS Data Augmentation (2023)](https://github.com/Moon0316/T2A)
- [Conditioning and Sampling in Variational Diffusion Models for Speech Super-Resolution (2022)](https://yoyololicon.github.io/diffwave-sr/) ([Code](https://github.com/yoyololicon/diffwave-sr))
- [Play.ht](https://play.ht/) - Generate and clone voices from 20 seconds of audio. ([HN](https://news.ycombinator.com/item?id=35328698))
- [NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates](https://github.com/mindslab-ai/nuwave2)
- [Bark](https://github.com/suno-ai/bark) - Text-prompted Generative Audio Model. ([HN](https://news.ycombinator.com/item?id=35643219))
- [piper](https://github.com/rhasspy/piper) - Fast, local neural text to speech system.
- [SoftVC VITS Singing Voice Conversion Fork](https://github.com/voicepaw/so-vits-svc-fork)
- [Kesha](https://github.com/Priler/jarvis) - Voice Assistant made as an experiment using Silero TTS + Vosk STT + Picovoice Porcupine + ChatGPT.
- [Bark...but with the ability to use voice cloning on custom audio/text pairs](https://github.com/serp-ai/bark-with-voice-clone)
- [SNAC: Speaker-normalized Affine Coupling Layer in Flow-based Architecture for Zero-Shot Multi-Speaker Text-to-Speech](https://github.com/hcy71o/SNAC)
- [SoundStorm: Efficient Parallel Audio Generation](https://github.com/rishikksh20/SoundStorm-pytorch)
- [DeepFilterNet](https://github.com/Rikorose/DeepFilterNet) - Low Complexity Speech Enhancement Framework for Full-Band Audio (48kHz) using on Deep Filtering.
- [Voicebox: Generative AI model for speech that generalizes across tasks (2023)](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/) ([HN](https://news.ycombinator.com/item?id=36393262))
- [Build a conversational engine so we can talk to our computers](https://github.com/yacineMTB/talk)
