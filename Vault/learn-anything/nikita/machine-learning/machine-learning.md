# Machine learning

[Phil Wang](https://github.com/lucidrains) always recreates many cutting edge ML papers with PyTorch. [This course](https://book.sciml.ai/) & [Math for ML](https://mml-book.github.io/) seem great. [Hugging Face](https://huggingface.co/) is incredible community & [tools](https://twitter.com/abhi1thakur/status/1533416501792935938). [Transformer architectures](https://twitter.com/michael_nielsen/status/1511853865150287873) & [Diffusion Models](https://www.youtube.com/watch?v=fbLgFrlTnGU) are great. [MLU-Explain](https://mlu-explain.github.io/) is a [great ML visual explainer](https://news.ycombinator.com/item?id=31455919).

Looking into using [envd](https://github.com/tensorchord/envd) together with [PyTorch Lightning](https://www.pytorchlightning.ai/) for my ML experiments.

[Lilian's Blog](https://lilianweng.github.io/), [ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained) & [Understanding Deep Learning](https://udlbook.github.io/udlbook/) are great reads.

[Practical Deep Learning for Coders](https://course.fast.ai/) is nice intro course. [Andrej Karpathy](https://github.com/karpathy) does great open research on ML.

[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) & [Transformer Recipes](https://github.com/dair-ai/Transformers-Recipe) are great reads.

[XLA](https://github.com/openxla/xla) is interesting ML compiler.

## Notes

- A big part of the utility of math (especially in ML) is having breadth rather than depth. The strategy of picking out specific things you don't know from papers and looking them up is only effective if you have the breadth in your background to understand the answers you find.
  - Broad knowledge is also what helps you manage the exponential tree of complexity you're encountering.
    - You won't have seen all the things you come across, but you'll develop the ability to make good judgements about what you need to read to achieve your goals. You'll learn how to recognize when a reference you're reading is more (or less) technical than you need, and how to search for something more appropriate. You'll also learn how and when you can use results without understanding the details.
  - Finally, as a general grad student strategy trying to learn everything just in time is not a path to success. Even if you had the perfect math oracle that you want it would be setting you up to be left behind. All the oracle gives you is the ability to catch up quickly to the ideas of others. Your job as a grad student is to generate new knowledge and to do that you need to seek things out on your own, not just follow along the latest trend. Part of your job is to go out hunting for ideas that your peers haven't found yet and bring them back to your field.
- [In supervised learning, you have a bunch of data, a specific question you want to answer, and access to the correct answer to many instances of that question. In unsupervised learning, you have a bunch of data points, and you want to find meaningful patterns in the structure of that data. In reinforcement learning, you have a task you want to take actions to accomplish, and you don't have any access to knowing what the best action is, but after each action you get a rough idea of how good the result was.](https://www.reddit.com/r/MachineLearning/comments/7780ok/r_alphago_zero_learning_from_scratch_deepmind/dol3knx/ "permalink")
- AI doesn't need to follow the human model, just like planes don't need to flap their wings like a bird. For most jobs AI will be very different from humans. Even when AI acts as human for entertainment I would imagine them being very different internally, as their job is to mimic aspects of human behaviors, not actually a human as a whole.
- Almost all of machine learning is about representing data as vectors and performing linear and non-linear transformations in order to perform classification, regression, etc.
- Most of ML is fitting models to data. To fit a model you minimize some error measure as a function of its real valued parameters, e.g. the weights of the connections in a neural network. The algorithms to do the minimization are based on gradient descent, which depends on derivatives, i.e. differential calculus.
- [Learn optimization before studying machine learning if you really want to understand what's going on.](https://twitter.com/Adam235711/status/1391067131169574914)
- [What idiot called it "machine learning" instead of "bias automation".](https://twitter.com/fasterthanlime/status/868840530813353985)
- [If you were to learn only 1 method for explaining machine learning models, it should be Shapley values (SHAP): 1. Model-agnostic: Use with any model. 2. Theoretic foundation: Game theory. 3. Good software ecosystem. 4. Local and global explanations.](https://twitter.com/ChristophMolnar/status/1486635139190992896)
- [What idiot called it "machine learning" instead of "bias automation".](https://twitter.com/fasterthanlime/status/1397352603508518912)

## Links

- [Neural Networks and Deep Learning book](http://neuralnetworksanddeeplearning.com/)
- [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
- [Ask HN: Best way to get started with AI?](https://news.ycombinator.com/item?id=15689399)
- [Ask HN: What maths are critical to pursuing ML/AI?](https://news.ycombinator.com/item?id=15116379)
- [Ask HN: 'Crash Courses' for Mathematics Related to DL, ML and Data Analysis](https://news.ycombinator.com/item?id=16508873)
- [Computational Statistics and Machine Learning Revision Notes](https://github.com/acbraith/CSML_notes)
- [Stanford CS229 course](https://github.com/econti/cs229)
- [Readings in applied data science](https://github.com/hadley/stats337)
- [Learn ML in 3 months](https://github.com/llSourcell/Learn_Machine_Learning_in_3_Months)
- [Deep Learn](https://github.com/GauravBh1010tt/DeepLearn) - Implementation of research papers on Deep Learning+ NLP+ CV in Python using Keras, TensorFlow and Scikit Learn.
- [Building Brundage Bot](https://hackernoon.com/building-brundage-bot-10252facf3d1)
- [Summaries of ML papers](https://github.com/aleju/papers)
- [Code and data for paper "Deep Painterly Harmonization"](https://github.com/luanfujun/deep-painterly-harmonization)
- [FB AI Tools](https://facebook.ai/developers/tools)
- [Best Practices for ML Engineering](https://developers.google.com/machine-learning/rules-of-ml/)
- [Machine Learning From Scratch](https://github.com/eriklindernoren/ML-From-Scratch)
- [Dive Into ML](http://hangtwenty.github.io/dive-into-machine-learning/)
- [Fermat's Library NIPS comments](http://fermatslibrary.com/nips)
- [Heroes of Deep Learning: Andrew Ng interviews Ian Goodfellow](https://www.youtube.com/watch?v=pWAc9B2zJS4)
- [Machine Learning for Humans](https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12) - Great article.
- [Deep Learning for Siri’s Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis](https://machinelearning.apple.com/2017/08/06/siri-voices.html)
- [The Google Brain Team — Looking Back on 2017](https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html?m=1)
- [Building the Software 2.0 Stack by Andrej Karpathy from Tesla (2018)](https://www.figure-eight.com/building-the-software-2-0-stack-by-andrej-karpathy-from-tesla/)
- [Deep Learning World](https://github.com/astorfi/Deep-Learning-World)
- [Machine Learning cheatsheets for Stanford's CS 229](https://github.com/afshinea/stanford-cs-229-machine-learning)
- [RAAIS 2018 - François Chollet (Creator of Keras)](https://www.youtube.com/watch?v=2L2u303FAs8)
- [KubeFlow](https://github.com/kubeflow/kubeflow) - Machine Learning Toolkit for Kubernetes. ([Winding Road to Better Machine Learning Infrastructure Through Tensorflow Extended and Kubeflow](https://engineering.atspotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/))
- [KALE (Kubeflow Automated pipeLines Engine)](https://github.com/kubeflow-kale/kale) - Aims at simplifying the Data Science experience of deploying Kubeflow Pipelines workflows.
- [MIT AGI: Deep Learning (Yoshua Bengio) (2018)](https://www.youtube.com/watch?v=azOmzumh0vQ)
- [TL-GAN: transparent latent-space GAN](https://github.com/SummitKwan/transparent_latent_gan) - Use supervised learning to illuminate the latent space of GAN for controlled generation and edit.
- [Grokking Deep Learning](https://github.com/iamtrask/Grokking-Deep-Learning) - Repository accompanying "Grokking Deep Learning" book.
- [HN: Can we rule out near-term AGI? (2018)](https://news.ycombinator.com/item?id=18405025)
- [Introduction to Grenade (Haskell library for Deep Learning)](https://www.huwcampbell.com/posts/2017-02-17-introduction-to-grenade.html)
- [Grenade](https://github.com/HuwCampbell/grenade) - Deep Learning in Haskell.
- [Deep Learning 1: Introduction to Machine Learning Based AI](https://www.youtube.com/watch?v=iOh7QUZGyiU)
- [Deep Learning cheatsheets for Stanford's CS 230 (2018)](https://github.com/afshinea/stanford-cs-230-deep-learning)
- [Deep Learning Book Chapter Summaries](https://github.com/dalmia/Deep-Learning-Book-Chapter-Summaries) - Attempting to make the Deep Learning Book easier to understand.
- [PracticalAI](https://github.com/GokuMohandas/practicalAI) - Practical approach to learning machine learning.
- [Ask HN: How to incorporate machine learning into day job? (2018)](https://news.ycombinator.com/item?id=18650646)
- [RLgraph](https://github.com/rlgraph/rlgraph) - Flexible computation graphs for deep reinforcement learning.
- [Nevergrad](https://github.com/facebookresearch/nevergrad) - Gradient-free optimization platform.
- [Machine Learning Cheat Sheet](https://ml-cheatsheet.readthedocs.io/en/latest/)
- [GANs and Divergence Minimization (2018)](https://colinraffel.com/blog/gans-and-divergence-minimization.html)
- [Convolution arithmetic](https://github.com/vdumoulin/conv_arithmetic) - Technical report on convolution arithmetic in the context of deep learning.
- [FloydHub](https://www.floydhub.com/) - Managed cloud platform for data scientists.
- [Style Transfer as Optimal Transport](https://github.com/VinceMarron/style_transfer) - Algorithm that transfers the distribution of visual characteristics, or style, of a reference image onto a subject image via an Optimal Transport plan.
- [Looking Back at Google’s Research Efforts in 2018](https://ai.googleblog.com/2019/01/looking-back-at-googles-research.html)
- [Recommenders](https://github.com/Microsoft/Recommenders) - Examples and best practices for building recommendation systems, provided as Jupyter notebooks.
- [Deep Learning State of the Art (2019) - MIT](https://www.youtube.com/watch?v=53YvP6gdD7U)
- [AdaNet](https://github.com/tensorflow/adanet) - Lightweight TensorFlow-based framework for automatically learning high-quality models with minimal expert intervention.
- [DAWNBench](https://dawn.cs.stanford.edu/benchmark/) - Benchmark suite for end-to-end deep learning training and inference.
- [Interpretable Machine Learning (2022)](https://christophm.github.io/interpretable-ml-book/) - Guide for Making Black Box Models Explainable. ([Code](https://github.com/christophM/interpretable-ml-book)) ([2nd edition](https://leanpub.com/interpretable-machine-learning))
- [All You Need to Know About Deep Learning - A kick-starter (2019)](https://github.com/osforscience/deep-learning-ocean)
- [KubeFlow Pipelines](https://github.com/kubeflow/pipelines) - Machine learning (ML) toolkit that is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable.
- [Summary of some ML papers](https://github.com/kweonwooj/papers)
- [Practical Deep Learning for Coders 2019](https://www.fast.ai/2019/01/24/course-v3/) - ([HN](https://news.ycombinator.com/item?id=19000027)) ([GitHub](https://github.com/fastai/course-v3))
- [Notebooks for the "A walk with fastai2" Study Group and Lecture Series](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0)
- [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/index.html) ([HN](https://news.ycombinator.com/item?id=21661545)) ([HN 2](https://news.ycombinator.com/item?id=26676729)) ([Paper](https://arxiv.org/abs/1802.01528))
- [Machine Learning Feynman Experience](https://github.com/leandromineti/ml-feynman-experience) - Collection of concepts I tried to implement using only Python, NumPy and SciPy on Google Colaboratory.
- [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) - Library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research.
- [Deep learning drizzle](https://deep-learning-drizzle.github.io/) - Various ML, reinforcement learning video lectures. ([Code](https://github.com/kmario23/deep-learning-drizzle))
- [Xfer](https://github.com/amzn/xfer) - Transfer Learning library for Deep Neural Networks.
- [List of summer schools in machine learning + related fields](https://github.com/sshkhr/awesome-mlss)
- [Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)
- [Machine Learning CS Columbia Course (2019)](http://www.cs.columbia.edu/%7Everma/classes/ml/index.html)
- [Learning to Discover Efficient Mathematical Identities](https://github.com/kkurach/math_learning) - Exploring how machine learning techniques can be applied to the discovery of efficient mathematical identities.
- [CleverHans](https://github.com/tensorflow/cleverhans) - Adversarial example library for constructing attacks, building defenses, and benchmarking both.
- [Google AI Research](https://github.com/google-research/google-research) - Contains code released by Google AI Research.
- [Machine Learning Mindmap / Cheatsheet](https://github.com/dformoso/machine-learning-mindmap)
- [Curated list of network embedding techniques](https://github.com/chihming/awesome-network-embedding)
- [Deploying Deep Learning](https://github.com/dusty-nv/jetson-inference) - Training guide for inference and deep vision runtime library for NVIDIA DIGITS and Jetson Xavier/TX1/TX2.
- ["Adversarial Machine Learning" with Ian Goodfellow (2018)](https://www.youtube.com/watch?v=3-qazNQS2JU)
- [HN: Yann LeCun, Geoffrey Hinton and Yoshua Bengio win Turing Award (2019)](https://news.ycombinator.com/item?id=19499515)
- [Large scale K-means and K-nn implementation on NVIDIA GPU / CUDA](https://github.com/src-d/kmcuda)
- [fairseq](https://github.com/facebookresearch/fairseq) - Sequence-to-sequence learning toolkit for Torch from Facebook AI Research tailored to Neural Machine Translation (NMT).
- [TinyFlow](https://github.com/tqchen/tinyflow) - Tutorial code on how to build your own Deep Learning System in 2k Lines.
- [Deep Learning Models](https://github.com/rasbt/deeplearning-models) - Collection of various deep learning architectures, models, and tips.
- [Multi-Level Intermediate Representation Overview](https://github.com/tensorflow/mlir) - MLIR project aims to define a common intermediate representation (IR) that will unify the infrastructure required to execute high performance machine learning models in TensorFlow and similar ML frameworks. ([Talks](https://mlir.llvm.org/talks/)) ([HN](https://news.ycombinator.com/item?id=22429107)) ([Slides](http://llvm.org/devmtg/2019-04/slides/Keynote-ShpeismanLattner-MLIR.pdf))
- [PySparNN](https://github.com/facebookresearch/pysparnn) - Approximate Nearest Neighbor Search for Sparse Data in Python.
- [Machine Learning Course with Python](https://github.com/machinelearningmindset/machine-learning-course)
- [ICML](https://icml.cc/) - International Conference on Machine Learning.
- [Integrating Domain Knowledge into Deep Learning by Ruslan Salakhutdinov (2019)](https://www.youtube.com/watch?v=b8ABJZ7lfXU)
- [Differentiation for Hackers](https://github.com/MikeInnes/diff-zoo) - The goal of this handbook is to demystify algorithmic differentiation, the tool that underlies modern machine learning.
- [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning)
- [Machine Learning Systems are Stuck in a Rut (2019)](https://dl.acm.org/citation.cfm?id=3321441) ([HN](https://news.ycombinator.com/item?id=20301619))
- [Literature of Deep Learning for Graphs](https://github.com/DeepGraphLearning/LiteratureDL4Graph)
- [Supplementary Materials for "Unsupervised word embeddings capture latent knowledge from materials science literature", Nature](https://github.com/materialsintelligence/mat2vec)
- [Solution of assignment in 2011 Stanford Machine Learning Class](https://github.com/everpeace/ml-class-assignments)
- [Autocompletion with deep learning (2019)](https://tabnine.com/blog/deep)
- [Rules of Machine Learning: Best Practices for ML Engineering](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)
- [Python Machine Learning Book (2019)](https://www.packtpub.com/product/python-machine-learning-third-edition/9781789955750) ([3rd edition code](https://github.com/rasbt/python-machine-learning-book-3rd-edition)) ([2nd edition code](https://github.com/rasbt/python-machine-learning-book-2nd-edition))
- [ML and DS Applications in Industry](https://github.com/firmai/industry-machine-learning) - Curated list of applied machine learning and data science notebooks and libraries across different industries.
- [Awesome production machine learning](https://github.com/EthicalML/awesome-production-machine-learning)
- [Awesome Gradient Boosting Research Papers](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers)
- [HoloClean](https://github.com/HoloClean/holoclean) - Machine Learning System for Data Enrichment.
- [Snorkel](https://github.com/snorkel-team/snorkel) - System for quickly generating training data with weak supervision.
- [RAdam](https://github.com/LiyuanLucasLiu/RAdam) - On The Variance Of The Adaptive Learning Rate And Beyond.
- [Google ML/AI Comic](https://cloud.google.com/products/ai/ml-comic-1/)
- [Machine Learning Notebooks](https://github.com/ageron/handson-ml2) - Series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.
- [Streamlit](https://github.com/streamlit/streamlit) - Fastest way to build custom ML tools. ([Web](https://streamlit.io/)) ([Awesome Streamlit](https://github.com/MarcSkovMadsen/awesome-streamlit)) ([Streamlit Cheat Sheet](https://github.com/daniellewisDL/streamlit-cheat-sheet)) ([Tips, tricks, methods, and techniques for building apps with streamlit](https://github.com/pmbaumgartner/streamlitopedia)) ([Best of Streamlit](https://github.com/jrieke/best-of-streamlit)) ([How to build Streamlit apps on Replit](https://blog.streamlit.io/how-to-build-streamlit-apps-on-replit/))
- [A Gentle Introduction to Bayes’ Theorem for Machine Learning (2019)](https://news.ycombinator.com/item?id=21151032) ([HN](https://news.ycombinator.com/item?id=21151032))
- [Practical Deep Learning for Coders](https://course.fast.ai/) ([Notes](https://github.com/reshamas/fastai_deeplearn_part1)) ([Code](https://github.com/fastai/course22))
- [Part 2: Deep Learning from the Foundations](https://course.fast.ai/part2)
- [Computational Linear Algebra for Coders](https://github.com/fastai/numerical-linear-algebra)
- [Introduction to Machine Learning for Coders](http://course18.fast.ai/ml)
- [Papers with Code](https://paperswithcode.com/) - The latest in machine learning. ([HN](https://news.ycombinator.com/item?id=29688214)) ([GitHub](https://github.com/paperswithcode))
- [Gradient Descent Derivation (2014)](https://mccormickml.com/2014/03/04/gradient-descent-derivation/)
- [Best of Machine Learning Newsletter](https://bestofml.com/)
- [TASO](https://github.com/jiazhihao/taso) - Tensor Algebra SuperOptimizer for Deep Learning.
- [An Exponential Learning Rate Schedule for Deep Learning (2019)](https://arxiv.org/abs/1910.07454)
- [Billion-scale semi-supervised learning for state-of-the-art image and video classification (2019)](https://ai.facebook.com/blog/billion-scale-semi-supervised-learning)
- [TRAINS](https://github.com/allegroai/trains) - Auto-Magical Experiment Manager & Version Control for AI.
- [Differentiable Optimization-Based Modeling for Machine Learning (2019)](https://github.com/bamos/thesis)
- [Notebooks and code for the book "Introduction to Machine Learning with Python"](https://github.com/amueller/introduction_to_ml_with_python)
- [Awesome Deep Learning Project Ideas](https://github.com/NirantK/awesome-project-ideas)
- [Top-down, practical guide to learn AI, Deep learning and Machine Learning](https://github.com/emilwallner/How-to-learn-Deep-Learning)
- [Most Aesthetically Pleasing ML Research Papers](https://www.reddit.com/r/MachineLearning/comments/bp6l9y/d_most_aesthetically_pleasing_ml_research_papers/)
- [Polyaxon](https://polyaxon.com/) - Platform for reproducible and scalable machine learning and deep learning on Kubernetes. ([GitHub](https://github.com/polyaxon)) ([Code](https://github.com/polyaxon/polyaxon))
- [Different projects built using fast.ai](https://forums.fast.ai/t/share-you-work-here-highlights/57140)
- [Spell](https://spell.run/) - Fastest and most powerful end-to-end platform for machine learning and deep learning.
- [ML portfolio tips (2019)](https://twitter.com/EmilWallner/status/1184723538810413056)
- [DeepMind Research](https://github.com/deepmind/deepmind-research) - Contains implementations and illustrative code to accompany DeepMind publications.
- [Deep Learning Tutorials](https://github.com/lisa-lab/DeepLearningTutorials)
- [Prodify](https://prodi.gy/) - Radically efficient machine teaching. An annotation tool powered by active learning.
- [Runway](https://runwayml.com/) - Professional video editing powered by machine learning — all on the web. ([HN](https://news.ycombinator.com/item?id=27766655))
- [An Extended Version Of The Scikit-Learn Cheat Sheet (2014)](https://medium.com/@chris_bour/an-extended-version-of-the-scikit-learn-cheat-sheet-5f46efc6cbb)
- [Notes on Machine Learning](https://wiki.kourouklides.com/wiki/Machine_Learning)
- [Notes on Deep Learning](https://wiki.kourouklides.com/wiki/Deep_Learning)
- [Awesome free deep learning papers](https://github.com/HFTrader/awesome-free-deep-learning-papers)
- [Teachable Machine](https://teachablemachine.withgoogle.com/) - Fast, easy way to create machine learning models for your sites, apps, and more – no expertise or coding required.
- [Deep Learning Interview Topics](https://github.com/vlgiitr/DL_Topics)
- [Ask HN: Why do so many startups claim machine learning is their long game? (2019)](https://news.ycombinator.com/item?id=21528246)
- [End-to-End Machine Learning Courses](https://end-to-end-machine-learning.teachable.com/courses/)
- [End-to-End Machine Learning Library](https://e2eml.school/blog.html)
- [Course material for STAT 479: Machine Learning (FS 2019) taught by Sebastian Raschka at University Wisconsin-Madison](https://github.com/rasbt/stat479-machine-learning-fs19)
- [Clipper](https://github.com/ucbrise/clipper) - Prediction serving system that sits between user-facing applications and a wide range of commonly used machine learning models and frameworks.
- [AI building blocks - from scratch with Python (2018)](https://datadan.io/ai-building-blocks-from-scratch-with-python)
- [ARUBA: Learning-to-Learn with Less Regret (2019)](https://blog.ml.cmu.edu/2019/11/22/aruba/)
- [Machine Learning Systems Design](https://github.com/chiphuyen/machine-learning-systems-design)
- [Guide to Production Level Deep Learning](https://github.com/alirezadir/Production-Level-Deep-Learning)
- [Lessons learned building an ML trading system that turned $5k into $200k (2019)](https://www.tradientblog.com/2019/11/lessons-learned-building-an-ml-trading-system-that-turned-5k-into-200k/) ([HN](https://news.ycombinator.com/item?id=21647038))
- [Deep Learning for Programmers](https://aiprobook.com/deep-learning-for-programmers/)
- [Arcade Learning Environment](https://github.com/mgbellemare/Arcade-Learning-Environment) - Simple object-oriented framework that allows researchers and hobbyists to develop AI agents for Atari 2600 games.
- [Space to discuss the future of the ML ecosystem in Rust](https://github.com/rust-ml/discussion)
- [Awesome System for Machine Learning](https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning)
- [Collection of explainer tutorials on how machine learning and statistical concepts work](https://end-to-end-machine-learning.teachable.com/p/machine-learning-signal-processing-statistics-concepts)
- [2019’s Top Machine and Deep Learning Research Papers](https://heartbeat.fritz.ai/2019s-Gtop-machine-and-deep-learning-research-papers-1ec363f29e85?gi=86d0e6c2ea9f) ([HN](https://news.ycombinator.com/item?id=21743950))
- [NeurIPS 2019 Schedule](https://nips.cc/Conferences/2019/Schedule)
- [Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course) - Google's fast-paced, practical introduction to machine learning.
- [What was your favorite paper of 2019 and why? (2019)](https://www.reddit.com/r/MachineLearning/comments/e8the3/d_what_was_your_favorite_paper_of_2019_and_why/)
- [Ask HN: Full-on machine learning for 2020, what are the best resources?](https://news.ycombinator.com/item?id=21924298)
- [Dive into Deep Learning](https://d2l.ai/) - Interactive deep learning book with code, math, and discussions, based on the NumPy interface. ([HN](https://news.ycombinator.com/item?id=21948698)) ([Code](https://github.com/d2l-ai/d2l-en))
- [Resources to learn more about Machine Learning and Artificial Intelligence](https://github.com/brylevkirill/notes)
- [Foundations of Machine Learning book](https://mitpress.mit.edu/books/foundations-machine-learning-second-edition) - New edition of a graduate-level machine learning textbook that focuses on the analysis and theory of algorithms.
- [Deep Learning book](https://www.deeplearningbook.org/) - Resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. ([Code](https://github.com/zsdonghao/deep-learning-book)) ([Notes](https://github.com/greentfrapp/deep-learning-book-notes)) ([Exercises](https://github.com/goodfeli/dlbook_exercises)) ([LaTeX files for book notation](https://github.com/goodfeli/dlbook_notation)) ([PDF](https://github.com/daviddao/deep-learning-book/blob/master/DeepLearningBook.pdf)) ([PDF 2](https://github.com/janishar/mit-deep-learning-book-pdf))
- [Introduction to Deep Learning - Eugene Charniak](https://mitpress.mit.edu/books/introduction-deep-learning) - Project-based guide to the basics of deep learning.
- [Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems](https://www.goodreads.com/book/show/40363665-hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow)
- [Topological Techniques for Unsupervised Learning (2019)](https://www.youtube.com/watch?v=7pAVPjwBppo)
- [Meet AdaMod: a new deep learning optimizer with memory (2020)](https://medium.com/@lessw/meet-adamod-a-new-deep-learning-optimizer-with-memory-f01e831b80bd)
- [Deep Learning State of the Art (2020)](https://www.youtube.com/watch?v=0VH1Lim8gL8)
- [The Case for Bayesian Deep Learning (2020)](https://cims.nyu.edu/~andrewgw/caseforbdl/) ([HN](https://news.ycombinator.com/item?id=22023490)) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/eng1gl/the_case_for_bayesian_deep_learning/))
- [Machine Learning Summer School (2020)](http://mlss.tuebingen.mpg.de/2020/)
- [Machine Learning Summer School videos (2009)](http://videolectures.net/mlss09uk_cambridge/)
- [Turi Create](https://github.com/apple/turicreate) - Simplifies the development of custom machine learning models.
- [Private machine learning progress](https://github.com/OpenMined/private-ai-resources)
- [Demucs](https://github.com/facebookresearch/demucs) - Code for the paper Music Source Separation in the Waveform Domain.
- [Apple at NeurIPS 2019](https://machinelearning.apple.com/2019/12/02/apple-at-neurips-2019.html)
- [Magenta](https://magenta.tensorflow.org/) - Make Music and Art Using Machine Learning. ([JS Code](https://github.com/magenta/magenta-js)) ([GitHub](https://github.com/magenta))
- [An overview of gradient descent optimization algorithms (2016)](https://ruder.io/optimizing-gradient-descent/)
- [What are the current significant trends in ML that are NOT Deep Learning related? (2020)](https://www.reddit.com/r/MachineLearning/comments/eq3da0/d_what_are_the_current_significant_trends_in_ml/)
- [Trax](https://github.com/google/trax) - Helps you understand and explore advanced deep learning.
- [ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning](https://dai.lids.mit.edu/projects/atmseer/) ([Code](https://github.com/HDI-Project/ATMSeer))
- [Cambridge Machine Learning Group](http://mlg.eng.cam.ac.uk/)
- [Convolutional Conditional Neural Processes (2020)](https://openreview.net/forum?id=Skey4eBYPS)
- [Privacy Preserving AI (Andrew Trask) (2020)](https://www.youtube.com/watch?v=4zrU54VIK6k)
- [Emil’s Story as a Self-Taught AI Researcher (2020)](https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/)
- [Humans of Machine Learning](https://blog.floydhub.com/tag/humans-of-ml/)
- [Machine Learning Flashcards](https://machinelearningflashcards.com/) ([HN](https://news.ycombinator.com/item?id=22629959))
- [Awesome Software Engineering for Machine Learning](https://github.com/SE-ML/awesome-seml)
- [Awesome Data Labeling](https://github.com/heartexlabs/awesome-data-labeling) - Curated list of awesome data labeling tools.
- [Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence (2020)](https://arxiv.org/abs/2002.04803)
- [fastai: A Layered API for Deep Learning (2020)](https://arxiv.org/abs/2002.04688) ([HN](https://news.ycombinator.com/item?id=22324023))
- [The Deep Learning Compiler: A Comprehensive Survey (2020)](https://arxiv.org/abs/2002.03794)
- [Perceptrons explained](https://owenshen24.github.io/perceptron/)
- [A Simple Framework for Contrastive Learning of Visual Representations (2020)](https://arxiv.org/abs/2002.05709) ([Tweet](https://twitter.com/tingchenai/status/1228337240708874241)) ([Code](https://github.com/leftthomas/SimCLR))
- [MediaPipe](https://github.com/google/mediapipe) - Cross-platform framework for building multimodal applied machine learning pipelines.
- [ML courses by Zico Kolter](http://zicokolter.com/courses/)
- [List of AI Residency Programs](https://github.com/dangkhoasdc/awesome-ai-residency)
- [MIT Introduction to Deep Learning course (2020)](http://introtodeeplearning.com/) ([Code](https://github.com/aamini/introtodeeplearning)) ([Videos](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI))
- [Stanford Deep Multi-Task and Meta Learning course (2019)](http://cs330.stanford.edu/)
- [FastAI book draft (2020)](https://github.com/fastai/fastbook) ([HN](https://news.ycombinator.com/item?id=22449562)) ([Notebooks](https://github.com/fastai/book_nbs))
- [Pattern Recognition and Machine Learning by Christopher M. Bishop Book](https://www.goodreads.com/book/show/55881.Pattern_Recognition_and_Machine_Learning) ([Code](https://github.com/ctgk/PRML)) ([PDF](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) ([Code/Notes](https://github.com/gerdm/prml))
- [Google Colaboratory](https://github.com/googlecolab/backend-container) - Research project created to help disseminate machine learning education and research.
- [Resources for teaching machine learning](https://github.com/kierisi/teaching_ml/blob/master/teaching_ml_resources.md)
- [Population Based Augmentation](https://github.com/arcelien/pba) - Algorithm that quickly and efficiently learns data augmentation functions for neural network training.
- [NVIDIA Deep Learning Examples for Tensor Cores](https://github.com/NVIDIA/DeepLearningExamples)
- [Introduction to Deep Learning and Generative Models course](http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/) ([Code](https://github.com/rasbt/stat453-deep-learning-ss20))
- [Collection of Conference & School Notes in Machine Learning](https://github.com/RobertTLange/visual-machine-learning-notes)
- [AutoML-Zero](https://github.com/google-research/google-research/tree/master/automl_zero#automl-zero) - Open source code for the paper: "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch". ([HN](https://news.ycombinator.com/item?id=22539117))
- [fastAI course v4](https://github.com/fastai/course-v4)
- [Ask HN: What is your ML stack like? (2020)](https://news.ycombinator.com/item?id=21516311)
- [MLflow](https://mlflow.org/) - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. ([Code](https://github.com/mlflow/mlflow/))
- [Deep Unsupervised Learning (2020)](https://sites.google.com/view/berkeley-cs294-158-sp20/home)
- [Machine Learning: a Probabilistic Perspective book](https://www.cs.ubc.ca/~murphyk/MLbook/) ([Code](https://github.com/probml/pyprobml))
- [Introduction to Machine Learning - Carnegie Mellon University (2019)](http://www.cs.cmu.edu/%7Eninamf/courses/315sp19/)
- [Notes on ML courses](https://github.com/alisher0717/machine-learning-notes)
- [Made With ML](https://madewithml.com/) - Share what you've Made With ML. ([Code](https://github.com/GokuMohandas/MadeWithML)) ([MLOps Course](https://github.com/GokuMohandas/applied-ml))
- [Backpropagation 101 (2020)](https://thinc.ai/docs/backprop101) - How to trick yourself into understanding backprop without even trying.
- [A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale Learning (2017)](https://arxiv.org/abs/1702.04638)
- [Open Source Deep Learning Glossary](https://github.com/jrdi/dl-glossary)
- [Awesome Graph Classification](https://github.com/benedekrozemberczki/awesome-graph-classification) - Collection of important graph embedding, classification and representation learning papers with implementations.
- [fast.ai](https://www.fast.ai/) - Making neural nets uncool again. ([Code](https://github.com/fastai/fastai)) ([Docs](https://docs.fast.ai/)) ([Course launch](https://www.fast.ai/2020/08/21/fastai2-launch/)) ([HN](https://news.ycombinator.com/item?id=24237207))
- [Interactive Tools for ML, DL and Math](https://github.com/Machine-Learning-Tokyo/Interactive_Tools)
- [Deep learning with graph-structured representations (2020)](https://pure.uva.nl/ws/files/46900201/Thesis.pdf)
- [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments) ([Web](https://trekhleb.github.io/machine-learning-experiments/#/))
- [AxCell: Automatic Extraction of Results from Machine Learning Papers (2020)](https://arxiv.org/abs/2004.14356)
- [Awesome Machine Learning and AI Courses](https://github.com/luspr/awesome-ml-courses)
- [How do you keep up with new research? (2020)](https://www.reddit.com/r/MachineLearning/comments/gko05p/discussion_how_do_you_guys_keep_up_with_new/)
- [OpenLTH: A Framework for Lottery Tickets and Beyond](https://github.com/facebookresearch/open_lth)
- [Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning](https://github.com/ruqizhang/csgmcmc)
- [Awesome Interpretable Machine Learning](https://github.com/lopusz/awesome-interpretable-machine-learning)
- [DLPack: Open In Memory Tensor Structure](https://github.com/dmlc/dlpack)
- [SVM tutorial](https://www.svm-tutorial.com/) ([HN](https://news.ycombinator.com/item?id=23368246))
- [DeepMind x UCL | Deep Learning Lecture Series (2020)](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)
- [Nicholas Carlini: Making and Measuring Progress in Adversarial Machine Learning (2019)](https://www.youtube.com/watch?v=jD3L6HiH4ls)
- [Deep Learning in Production](https://github.com/ahkarami/Deep-Learning-in-Production) - Notes and references about deploying deep learning-based models in production.
- [Stanford Class on Deep Multi-Task and Meta-Learning (2019)](https://cs330.stanford.edu/) ([HN](https://news.ycombinator.com/item?id=23474846))
- [Weights & Biases](https://wandb.ai/home) - Developer tools for ML. Experiment tracking, hyperparameter optimization, model and dataset versioning. ([Code](https://github.com/wandb/client)) ([Docs](https://docs.wandb.ai/)) ([Examples](https://github.com/wandb/examples)) ([Community](https://community.wandb.ai/))
- [Protocols and Structures for Inference (PSI) spec](http://psi.cecs.anu.edu.au/spec/) - Aims to develop an architecture for presenting machine learning algorithms, their inputs (data) and outputs (predictors) as resource-oriented RESTful web services.
- [ML Engineer Roadmap](https://github.com/chris-chris/ml-engineer-roadmap)
- [Machine Learning for Everyone - In simple words. With real-world examples.](https://vas3k.com/blog/machine_learning/)
- [Deep learning на пальцах](https://dlcourse.ai/) ([Code](https://github.com/sim0nsays/dlcourse_ai))
- [How to add AI to your app without knowing anything about AI (2020)](https://jaredpalmer.com/blog/add-ai-to-your-app-without-knowing-anything-about-ai)
- [What I learned from looking at 200 machine learning tools (2020)](https://huyenchip.com/2020/06/22/mlops.html) ([HN](https://news.ycombinator.com/item?id=23620757))
- [Interactive Machine Learning List](https://p.migdal.pl/interactive-machine-learning-list/) ([Code](https://github.com/stared/interactive-machine-learning-list/))
- [Sema](https://sema.codes/) - Live Code Language Design Playground. ([Code](https://github.com/mimic-sussex/sema))
- [Model Zoo](https://modelzoo.dev/) - Deploy your model with a single line of code. ([HN](https://news.ycombinator.com/item?id=23678633))
- [Introduction to Machine Learning with Julia](https://juliaacademy.com/p/introduction-to-machine-learning)
- [Reverb](https://github.com/deepmind/reverb) - Efficient and easy-to-use data storage and transport system designed for machine learning research.
- [System design patterns for machine learning](https://github.com/mercari/ml-system-design-pattern)
- [Income strategies to support your ML research (2020)](https://twitter.com/EmilWallner/status/1278321048346341379)
- [Synthetic Data for Deep Learning (2019)](https://arxiv.org/abs/1909.11512)
- [NeurIPS](https://neurips.cc/) - Conference on Neural Information Processing Systems.
- [Machine Learning Mastery](https://machinelearningmastery.com/)
- [Distill](https://distill.pub/) - Latest articles about machine learning.
- [Compute access for ML training (2020)](https://twitter.com/EmilWallner/status/1276071724224831489)
- [Scann: Scalable Nearest Neighbors](https://github.com/google-research/google-research/tree/master/scann) ([HN](https://news.ycombinator.com/item?id=23737338))
- [CML](https://cml.dev/) - Continuous Machine Learning: Bring DevOps to Data Science. ([HN](https://news.ycombinator.com/item?id=23759332)) ([Code](https://github.com/iterative/cml)) ([Web Code](https://github.com/iterative/cml.dev))
- [TensorFlow, Keras and deep learning, without a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0) ([HN](https://news.ycombinator.com/item?id=23867892))
- [Apple Machine Learning Research](https://machinelearning.apple.com/) ([HN](https://news.ycombinator.com/item?id=23944506))
- [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit) - Streamlines and automates generation of Model Cards, machine learning documents that provide context and transparency into a model's development and performance. ([Article](https://ai.googleblog.com/2020/07/introducing-model-card-toolkit-for.html))
- [Top ML Books recommended by experts](https://mentorcruise.com/books/ml/)
- [Best practices for performance and cost optimization for machine learning](https://cloud.google.com/solutions/machine-learning/best-practices-for-ml-performance-cost)
- [Bethge Lab](http://bethgelab.org/) - Perceiving Neural Networks.
- [Graphcore code examples](https://github.com/graphcore/examples)
- [Machine learning examples and tutorials](https://github.com/lazyprogrammer/machine_learning_examples)
- [Vintage Factor Analysis with Varimax Performs Statistical Inference (2020)](https://arxiv.org/abs/2004.05387)
- [An Opinionated Guide to ML Research (2020)](http://joschu.net/blog/opinionated-guide-ml-research.html)
- [Amazon's Machine Learning University](https://www.amazon.science/latest-news/machine-learning-course-free-online-from-amazon-machine-learning-university) ([HN](https://news.ycombinator.com/item?id=24167034))
- [Progress, Notes, Summaries and a lot of Questions on Machine Learning](https://github.com/RobertTLange/reading-notes-ml)
- [SciML](https://sciml.ai/) - Open Source Software for Scientific Machine Learning.
- [Mihaela Rosca ML notes](https://github.com/mihaelacr/paper-notes)
- [Compression of Deep Learning Models for Text: A Survey (2020)](https://arxiv.org/abs/2008.05221)
- [The Computational Limits of Deep Learning (2020)](https://arxiv.org/abs/2007.05558) ([HN](https://news.ycombinator.com/item?id=24192117))
- [ML Ops: Machine Learning Operations](https://ml-ops.org/) ([Awesome](https://github.com/visenger/awesome-mlops)) ([References](https://ml-ops.org/content/references.html))
- [Benchmarks of approximate nearest neighbor libraries in Python](https://github.com/erikbern/ann-benchmarks) ([Web](http://ann-benchmarks.com/))
- [MIT Deep Learning course](https://github.com/lexfridman/mit-deep-learning)
- [Visualizing Deep Learning (2020)](https://www.youtube.com/playlist?list=PLyPKqVSnetmEOp_g_hfabuRAs9ET-shl_)
- [Books for Machine Learning, Deep Learning, and related topics](https://github.com/loveunk/Deep-learning-books)
- [Graph Representation Learning Book](https://www.cs.mcgill.ca/~wlh/grl_book/) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/iezafd/r_graph_representation_learning_book_by_will/))
- [Effective testing for machine learning systems (2020)](https://www.jeremyjordan.me/testing-ml/) ([HN](https://news.ycombinator.com/item?id=24332202))
- [Machine Learning from Scratch](https://dafriedman97.github.io/mlbook/content/introduction.html) ([HN](https://news.ycombinator.com/item?id=24332303)) ([Code](https://github.com/dafriedman97/mlbook))
- [Compose](https://github.com/FeatureLabs/compose) - Machine learning tool for automated prediction engineering. It allows you to structure prediction problems and generate labels for supervised learning.
- [Daily scikit-learn tips](https://github.com/justmarkham/scikit-learn-tips)
- [Applied ML](https://github.com/eugeneyan/applied-ml) - Curated papers, articles, and blogs on data science & machine learning in production.
- [Understanding Convolution in Deep Learning (2015)](https://timdettmers.com/2015/03/26/convolution-deep-learning/)
- [21 Habits I Picked Up While Learning Machine Learning (2019)](http://blog.varunajayasiri.com/practices_learned_while_learning_machine_learning.html)
- [Hacker News for ML](https://mln.dev/top/1)
- [Think Fast: Tensor Streaming Processor for Accelerating Deep Learning Workloads (2020)](https://conferences.computer.org/isca/pdfs/ISCA2020-4QlDegUf3fKiwUXfV0KdCm/466100a145/466100a145.pdf)
- [My Deep Learning Toolchain (2020)](https://rosshemsley.co.uk/posts/deep_learning_toolchain/)
- [igel](https://github.com/nidhaloff/igel) - Machine learning tool that allows you to train/fit, test and use models without writing code. ([HN](https://news.ycombinator.com/item?id=24671525))
- [Gradient Boosted Decision Trees (2020)](https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/) ([HN](https://news.ycombinator.com/item?id=24700250))
- [NeurIPS 2020 Accepted Papers](https://neurips.cc/Conferences/2020/AcceptedPapersInitial)
- [explained.ai](https://explained.ai/) - Deep explanations of machine learning and related topics.
- [How to visualize decision trees (2018)](https://explained.ai/decision-tree-viz/index.html)
- [How to explain gradient boosting (2018)](https://explained.ai/gradient-boosting/index.html)
- [Beware Default Random Forest Importances (2018)](https://explained.ai/rf-importance/index.html)
- [The Mechanics of Machine Learning](https://mlbook.explained.ai/)
- [Yann LeCun Spring 2020 DL Course (Videos, Slides, Jupyter Notebooks)](https://atcold.github.io/pytorch-Deep-Learning/) ([HN](https://news.ycombinator.com/item?id=24715307)) ([Article](https://nyudatascience.medium.com/yann-lecuns-deep-learning-course-at-cds-is-now-fully-online-accessible-to-all-787ddc8bf0af))
- [Yann LeCun Deep Learning Course 2021](https://atcold.github.io/NYU-DLSP21/) ([HN](https://news.ycombinator.com/item?id=27387154))
- [ML Guide: Feature Store vs Data Warehouse (2020)](https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse) ([HN](https://news.ycombinator.com/item?id=24718301))
- [Grid AI](https://www.grid.ai/) - Seamlessly train hundreds of Machine Learning models on the cloud from your laptop. ([HN](https://news.ycombinator.com/item?id=24720681))
- [Getting Started with Applied ML Research (2020)](https://elvissaravia.substack.com/p/getting-started-with-applied-ml-research)
- [Machine Learning Engineering book by Andriy Burkov](http://www.mlebook.com/wiki/doku.php)
- [Determined](https://github.com/determined-ai/determined) - Deep Learning Training Platform. ([Web](https://determined.ai/))
- [Phasic Policy Gradient](https://github.com/openai/phasic-policy-gradient)
- [Juergen Schmidhuber ML reading list (2015)](https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp5c0py/)
- [Machine Learning Primer for Interviews](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)
- [Confetti AI](https://www.confetti.ai/) - Ace Your Machine Learning Interviews.
- [Intro to Deep Learning: Use TensorFlow and Keras to build and train neural networks by Kaggle](https://www.kaggle.com/learn/intro-to-deep-learning)
- [Manifold](https://github.com/uber/manifold) - Model-agnostic visual debugging tool for machine learning. ([Web](http://manifold.mlvis.io/))
- [Making With ML YouTube series](https://github.com/google/making_with_ml)
- [Topological Autoencoders (2020)](https://michaelmoor.ml/blog/topoae/main/) ([Code](https://github.com/BorgwardtLab/topological-autoencoders))
- [Awesome Teachable Machine List](https://github.com/SashiDo/awesome-teachable-machine) - Curated list of awesome machine learning projects built with Google's Teachable Machine.
- [How to put machine learning models into production (2020)](https://stackoverflow.blog/2020/10/12/how-to-put-machine-learning-models-into-production/)
- [Example Machine Learning Scripts for Numerai's Tournament (2020)](https://github.com/numerai/example-scripts)
- [Synthetic Data Vault (SDV)](https://github.com/sdv-dev/SDV) - Synthetic Data Generation for tabular, relational, time series data. ([Web](https://sdv.dev/))
- [Penn Machine Learning Benchmarks](https://github.com/EpistasisLab/pmlb) - Large, curated repository of benchmark datasets for evaluating supervised machine learning algorithms. ([Web](https://epistasislab.github.io/pmlb/))
- [2020 Machine Learning Roadmap](https://github.com/mrdbourke/machine-learning-roadmap)
- [Responsible Machine Learning](https://github.com/ModelOriented/DrWhy) - Collection of tools for eXplainable AI (XAI). ([Web](https://modeloriented.github.io/DrWhy/))
- [MI2 DataLab](https://mi2-warsaw.github.io/) - Group of mathematicians and computer scientists that love to play with data. ([GitHub](https://github.com/ModelOriented))
- [Papers of Robust ML](https://github.com/P2333/Papers-of-Robust-ML) - Mainly focus on defenses.
- [Why Deep Learning Works Even Though It Shouldn’t (2020)](https://moultano.wordpress.com/2020/10/18/why-deep-learning-works-even-though-it-shouldnt/) ([Lobsters](https://lobste.rs/s/qzbfzc/why_deep_learning_works_even_though_it))
- [Some Notable Recent ML Papers and Future Trends (2020)](https://arankomatsuzaki.wordpress.com/2020/10/15/some-notable-recent-ml-papers-and-future-trends/)
- [Wiki: 2020 ML Interviews Resources & Advice(s)](https://forums.fast.ai/t/wiki-2020-ml-interviews-resources-advice-s/70528)
- [Interpretable Machine Learning -- A Brief History, State-of-the-Art and Challenges (2020)](https://arxiv.org/abs/2010.09337)
- [Over 200 of the Best Machine Learning, NLP, and Python Tutorials (2018)](https://medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc)
- [What is a Feature Store? (2020)](https://www.tecton.ai/blog/what-is-a-feature-store/)
- [Awesome AutoML Papers](https://github.com/hibayesian/awesome-automl-papers) - Curated list of automated machine learning papers, articles.
- [Machine Learning Systems Design at Stanford course (2020)](https://huyenchip.com/2020/10/27/ml-systems-design-stanford.html)
- [Preferred Networks](https://preferred.jp/en/) - Develops practical applications of deep learning and other cutting-edge technologies. ([GitHub](https://github.com/pfnet))
- [ML Art](https://mlart.co/) - Curated showcase of creative machine learning artworks and projects.
- [Decision Making under Uncertainty course](https://web.stanford.edu/class/aa228/cgi-bin/wp/) ([Algorithms for Decision Making book](https://github.com/sisl/algorithmsbook/)) ([Concise Deep Learning Overview (2020)](https://web.stanford.edu/group/sisl/public/dm/chapter-31.pdf) ([HN](https://news.ycombinator.com/item?id=24908999))) ([Book Website](https://algorithmsbook.com/))
- [Effective testing for machine learning systems (2020)](https://www.jeremyjordan.me/testing-ml/)
- [Reading List for Topics in Multimodal Machine Learning](https://github.com/pliang279/awesome-multimodal-ml)
- [Awesome Multimodal Research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research)
- [ML and DL related contests, competitions and conference challenges](https://github.com/skrish13/ml-contests-conf)
- [ML Visuals](https://github.com/dair-ai/ml-visuals) - Contains figures and templates which you can reuse and customize to improve your scientific writing.
- [DL Visuals](https://github.com/dvgodoy/dl-visuals) - Deep Learning Visuals.
- [Deep Learning with Catalyst course](https://github.com/catalyst-team/dl-course)
- [OpenMined Courses](https://courses.openmined.org/) - Learn how privacy technology is changing our world and how you can lead the charge.
- [Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix)
- [DeepMind Educational Resources](https://github.com/deepmind/educational)
- [Deep Learning (for Audio) with Python](https://www.youtube.com/playlist?list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf) ([Code](https://github.com/musikalkemist/DeepLearningForAudioWithPython))
- [Awesome Tensor Compilers](https://github.com/merrymercy/awesome-tensor-compilers)
- [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox) - Python library for Machine Learning Security.
- [AI Summer](https://theaisummer.com/) - Learn Deep Learning and Artificial Intelligence. ([GitHub](https://github.com/The-AI-Summer))
- [How Attention works in Deep Learning (2020)](https://theaisummer.com/attention/)
- [Brain Tokyo Workshop](https://github.com/google/brain-tokyo-workshop) - Research materials released by members of the Google Brain team in Tokyo.
- [A Novel Framework for Explaining Machine Learning Using Shapley Values (2020)](https://arxiv.org/abs/1909.08128) ([HN](https://news.ycombinator.com/item?id=25180778))
- [create-ml-app](https://github.com/shreyashankar/create-ml-app) - Template Makefile for ML projects in Python.
- [telesto.ai](https://telesto.ai/) - Competitive marketplace, where you can work on real-life machine learning challenges.
- [ML from the Fundamentals](https://rickwierenga.com/blog/ml-fundamentals) - Machine learning in a "from the first principles" style. ([Code](https://github.com/rickwierenga/MLFundamentals))
- [Interpretability in Machine Learning: An Overview (2020)](https://thegradient.pub/interpretability-in-ml-a-broad-overview/)
- [Implicit Rank-Minimizing Autoencoder (2020)](https://arxiv.org/abs/2010.00679) ([Code](https://github.com/facebookresearch/irmae))
- [ML/CV/NLP study resources](https://github.com/mileistone/study_resources)
- [MIT Mądry Lab](http://madry-lab.ml/) - Towards a Principled Science of Deep Learning. ([GitHub](https://github.com/MadryLab))
- [Scaling Down Deep Learning (2020)](https://greydanus.github.io/2020/12/01/scaling-down/) ([HN](https://news.ycombinator.com/item?id=25314066)) ([HN](https://news.ycombinator.com/item?id=34097108))
- [Every Model Learned by Gradient Descent Is Approximately a Kernel Machine (2020)](https://arxiv.org/abs/2012.00152) ([HN](https://news.ycombinator.com/item?id=25314830))
- [DeepFaceLab](https://github.com/iperov/DeepFaceLab) - Leading software for creating deepfakes.
- [Deep Learning DIY](https://dataflowr.github.io/website/) ([Code](https://github.com/dataflowr/notebooks)) ([GitHub](https://github.com/dataflowr)) ([Website Code](https://github.com/dataflowr/website))
- [Using JAX to accelerate our research (2020)](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) ([HN](https://news.ycombinator.com/item?id=25332526))
- [Stanford MLSys Seminar Series (2020)](https://mlsys.stanford.edu/)
- [MLCommons](https://mlcommons.org/en/) - Machine learning innovation to benefit everyone.
- [Automated discovery of machine learning optimizations (2020)](https://searchworks.stanford.edu/view/13680855)
- [A Visual Tour of Backpropagation (2020)](https://blog.jinay.dev/posts/backprop/)
- [Deep Learning GPU Benchmarks](https://lambdalabs.com/gpu-benchmarks) ([Code](https://github.com/lambdal/lambda-tensorflow-benchmark))
- [What I wish someone had told me about tensor computation libraries (2020)](https://eigenfoo.xyz/tensor-computation-libraries/) ([HN](https://news.ycombinator.com/item?id=25435028))
- [Machine learning could be fundamentally unexplainable (2020)](https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable)
- [Minimum Viable Study Plan for Machine Learning Interviews](https://github.com/khangich/machine-learning-interview)
- [Awesome JAX](https://github.com/n2cholas/awesome-jax)
- [Machine Learning Productivity Hacks (2019)](http://amid.fish/ml-productivity)
- [Learn Deep Learning: Powerful Mental Models to Accelerate Your Journey (2020)](https://gumroad.com/l/learn_deep_learning) ([Tweet](https://twitter.com/radekosmulski/status/1340705699521769474))
- [OpenNMT](https://opennmt.net/) - Open source ecosystem for neural machine translation and neural sequence learning. ([GitHub](https://github.com/OpenNMT))
- [How much hyperparameter tuning do you typically end up doing? (2020)](https://www.reddit.com/r/MachineLearning/comments/khyk9r/d_for_those_in_the_industry_how_much/)
- [ZenML](https://github.com/zenml-io/zenml) - Extensible, open-source MLOps framework for using production-ready Machine Learning pipelines. ([Web](https://zenml.io/home))
- [MIT Parallel Computing and Scientific Machine Learning course (2020)](https://github.com/mitmath/18337)
- [Invariant Risk Minimization (2019)](https://arxiv.org/abs/1907.02893v1) ([Code](https://github.com/facebookresearch/InvariantRiskMinimization))
- [Awesome Federated Learning](https://github.com/chaoyanghe/Awesome-Federated-Learning)
- [Awesome Fraud Detection Research Papers](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers)
- [Probabilistic Machine Learning: An Introduction](https://probml.github.io/pml-book/book1.html) ([HN](https://news.ycombinator.com/item?id=25593262))
- [Awesome Machine Learning Interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)
- [Reflections on my (Machine Learning) PhD Journey (2020)](https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/)
- [ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus (2018)](https://www.inference.vc/untitled/) ([HN](https://news.ycombinator.com/item?id=25645205))
- [Distributed deep learning and inference without sharing raw data](https://splitlearning.github.io/) ([Code](https://github.com/splitlearning/splitlearning.github.io))
- [Famous ML papers/concepts that are hard to understand (2021)](https://www.reddit.com/r/MachineLearning/comments/krkxog/d_lets_start_2021_by_confessing_to_which_famous/)
- [MLJAR Automated Machine Learning](https://github.com/mljar/mljar-supervised) - Automates Machine Learning Pipeline with Feature Engineering and Hyper-Parameters Tuning. ([Web](https://mljar.com/)) ([HN](https://news.ycombinator.com/item?id=25644733))
- [Best of Machine Learning with Python](https://github.com/ml-tooling/best-of-ml-python)
- [Deep Learning's Most Important Ideas - A Brief Historical Review (2020)](https://dennybritz.com/blog/deep-learning-most-important-ideas/)
- [Awesome Anomaly Detection](https://github.com/hoya012/awesome-anomaly-detection)
- [Extending JAX with custom C++ and CUDA code](https://github.com/dfm/extending-jax)
- [Mathematical Engineering of Deep Learning Course (2021)](https://deeplearningmath.org/)
- [Paper List for Style Transfer in Text](https://github.com/fuzhenxin/Style-Transfer-in-Text)
- [Machine learning with large-scale graphs course](https://snap-stanford.github.io/cs224w-notes/) ([Notes](https://github.com/snap-stanford/cs224w-notes))
- [Single-Machine Simulation of Federated Learning Systems (2021)](https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems)
- [Awesome AutoML](https://github.com/windmaple/awesome-AutoML)
- [Optimization Methods for Machine Learning and Engineering (2021)](https://www.youtube.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5)
- [Three mysteries in deep learning: Ensemble, knowledge distillation, and self-distillation (2021)](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
- [Awesome Federated Computing](https://github.com/tushar-semwal/awesome-federated-computing)
- [Noah ML Research](https://github.com/huawei-noah/noah-research) - Research related code released by Huawei Noah's Ark Lab.
- [Prototypical Networks for Few-shot Learning (2017)](https://arxiv.org/abs/1703.05175) ([Code](https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch))
- [Domain generalization papers/resources](https://github.com/amber0309/Domain-generalization)
- [The Universal Training Loop of Machine Learning (2021)](https://liuliu.me/eyes/the-universal-training-loop-of-machine-learning/)
- [Learning Curve Theory (2021)](https://arxiv.org/abs/2102.04074)
- [ML Surveys](https://github.com/eugeneyan/ml-surveys) - Survey papers summarizing advances in deep learning, NLP, CV, graphs, reinforcement learning, recommendations, graphs, etc.
- [Practical Deep Learning Course](https://github.com/yandexdataschool/Practical_DL)
- [Diverse Counterfactual Explanations (DiCE) for ML](https://github.com/interpretml/DiCE) - Generate Diverse Counterfactual Explanations for any machine learning model. ([Docs](https://interpret.ml/DiCE/))
- [Interpretable Machine Learning](https://github.com/navdeep-G/interpretable-ml) - Techniques & resources for training interpretable ML models, explaining ML models, and debugging ML models.
- [Awesome Causality](https://github.com/napsternxg/awesome-causality) - Resources related to causality.
- [How to Understand ML Papers Quickly (2021)](https://blog.evjang.com/2021/01/understanding-ml.html)
- [Patterns, Predictions, and Actions Book](https://mlstory.org/) - A story about machine learning.
- [Full Stack Deep Learning Course (2021)](https://fullstackdeeplearning.com/spring2021/) ([Code](https://github.com/filipafcastro/fullstack_deeplearning_course))
- [Physical Principles for Scalable Neural Recording](https://arxiv.org/ftp/arxiv/papers/1306/1306.5709.pdf)
- [Learn About Transformers: A Recipe (2021)](https://elvissaravia.substack.com/p/learn-about-transformers-a-recipe)
- [An Inferential Perspective on Federated Learning (2021)](https://blog.ml.cmu.edu/2021/02/19/an-inferential-perspective-on-federated-learning/)
- [Free Lunch for Few-shot Learning: Distribution Calibration (2020)](https://arxiv.org/abs/2101.06395) ([Code](https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration))
- [Enlightening Guide to Machine Learning Interviews](https://github.com/alirezadir/machine-learning-interview-enlightener)
- [How Machine Language Works (2021)](https://www.youtube.com/watch?v=HWpi9n2H3kE)
- [Sliced Score Matching: A Scalable Approach to Density and Score Estimation (2019)](https://yang-song.github.io/blog/2019/ssm/)
- [Accelerating Natural Gradient with Higher-Order Invariance (2018)](https://yang-song.github.io/blog/2018/geo/)
- [Some interesting observations about machine learning publication practices from an outsider (2021)](https://www.reddit.com/r/MachineLearning/comments/lvwt3l/d_some_interesting_observations_about_machine/)
- [Understanding deep learning requires rethinking generalization (2021)](https://cacm.acm.org/magazines/2021/3/250713-understanding-deep-learning-still-requires-rethinking-generalization/fulltext) ([HN](https://news.ycombinator.com/item?id=26346226))
- [MIT HAN Lab](https://hanlab.mit.edu/) - Accelerate Deep Learning Computing. ([GitHub](https://github.com/mit-han-lab))
- [Feature Stores - A Hierarchy of Needs (2021)](https://eugeneyan.com/writing/feature-stores/)
- [Visualizing Representations: Deep Learning and Human Beings (2015)](http://colah.github.io/posts/2015-01-Visualizing-Representations/) ([Tweet](https://twitter.com/ch402/status/1367586896801492992))
- [Transformers](https://github.com/sannykim/transformers) - Collection of resources to study Transformers in depth.
- [Incomplete Deep Learning Guide](https://github.com/sannykim/deep-learning-guide)
- [A Year at Google Brain (2020)](https://www.debugmind.com/2020/01/04/paths-to-the-future-a-year-at-google-brain/) ([HN](https://news.ycombinator.com/item?id=26374143))
- [Pretrained Transformers as Universal Computation Engines (2021)](https://arxiv.org/abs/2103.05247) ([Code](https://github.com/kzl/universal-computation))
- [Testing Machine Learning Systems: Code, Data and Models](https://madewithml.com/courses/applied-ml/testing/) ([Tweet](https://twitter.com/GokuMohandas/status/1369261247993176066))
- [Finding Mona Lisa in the Game of Life (2021)](https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html) ([HN](https://news.ycombinator.com/item?id=26384403))
- [Geometric deep learning, from Euclid to drug design (2021)](https://www.youtube.com/watch?v=8IwJtFNXr1U&t=210s) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/m8ewph/geometric_foundations_of_deep_learning_research/))
- [GeoGuessing with Deep Learning (2021)](https://healeycodes.com/geoguessing-with-deep-learning/)
- [Awesome Incremental Learning / Lifelong learning](https://github.com/xialeiliu/Awesome-Incremental-Learning)
- [Out of Distribution Generalization in Machine Learning (2021)](https://arxiv.org/abs/2103.02667)
- [Label Errors](https://labelerrors.com/) - Label errors in benchmark ML test sets. ([Lobsters](https://lobste.rs/s/v28crd/label_errors_benchmark_ml_test_sets)) ([Code](https://github.com/cleanlab/label-errors))
- [What will the major ML research trends be in the 2020s?](https://www.reddit.com/r/MachineLearning/comments/mfnhki/d_what_will_the_major_ml_research_trends_be_in/)
- [Machine Learning and Deep Learning Courses (2021)](https://elvissaravia.substack.com/p/machine-learning-and-deep-learning)
- [Awesome Domain Adaptation](https://github.com/zhaoxin94/awesome-domain-adaptation)
- [Why machine learning struggles with causality (2021)](https://bdtechtalks.com/2021/03/15/machine-learning-causality/)
- [TabNet: Attentive Interpretable Tabular Learning (2020)](https://arxiv.org/abs/1908.07442) ([Code](https://github.com/dreamquark-ai/tabnet))
- [AutoML.org](https://www.automl.org/) ([GitHub](https://github.com/automl))
- [How I built a €25K Machine Learning Rig (2021)](https://www.emilwallner.com/p/ml-rig) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/ml6u5u/p_how_i_built_a_25k_machine_learning_rig/))
- [Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations (2019)](https://arxiv.org/abs/1903.05895)
- [Machine Learning Collection](https://github.com/aladdinpersson/Machine-Learning-Collection) - Resource for learning about ML, DL, PyTorch and TensorFlow.
- [Joint Universal Syntactic and Semantic Parsing (2021)](https://arxiv.org/abs/2104.05696)
- [A Comprehensive Introduction to Bayesian Deep Learning (2021)](https://www.topbots.com/comprehensive-introduction-to-bayesian-deep-learning/)
- [Stanford Machine Learning with Graphs Course (2021)](http://web.stanford.edu/class/cs224w/)
- [Keepsake](https://github.com/replicate/keepsake) - Version control for machine learning. ([Web](https://keepsake.ai/))
- [Learning Versatile Neural Architectures by Propagating Network Codes](https://github.com/dingmyu/NCP)
- [Machine learning is going real-time (2020)](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)
- [Awesome Normalizing Flows](https://github.com/janosh/awesome-normalizing-flows)
- [Differentiable Model Compression via Pseudo Quantization Noise (2021)](https://arxiv.org/abs/2104.09987) ([Code](https://github.com/facebookresearch/diffq))
- [The Rise of HuggingFace (2021)](https://marksaroufim.substack.com/p/huggingface)
- [See through Gradients: Image Batch Recovery via GradInversion (2021)](https://arxiv.org/abs/2104.07586) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/n0o6dn/d_new_paper_shows_that_federated_learning_is/))
- [Recommendation System using ML and DL](https://github.com/amitkaps/recommendation)
- [Mathematical Foundations of Machine Learning (2020)](https://www.dropbox.com/s/mffzmuo9fvs5j6m/Study_Guide.pdf)
- [How to Write Design Docs for Machine Learning Systems](https://eugeneyan.com/writing/ml-design-docs/) ([Code](https://github.com/eugeneyan/ml-design-docs))
- [Reproducible Deep Learning (2021)](https://www.sscardapane.it/teaching/reproducibledl/) - PhD Course in Data Science. ([Code](https://github.com/sscardapane/reprodl2021))
- [Unsupervised Contrastive Learning of Sound Event Representations (2020)](https://arxiv.org/abs/2011.07616) ([Code](https://github.com/edufonseca/uclser20/blob/main/README.md))
- [Differentially Private Learning Needs Better Features (or Much More Data) (2021)](https://arxiv.org/abs/2011.11660)
- [Bias, variance, and their relationship with machine learning algorithms explained (2021)](https://twitter.com/svpino/status/1390969728504565761)
- [Unsupervised Contrastive Learning of Sound Event Representations](https://github.com/edufonseca/uclser20)
- [Kobra](https://kobra.dev/) - Visual programming language for machine learning. ([HN](https://news.ycombinator.com/item?id=27135573))
- [Delving into Deep Imbalanced Regression (2021)](https://arxiv.org/abs/2102.09554) ([Code](https://github.com/YyzHarry/imbalanced-regression))
- [Comprehensive Survey on Transfer Learning](http://datamining.rutgers.edu/publication/A%20Comprehensive%20Survey%20on%20Transfer%20Learning.pdf)
- [Applied Deep Learning Course](https://github.com/maziarraissi/Applied-Deep-Learning) ([Videos](https://www.youtube.com/playlist?list=PLoEMreTa9CNmuxQeIKWaz7AVFd_ZeAcy4))
- [Pay Attention to MLPs (2021)](https://arxiv.org/abs/2105.08050) ([Tweet](https://twitter.com/Hanxiao_6/status/1394742841033641985)) ([Code](https://github.com/lucidrains/g-mlp-pytorch))
- [E(n) Equivariant Normalizing Flows for Molecule Generation in 3D (2021)](https://arxiv.org/abs/2105.09016) ([Tweet](https://twitter.com/wellingmax/status/1395281027824857088))
- [Fast and Slow Learning of Recurrent Independent Mechanisms (2021)](https://arxiv.org/abs/2105.08710) ([Tweet](https://twitter.com/anirudhg9119/status/1395889099102380032))
- [Weekly Papers](https://papers.labml.ai/papers/weekly) ([Daily](https://papers.labml.ai/papers/daily))
- [Sharpness-Aware Minimization for Efficiently Improving Generalization (2020)](https://arxiv.org/abs/2010.01412) ([Code](https://github.com/Jannoshh/simple-sam))
- [Apple - Making Mobile Applications Accessible with Machine Learning (2021)](https://machinelearning.apple.com/research/mobile-applications-accessible)
- [NYU Deep Learning Spring 2021](https://github.com/Atcold/NYU-DLSP21) ([Videos](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI))
- [JAX learning resources (2021)](https://www.reddit.com/r/MachineLearning/comments/no3r7m/d_jax_learning_resources/)
- [Machine Learning with Python Cookbook Book (2018)](https://www.oreilly.com/library/view/machine-learning-with/9781491989371/)
- [Understanding Dimensionality Reduction with UMAP](https://pair-code.github.io/understanding-umap/)
- [Neural Algorithmic Reasoning (2021)](https://arxiv.org/abs/2105.02761) ([Tweet](https://twitter.com/s_scardapane/status/1399378122894684166))
- [A Pragmatic Look at Deep Imitation Learning](https://github.com/Kaixhin/imitation-learning)
- [Stanford CS229: Machine Learning Course (2021)](http://cs229.stanford.edu/) ([Notes](https://github.com/mossr/machine_learning_book))
- [Informative Dropout for Robust Representation Learning: A Shape-bias Perspective (2020)](https://arxiv.org/abs/2008.04254) ([Code](https://github.com/bfshi/InfoDrop))
- [Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval (2020)](https://arxiv.org/abs/2007.00808) ([Code](https://github.com/microsoft/ANCE))
- [Fairification: Making Unfair Programs Fair (2017)](https://barghouthi.github.io/2017/05/01/debiasing/)
- [Fairness and machine learning: Limitations and Opportunities](https://fairmlbook.org/)
- [Practical Deep Learning for Cloud, Mobile, and Edge (2019)](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/)
- [Pretrained Encoders are All You Need (2021)](https://arxiv.org/abs/2106.05139) ([Code](https://github.com/PAL-ML/PEARL_v1))
- [The Modern Mathematics of Deep Learning (2021)](https://arxiv.org/abs/2105.04026) ([HN](https://news.ycombinator.com/item?id=27485574))
- [An Attention Free Transformer (2021)](https://arxiv.org/abs/2105.14103) ([Code](https://github.com/rish-16/aft-pytorch))
- [Towards Causal Representation Learning (2021)](https://arxiv.org/abs/2102.11107)
- [SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training (2021)](https://arxiv.org/abs/2106.01342) ([Code](https://github.com/somepago/saint))
- [AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation (2021)](https://arxiv.org/abs/2106.04732) ([Video](https://www.youtube.com/watch?v=ORufPOY8H14))
- [Distributed Machine Learning Patterns Book (2021)](https://www.manning.com/books/distributed-machine-learning-patterns) ([Code](https://github.com/terrytangyuan/distributed-ml-patterns))
- [Revisiting Deep Learning Models for Tabular Data (2021)](https://arxiv.org/abs/2106.11959)
- [Introduction to Machine Learning Interviews Book](https://huyenchip.com/ml-interviews-book/) ([Code](https://github.com/chiphuyen/ml-interviews-book))
- [Introduction to Machine Learning 2019 at ETH Zürich](https://las.inf.ethz.ch/teaching/introml-s19) ([Summary](https://github.com/eth-cs-student-summaries/Introduction-to-Machine-Learning))
- [Awesome Community Detection Research Papers](https://github.com/benedekrozemberczki/awesome-community-detection)
- [Understanding Deep Learning (2021)](https://www.youtube.com/playlist?list=PLFE-LjWAAP9Q74cGaUF3yqUhqo2kOYY20)
- [The Scaling Hypothesis](https://www.gwern.net/Scaling-hypothesis)
- [ML YouTube Courses](https://github.com/dair-ai/ML-YouTube-Courses)
- [Neuromatch Academy Deep Learning (NMA-DL) syllabus](https://github.com/NeuromatchAcademy/course-content-dl)
- [Stanford AI Lab Papers and Talks at CVPR 2021](https://ai.stanford.edu/blog/cvpr-2021/)
- [SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption (2021)](https://arxiv.org/abs/2106.15147)
- [Machine Learning for Beginners - A Curriculum](https://github.com/microsoft/ML-For-Beginners)
- [You Don’t Need Math For Machine Learning (2021)](https://towardsdatascience.com/you-dont-need-math-for-machine-learning-e168b7d973d4)
- [Data Augmentation Resources](https://github.com/AgaMiko/data-augmentation-review)
- [Extremely revealing books that explains everything behind machine learning? (2021)](https://www.reddit.com/r/learnmachinelearning/comments/ofnl9d/extremely_revealing_books_that_explains/)
- [ML@B](https://ml.berkeley.edu/) - Machine Learning at Berkeley.
- [Awesome Graph Self-Supervised Learning](https://github.com/LirongWu/awesome-graph-self-supervised-learning)
- [Contrastive Representation Learning (2021)](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html) ([HN](https://news.ycombinator.com/item?id=27812862))
- [Learn Machine Learning Resources](https://machinelearning.to/)
- [Popular Machine Learning Interview Questions (2021)](https://www.thinkdataanalytics.com/machine-learning-interview-questions/)
- [Solving Machine Learning Performance Anti-Patterns: a Systematic Approach (2021)](https://paulbridger.com/posts/nsight-systems-systematic-optimization/)
- [Bayesian learning via stochastic gradient langevin dynamics (2011)](https://dl.acm.org/doi/10.5555/3104482.3104568)
- [Megaverse: Simulating Embodied Agents at One Million Experiences per Second](https://www.megaverse.info/) ([Paper](https://arxiv.org/abs/2107.08170)) ([Code](https://github.com/alex-petrenko/megaverse))
- [Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them (2021)](https://openreview.net/forum?id=6pgY2PkoXb0) ([Tweet](https://twitter.com/florian_tramer/status/1418911926508216321))
- [Linear unit-tests for invariance discovery (2021)](https://arxiv.org/abs/2102.10867) ([Code](https://github.com/facebookresearch/InvarianceUnitTests))
- [In Search of Lost Domain Generalization (2020)](https://arxiv.org/abs/2007.01434) ([Code](https://github.com/facebookresearch/DomainBed))
- [Understanding and improving out-of-distribution generalisation with Agnieszka Słowik (2021)](https://www.youtube.com/watch?v=W3XE9yD5H4A)
- [Algorithmic Concept-based Explainable Reasoning (2021)](https://arxiv.org/abs/2107.07493) ([Tweet](https://twitter.com/PetarV_93/status/1415937593225760771))
- [Tsinghua Machine Learning Group](https://ml.cs.tsinghua.edu.cn/) ([GitHub](https://github.com/thu-ml))
- [Zero-Shot Learning Resources](https://github.com/sbharadwajj/awesome-zero-shot-learning)
- [Machine Learning Collection](https://github.com/microsoft/machine-learning-collection)
- [Open MLOps – Open-Source Production Machine Learning (2021)](https://datarevenue.com/en-blog/open-mlops-open-source-production-machine-learning) ([HN](https://news.ycombinator.com/item?id=28052182))
- [A Gentle Introduction To Gradient Descent Procedure (2021)](https://machinelearningmastery.com/a-gentle-introduction-to-gradient-descent-procedure/)
- [Stanford MLSys Seminars](https://www.youtube.com/playlist?list=PLSrTvUm384I9PV10koj_cqit9OfbJXEkq)
- [Painless Uncertainty for Deep Learning (2021)](https://www.machinelearningforscience.de/en/painless-uncertainty-for-deep-learning/)
- [How to avoid machine learning pitfalls: a guide for academic researchers (2021)](https://arxiv.org/abs/2108.02497)
- [MLOps-Basics](https://github.com/graviraja/MLOps-Basics)
- [Machine & Deep Learning Compendium](https://book.mlcompendium.com/) ([Code](https://github.com/orico/www.mlcompendium.com))
- [Differentiable Factor Graph Optimization for Learning Smoothers (2021)](https://github.com/brentyi/dfgo)
- [A visual introduction to Gaussian Belief Propagation (2021)](https://gaussianbp.github.io/) ([HN](https://news.ycombinator.com/item?id=28367177))
- [Bootstrap your own latent: A new approach to self-supervised Learning (2020)](https://arxiv.org/abs/2006.07733) ([Code](https://github.com/Spijkervet/BYOL))
- [Tutorial: Performance Engineering for Machine Learning and Scientific Computing (2017)](https://dblalock.github.io/Performance-Engineering-Tutorial/)
- [Must-read papers on Recommender System](https://github.com/hongleizhang/RSPapers)
- [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts (2018)](http://www.kdd.org/kdd2018/accepted-papers/view/modeling-task-relationships-in-multi-task-learning-with-multi-gate-mixture-) ([Code](https://github.com/drawbridge/keras-mmoe))
- [Machine Learning Bookcamp: Build a portfolio of real-life projects (2021)](https://www.manning.com/books/machine-learning-bookcamp) ([Code](https://github.com/alexeygrigorev/mlbookcamp-code))
- [Product Recommendations (2019)](http://bugra.github.io/posts/2019/8/15/product-recommendations/)
- [Stanford CRFM](https://crfm.stanford.edu/) - Stanford Center for Research on Foundation Models. ([GitHub](https://github.com/stanford-crfm))
- [Multi-Task Learning as Multi-Objective Optimization (2019)](https://arxiv.org/abs/1810.04650) ([Code](https://github.com/isl-org/MultiObjectiveOptimization))
- [Hyperparameter Search with spaCy and Weights & Biases (2021)](https://wandb.ai/wandb/wandb_spacy_sweeps/reports/Hyperparameter-Search-with-spaCy-and-Weights-Biases--Vmlldzo5NDA2MjE) ([Tweet](https://twitter.com/_ScottCondron/status/1435981838212911109))
- [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)
- [The Values Encoded in Machine Learning Research (2021)](https://arxiv.org/abs/2106.15590) ([Tweet](https://twitter.com/tdietterich/status/1439666761834459136))
- [An overview of the theory of overparameterized machine learning (2021)](https://arxiv.org/abs/2109.02355)
- [Geometric Deep Learning Blueprint (2021)](https://www.youtube.com/watch?v=bIZB1hIJ4u8)
- [Multi-Armed Bandits and Pure-Exploration (2020)](https://www.youtube.com/watch?v=h-dYzjF8eFA)
- [The First Rule of Machine Learning: Start Without Machine Learning (2021)](https://eugeneyan.com/writing/first-rule-of-ml/) ([HN](https://news.ycombinator.com/item?id=28613099))
- [An Introduction to Weighted Automata in Machine Learning (2021)](https://awnihannun.com/writing/automata_ml.html) ([Code](https://github.com/awni/automata_ml))
- [Ultimate FREE Machine Learning Study Plan](https://github.com/python-engineer/ml-study-plan)
- [node2vec: Scalable Feature Learning for Networks](https://snap.stanford.edu/node2vec/) ([Code](https://github.com/aditya-grover/node2vec))
- [Learning to Superoptimize Real-world Programs (2021)](https://arxiv.org/abs/2109.13498)
- [Data Movement Is All You Need: A Case Study on Optimizing Transformers (2020)](https://arxiv.org/abs/2007.00072) ([Code](https://github.com/spcl/substation))
- [Reading List for Topics in Representation Learning](https://github.com/Mehooz/awesome-representation-learning)
- [Курс по машинному обучению для 3 курса факультета ВМК МГУ (2021)](https://github.com/MSU-ML-COURSE/ML-COURSE-21-22)
- [Deep Learning with Python, Second Edition (2021)](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) ([Code](https://github.com/fchollet/deep-learning-with-python-notebooks))
- [Some ML tools (2021)](https://twitter.com/GaryMarcus/status/1447206961045336066)
- [Unsolved Problems in ML Safety (2021)](https://arxiv.org/abs/2109.13916) ([HN](https://news.ycombinator.com/item?id=28809233))
- [Evaluating Predictive Distributions: Does Bayesian Deep Learning Work? (2021)](https://arxiv.org/abs/2110.04629) ([Code](https://github.com/deepmind/neural_testbed)) ([Tweet](https://twitter.com/DeepMind/status/1447975332489859076))
- [Arsenii Ashukha: Ensemble Generation (2020)](https://www.youtube.com/watch?v=bj933t6rqFw)
- [Imitating Deep Learning Dynamics via Stochastic Differential Equations (2021)](https://arxiv.org/abs/2110.05960) ([HN](https://news.ycombinator.com/item?id=28864171))
- [What are some ideas that are hyped up in machine learning research but don't actually get used in industry (and vice versa)? (2021)](https://www.reddit.com/r/MachineLearning/comments/q86kqn/d_what_are_some_ideas_that_are_hyped_up_in/)
- [Variational Graph Auto-Encoders (2016)](https://arxiv.org/abs/1611.07308) ([Code](https://github.com/DaehanKim/vgae_pytorch))
- [Diffusion Normalizing Flow (2021)](https://arxiv.org/abs/2110.07579)
- [Approximately Correct Machine Intelligence (ACMI) Lab](https://acmilab.org/) - Research on machine learning, its social impacts, and applications to healthcare. ([GitHub](https://github.com/acmi-lab)) ([Twitter](https://twitter.com/acmi_lab))
- [Machine Learning, Kolmogorov Complexity, and Squishy Bunnies (2019)](https://theorangeduck.com/page/machine-learning-kolmogorov-complexity-squishy-bunnies)
- [Fast Machine Learning Lab](https://fastmachinelearning.org/) ([GitHub](https://github.com/fastmachinelearning))
- [Meaning of interpolation in ML (2021)](https://twitter.com/fchollet/status/1450524400227287040)
- [Learning in High Dimension Always Amounts to Extrapolation (2021)](https://arxiv.org/abs/2110.09485) ([Tweet](https://twitter.com/ylecun/status/1450560732483948545))
- [Awesome Transformer Architecture Search](https://github.com/automl/awesome-transformer-search)
- [Katana ML Skipper](https://github.com/katanaml/katana-skipper) - Simple and flexible ML workflow engine. It helps to orchestrate events across a set of microservices and create executable flow to handle requests.
- [PaRoT: A Practical Framework for Robust Deep Neural Network Training (2021)](https://arxiv.org/abs/2001.02152)
- [Superposition of many models into one (2019)](https://arxiv.org/abs/1902.05522) ([Tweet](https://twitter.com/thisismyhat/status/1096480539601657856))
- [Meta-Learning Requires Meta-Augmentation (2020)](https://arxiv.org/abs/2007.05549)
- [Shaking the foundations: delusions in sequence models for interaction and control (2021)](https://arxiv.org/abs/2110.10819) ([Tweet](https://twitter.com/janexwang/status/1453027447151157251))
- [Introduction to Deep Learning (I2DL) (2021)](https://www.youtube.com/playlist?list=PLQ8Y4kIIbzy_OaXv86lfbQwPHSomk2o2e)
- [Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data (2021)](https://arxiv.org/abs/2110.15094) ([Code](https://github.com/zju-vipa/MosaicKD))
- [Advanced-Foundations-of-ML](https://github.com/yashsavani/Advanced-Foundations-of-ML)
- [Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions (2021)](https://arxiv.org/abs/2106.01798) ([Code](https://github.com/uclnlp/torch-imle))
- [Deep Learning Recommendation Model for Personalization and Recommendation Systems](https://github.com/facebookresearch/dlrm)
- [MLflow Examples](https://github.com/amesar/mlflow-examples)
- [8-bit Optimizers via Block-wise Quantization (2021)](https://arxiv.org/abs/2110.02861) ([Code](https://github.com/facebookresearch/bitsandbytes))
- [Efficiently Modeling Long Sequences with Structured State Spaces (2021)](https://arxiv.org/abs/2111.00396) ([Code](https://github.com/HazyResearch/state-spaces))
- [Get started with JAX](https://github.com/gordicaleksa/get-started-with-JAX) ([Videos](https://www.youtube.com/playlist?list=PLBoQnSflObckOARbMK9Lt98Id0AKcZurq))
- [How does Jax allocate memory on a TPU? An interactive C++ walkthrough](https://gist.github.com/shawwn/0e524d4a7a5d8fb152a86616559cc02a) ([HN](https://news.ycombinator.com/item?id=29128998))
- [Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström Method (2021)](https://arxiv.org/abs/2111.00035) ([Code](https://github.com/pkuzengqi/Skyformer))
- [Introduction to Deep Learning (2021)](https://sebastianraschka.com/blog/2021/dl-course.html) - 170 Video Lectures from Adaptive Linear Neurons to Zero-shot Classification with Transformers.
- [Gradients are Not All You Need (2021)](https://arxiv.org/abs/2111.05803) ([Tweet](https://twitter.com/Luke_Metz/status/1458661090326286336)) ([HN](https://news.ycombinator.com/item?id=35677776))
- [FC2T2: The Fast Continuous Convolutional Taylor Transform with Applications in Vision and Graphics (2021)](https://arxiv.org/abs/2111.00110) ([Summary](https://www.youtube.com/watch?v=e6gXoMA5te4))
- [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modelingvon (2018)](https://arxiv.org/abs/1803.01271) ([Code](https://github.com/locuslab/TCN))
- [Model compression via distillation and quantization (2019)](https://arxiv.org/abs/1802.05668) ([Code](https://github.com/antspy/quantized_distillation))
- [ML Collective](https://mlcollective.org/) - Independent, nonprofit organization with a mission to make research opportunities accessible and free. ([Classics and Trends](https://mlcollective.org/dlct/))
- [Awesome MLOps](https://github.com/kelvins/awesome-mlops)
- [Machine Learning Zoomcamp](https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp) ([Code](https://github.com/ziritrion/ml-zoomcamp))
- [Yann LeCun’s 2021 Deep Learning Course at CDS (2021)](https://cds.nyu.edu/deep-learning/) ([HN](https://news.ycombinator.com/item?id=29218520))
- [Interactive Gradient Descent Demo (2021)](https://blog.skz.dev/gradient-descent)
- [Why Momentum Really Works (2017)](https://distill.pub/2017/momentum/)
- [HNPE: Leveraging Global Parameters for Neural Posterior Estimation (2021)](https://arxiv.org/abs/2102.06477) ([Tweet](https://twitter.com/plc_rodrigues/status/1460654220944809986))
- [Facebook AI Similarity Search (Faiss)](https://www.pinecone.io/learn/faiss-tutorial/) ([HN](https://news.ycombinator.com/item?id=29291047))
- [Combined Scaling for Zero-shot Transfer Learning (2021)](https://arxiv.org/abs/2111.10050)
- [Awesome Distributed Deep Learning](https://github.com/bharathgs/Awesome-Distributed-Deep-Learning)
- [Neuro Evolution Of Augmented Topologies (2021)](https://fev.al/posts/neat/) ([HN](https://news.ycombinator.com/item?id=29296158))
- [machine-config-operator](https://github.com/openshift/machine-config-operator) - Managing updates and configuration changes to essentially everything between the kernel and kubelet.
- [Factorized Fourier Neural Operators (2021)](https://arxiv.org/abs/2111.13802) ([Code](https://github.com/alasdairtran/fourierflow))
- [NeurIPS 2021 Best Paper Awards (2021)](https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/)
- [What areas of deep learning are under-explored? (2021)](https://www.reddit.com/r/MachineLearning/comments/r9yzub/d_in_your_opinion_what_areas_of_deep_learning_are/)
- [cnvrg.io](https://cnvrg.io/) - Full Stack Machine Learning Operating System.
- [Learning with not Enough Data Part 1: Semi-Supervised Learning (2021)](https://lilianweng.github.io/lil-log/2021/12/05/semi-supervised-learning.html) ([HN](https://news.ycombinator.com/item?id=29456732))
- [Efficient Training of Audio Transformers with Patchout (2021)](https://arxiv.org/abs/2110.05069) ([Code](https://github.com/kkoutini/PaSST))
- [Machine Learning for Creativity and Design](https://neuripscreativityworkshop.github.io/2021/)
- [Maximum Likelihood Training of Score-Based Diffusion Models (2021)](https://arxiv.org/abs/2101.09258) ([Code](https://github.com/yang-song/score_flow))
- [Learning Gradient Fields for Shape Generation (2020)](http://www.cs.cornell.edu/~ruojin/ShapeGF/) ([Code](https://github.com/RuojinCai/ShapeGF))
- [Making Friends with Machine Learning - YouTube](https://www.youtube.com/playlist?list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG)
- [Schedule - NeurIPS 2021](https://deepmind.events/events/neurips2021/resources)
- [The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization (2021)](https://arxiv.org/abs/2110.07732) ([Code](https://github.com/RobertCsordas/ndr))
- [Momentum Residual Neural Networks (2021)](https://arxiv.org/abs/2102.07870) ([Code](https://github.com/michaelsdr/momentumnet))
- [Awesome-Zero-Shot-Learning](https://github.com/WilliamYi96/Awesome-Zero-Shot-Learning)
- [Awesome Treasure of Transformers Models Collection](https://github.com/ashishpatel26/Treasure-of-Transformers)
- [Self-attention Does Not Need $O(n^2)$ Memory (2021)](https://arxiv.org/abs/2112.05682v2) ([Code](https://github.com/AminRezaei0x443/memory-efficient-attention)) ([Code](https://github.com/lucidrains/memory-efficient-attention-pytorch))
- [Neural Discrete Representation Learning (2021)](https://arxiv.org/abs/1711.00937) ([Code](https://github.com/MishaLaskin/vqvae))
- [VSE++: Improving Visual-Semantic Embeddings with Hard Negatives (2018)](https://arxiv.org/abs/1707.05612) ([Code](https://github.com/fartashf/vsepp))
- [JAX ResNet](https://github.com/n2cholas/jax-resnet) - Implementations and checkpoints for ResNet, Wide ResNet, ResNeXt, ResNet-D, and ResNeSt in JAX (Flax).
- [Best AI and Deep learning books to read in 2022](https://theaisummer.com/deep-learning-books-2022/)
- [Machine Learning for Combinatorial Optimization - NeurIPS 2021 Competition](https://www.ecole.ai/2021/ml4co-competition/) ([Code](https://github.com/ds4dm/ml4co-competition))
- [Tutorial and Summary of Machine Learning](https://github.com/zchen0211/ML-tutorial)
- [Never Give Up: Learning Directed Exploration Strategies (2020)](https://arxiv.org/abs/2002.06038) ([Code](https://github.com/Coac/never-give-up))
- [A Step Toward Quantifying Independently Reproducible Machine Learning Research (2019)](https://arxiv.org/abs/1909.06674) ([Tweet](https://twitter.com/_onionesque/status/1476769719256498177))
- [ML Hub](https://github.com/ml-tooling/ml-hub) - Multi-user development platform for machine learning teams. Simple to setup within minutes.
- [Adversarial Explainable AI](https://github.com/hbaniecki/adversarial-explainable-ai)
- [AI/ML Tutorials List](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials)
- [Awesome Diffusion Models](https://github.com/heejkoo/Awesome-Diffusion-Models)
- [Autoencoder-based deep metric learning for network intrusion detection (2021)](https://www.sciencedirect.com/science/article/abs/pii/S002002552100462X) ([Code](https://github.com/gsndr/RENOIR))
- [Graph Adversarial Learning Literature](https://github.com/safe-graph/graph-adversarial-learning-literature)
- [Trustworthy Machine Learning by Kush R. Varshney](http://www.trustworthymachinelearning.com/)
- [Recommender System Suits](https://github.com/hongleizhang/RSAlgorithms) - Open source toolkit for recommender system.
- [Randomized Ensembled Double Q-Learning: Learning Fast Without a Model (2021)](https://arxiv.org/abs/2101.05982) ([Code](https://github.com/watchernyu/REDQ))
- [STATS320: Machine Learning Methods for Neural Data Analysis Course (2021)](https://github.com/slinderman/stats320)
- [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (2021)](https://arxiv.org/abs/2201.00650) ([Code](https://github.com/BoltzmannEntropy/interviews.ai)) ([HN](https://news.ycombinator.com/item?id=29876742))
- [Diffusion-Models-Seminar](https://github.com/sangyun884/Diffusion-Models-Seminar)
- [Awesome Graph Representation Learning](https://github.com/kaiyuanzh/awesome-graph-representation-learning)
- [Machine Learning System Resources (2022)](https://www.bodunhu.com/blog/posts/machine-learning-system-resources/)
- [Dynamic Tensor Rematerialization (2021)](https://arxiv.org/abs/2006.09616) ([Review](https://www.bodunhu.com/blog/posts/paper-review-dynamic-tensor-rematerialization/))
- [Designing a Practical Degradation Model for Deep Blind Image Super-Resolution (2021)](https://arxiv.org/abs/2103.14006) ([Code](https://github.com/cszn/BSRGAN))
- [A Theoretical Framework for Target Propagation (2020)](https://arxiv.org/abs/2006.14331) ([Code](https://github.com/meulemansalex/theoretical_framework_for_target_propagation))
- [SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks (2020)](https://arxiv.org/abs/2006.10503) ([Code](https://github.com/FabianFuchsML/se3-transformer-public))
- [Iterative SE(3)-Transformers (2021)](https://arxiv.org/abs/2102.13419) ([Article](https://fabianfuchsml.github.io/se3iterative/))
- [Permutation Invariance, DeepSets and Universal Function Approximation](https://fabianfuchsml.github.io/permutationinvariance/)
- [Review: Deep Learning on Sets](https://fabianfuchsml.github.io/learningonsets/)
- [Contrastive Self-Supervised Learning (2020)](https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html)
- [Top AI Conference Papers with Code](https://github.com/MLNLP-World/Top-AI-Conferences-Paper-with-Code)
- [Awesome Deep Learning papers for industrial Search, Recommendation and Advertising](https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising)
- [Deep Multi-attribute Graph Representation Learning on Protein Structures (2020)](https://arxiv.org/abs/2012.11762)
- [Variational Diffusion Models (2021)](https://arxiv.org/abs/2107.00630) ([Code](https://github.com/yoyololicon/variational-diffwave))
- [Cheat sheet for the "Deep Learning" course at ETH Zürich](https://github.com/andbloch/eth-dl-cheat-sheet)
- [Convolutional Networks on Graphs for Learning Molecular Fingerprints (2015)](https://arxiv.org/abs/1509.09292) ([Code](https://github.com/HIPS/neural-fingerprint))
- [Cheatsheet for the Advanced Machine Learning Lecture 2020, ETH Zurich](https://github.com/veroniquek/aml_cheatsheet/blob/main/cheatsheet.pdf)
- [Tutorial on amortized optimization for learning to optimize over continuous domains (2022)](https://arxiv.org/abs/2202.00665) ([Code](https://github.com/facebookresearch/amortized-optimization-tutorial))
- [Growing 3D Artefacts and Functional Machines with Neural Cellular Automata (2021)](https://arxiv.org/abs/2103.08737) ([Code](https://github.com/real-itu/3d-artefacts-nca))
- [Generative Flow Networks for Discrete Probabilistic Modeling (2022)](https://arxiv.org/abs/2202.01361) ([Code](https://github.com/zdhNarsil/EB_GFN))
- [Awesome Contrastive Learning](https://github.com/asheeshcric/awesome-contrastive-self-supervised-learning)
- [ML-fairness-gym](https://github.com/google/ml-fairness-gym) - Components for building simple simulations that explore the potential long-run impacts of deploying machine learning-based decision systems in social environments.
- [MultiBench: Multiscale Benchmarks for Multimodal Representation Learning](https://github.com/pliang279/MultiBench)
- [Learning Features with Parameter-Free Layers (2022)](https://github.com/naver-ai/PfLayer)
- [Gaussian Processes for Machine Learning: Book](http://www.gaussianprocess.org/gpml/)
- [IQ-Learn: Inverse soft-Q Learning for Imitation (2021)](https://arxiv.org/abs/2106.12142) ([Code](https://github.com/Div99/IQ-Learn))
- [On Neural Differential Equations (2022)](https://arxiv.org/abs/2202.02435) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/snmtzn/r_phd_thesis_on_neural_differential_equations/)) ([Tweet](https://twitter.com/PatrickKidger/status/1491069456185200640))
- [Datamodels: Predicting Predictions from Training Data (2022)](https://arxiv.org/abs/2202.00622) ([Data](https://github.com/MadryLab/datamodels-data))
- [Understanding Black-box Predictions via Influence Functions (2020)](https://arxiv.org/abs/1703.04730) ([PyTorch Code](https://github.com/nimarb/pytorch_influence_functions))
- [Parameter Prediction for Unseen Deep Architectures (NeurIPS 2021)](https://github.com/facebookresearch/ppuda)
- [Language-Agnostic Representation Learning of Source Code from Structure and Context (2021)](https://arxiv.org/abs/2103.11318) ([Code](https://github.com/danielzuegner/code-transformer))
- [Machine Learning Open Source University](https://github.com/d0r1h/ML-University)
- [Exploring hyperparameter meta-loss landscapes with Jax (2021)](http://lukemetz.com/exploring-hyperparameter-meta-loss-landscapes-with-jax/)
- [Transformers Can Do Bayesian Inference (2022)](https://arxiv.org/abs/2112.10510)
- [Norm-based Analysis of Transformer](https://github.com/gorokoba560/norm-analysis-of-transformer) - Implementations for 2 papers introducing to analyze Transformers using vector norms.
- [Point-NeRF: Point-based Neural Radiance Fields (2022)](https://xharlie.github.io/projects/project_sites/pointnerf/index.html) ([Code](https://github.com/Xharlie/pointnerf))
- [ML training compute has been doubling every 6 months since 2010](https://twitter.com/ohlennart/status/1493521176286609412) ([HN](https://news.ycombinator.com/item?id=30348925))
- [Using JAX in 2022](https://www.assemblyai.com/blog/why-you-should-or-shouldnt-be-using-jax-in-2022/) ([HN](https://news.ycombinator.com/item?id=30349687))
- [Should We Be Using JAX in 2022?](https://www.reddit.com/r/MachineLearning/comments/st8b11/d_should_we_be_using_jax_in_2022/)
- [Parallel Computing and Scientific Machine Learning (SciML): Methods and Applications](https://book.sciml.ai/) ([Code](https://github.com/SciML/SciMLBook))
- [Awesome Neural ODE](https://github.com/Zymrael/awesome-neural-ode) - Resources regarding the interplay between differential equations, deep learning, dynamical systems, control and numerical methods.
- [LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes (2021)](https://arxiv.org/abs/2106.01487) ([Code](https://github.com/RAIVNLab/LLC))
- [TinyML Paper and Projects](https://github.com/gigwegbe/tinyml-papers-and-projects)
- [Multiplicative Filter Networks (2021)](https://openreview.net/forum?id=OmtmcPkkhT) ([Code](https://github.com/boschresearch/multiplicative-filter-networks))
- [Class-incremental learning: survey and performance evaluation on image classification (2020)](https://arxiv.org/abs/2010.15277) ([Code](https://github.com/mmasana/FACIL))
- [Appendix: More Is Different In Other Domains (2022)](https://bounded-regret.ghost.io/appendix-more-is-different-in-related-fields/)
- [Robustness and Accuracy Could Be Reconcilable by (Proper) Definition (2022)](https://arxiv.org/abs/2202.10103) ([Code](https://github.com/P2333/SCORE))
- [Nebullvm](https://github.com/nebuly-ai/nebullvm) - All-in-one library for easy-to-use DL compilers.
- [SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies (2021)](https://arxiv.org/abs/2106.09678) ([Code](https://github.com/LinxiFan/SECANT))
- [Open Platform for AI (OpenPAI)](https://github.com/microsoft/pai) - Resource scheduling and cluster management for AI.
- [Hugging Face Optimum](https://github.com/huggingface/optimum) - Accelerate Transformer models for training and inference on targeted hardware. ([Tweet](https://twitter.com/Thom_Wolf/status/1496768744747532290))
- [Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces (2022)](https://arxiv.org/abs/2202.10613) ([Tweet](https://twitter.com/avt_im/status/1496453031960981514))
- [What's hot for Machine Learning Research in 2022?](https://www.reddit.com/r/MachineLearning/comments/t04ekm/d_whats_hot_for_machine_learning_research_in_2022/)
- [Machine Learning with PyTorch and Scikit-Learn (2022)](https://sebastianraschka.com/blog/2022/ml-pytorch-book.html) ([HN](https://news.ycombinator.com/item?id=30473254)) ([Author AMA](https://www.reddit.com/r/MachineLearning/comments/t6lcyz/hey_all_im_sebastian_raschka_author_of_machine/))
- [General Cyclical Training of Neural Networks (2022)](https://arxiv.org/abs/2202.08835) ([Code](https://github.com/lnsmith54/CFL))
- [Machine Learning Interview Questions](https://github.com/andrewekhalel/MLQuestions)
- [Intro to Continual Learning](https://github.com/clam004/intro_continual_learning)
- [Gradients without Backpropagation (2022)](https://arxiv.org/abs/2202.08587) ([HN](https://news.ycombinator.com/item?id=30525214))
- [Variational Autoencoders Without the Variation (2022)](https://arxiv.org/abs/2203.00645)
- [What's your favorite unpopular/forgotten Machine Learning method? (2022)](https://www.reddit.com/r/MachineLearning/comments/t55lbw/d_whats_your_favorite_unpopularforgotten_machine/)
- [Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels (2022)](https://machinelearning.apple.com/research/generalizing-confusion-matrix) ([Tweet](https://twitter.com/_jgoertler/status/1499139488693604362))
- [Probabilistic Machine Learning: Advanced Topics](https://probml.github.io/pml-book/book2.html) ([Code](https://github.com/probml/pml2-book))
- [AST: Audio Spectrogram Transformer (2021)](https://arxiv.org/abs/2104.01778) ([Code](https://github.com/YuanGongND/ast))
- [Practical Machine Learning](https://github.com/eugenesiow/practical-ml) - Learn by experimenting on state-of-the-art machine learning models and algorithms.
- [Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer (2022)](https://arxiv.org/abs/2203.03466) ([Code](https://github.com/microsoft/mup))
- [Optimization for machine learning course (2022)](https://edu.epfl.ch/coursebook/en/optimization-for-machine-learning-CS-439) ([Code](https://github.com/epfml/OptML_course))
- [Awesome Long-Tailed Learning](https://github.com/Stomach-ache/awesome-long-tail-learning)
- [Offline Reinforcement Learning as One Big Sequence Modeling Problem (2021)](https://arxiv.org/abs/2106.02039) ([Code](https://github.com/jannerm/trajectory-transformer))
- [Deep Learning’s New Infrastructure (2022)](https://mirror.xyz/gensyn.eth/0SHaOYVPhATdTfw8Ypixoln_G5HF_NcVz9gEI7AXLTw)
- [Gensyn](https://www.gensyn.ai/) - Hyperscale, cost-efficient compute protocol for the world's deep learning models. ([Twitter](https://twitter.com/gensynai))
- [Software Engineering for AI/ML -- An Annotated Bibliography](https://github.com/ckaestne/seaibib)
- [Physics-Based Deep Learning](https://github.com/thunil/Physics-Based-Deep-Learning)
- [Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation (2019)](https://arxiv.org/abs/1905.08094) ([Code](https://github.com/luanyunteng/pytorch-be-your-own-teacher))
- [Tensil](https://www.tensil.ai/) - Open-Source ML Accelerators. ([HN](https://news.ycombinator.com/item?id=30643520)) ([Code](https://github.com/tensil-ai/tensil))
- [Ask HN: What ML platform are you using? (2022)](https://news.ycombinator.com/item?id=30658324)
- [Graphsignal](https://graphsignal.com/) - Machine Learning Profiler. ([HN](https://news.ycombinator.com/item?id=30628618))
- [Machine Learning and AI with Go](https://github.com/dwhitena/gc-ml)
- [Everything about Transfer Learning](https://github.com/jindongwang/transferlearning)
- [Making Deep Learning Go Brrrr From First Principles](https://horace.io/brrr_intro.html)
- [Machine Learning Guide](https://github.com/mikeroyal/Machine-Learning-Guide)
- [Building a ML Transformer in a Spreadsheet (2022)](https://www.youtube.com/watch?v=S9eKuRVigjY)
- [Lecture Notes for Machine Learning Theory (2021)](https://github.com/tengyuma/cs229m_notes/blob/main/master.pdf)
- [On Embeddings for Numerical Features in Tabular Deep Learning (2022)](https://arxiv.org/abs/2203.05556) ([Code](https://github.com/Yura52/tabular-dl-num-embeddings))
- [Automated Machine Learning in Action Book (2022)](https://www.manning.com/books/automated-machine-learning-in-action) ([Code](https://github.com/datamllab/automl-in-action-notebooks))
- [ML Course Notes](https://github.com/dair-ai/ML-Course-Notes)
- [The Mathematics of Artificial Intelligence (2022)](https://arxiv.org/abs/2203.08890)
- [Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision (2021)](https://arxiv.org/abs/2105.04019) ([Code](https://github.com/Felix-Petersen/diffsort))
- [Fast TreeSHAP: Accelerating SHAP Value Computation for Trees (2021)](https://arxiv.org/abs/2109.09847) ([Code](https://github.com/linkedin/FastTreeSHAP))
- [Memorizing Transformers (2022)](https://arxiv.org/abs/2203.08913) ([Code](https://github.com/lucidrains/memorizing-transformers-pytorch)) ([HN](https://news.ycombinator.com/item?id=31448360))
- [DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents (2022)](https://arxiv.org/abs/2201.00308) ([Code](https://github.com/kpandey008/DiffuseVAE))
- [Metarank](https://www.metarank.ai/) - Low-code Machine Learning personalization service. ([Code](https://github.com/metarank/metarank)) ([HN](https://news.ycombinator.com/item?id=30778100))
- [Research on Tabular Deep Learning](https://github.com/Yura52/rtdl)
- [HuggingFace Blog](https://huggingface.co/blog) ([Code](https://github.com/huggingface/blog))
- [Learning to Prompt for Continual Learning (2022)](https://arxiv.org/abs/2112.08654) ([Code](https://github.com/google-research/l2p))
- [Group Equivariant Deep Learning (2022)](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd) ([Tweet](https://twitter.com/erikjbekkers/status/1507807031088062470))
- [Human-Centered Machine Learning (2022)](https://github.com/ChicagoHAI/human-centered-machine-learning)
- [Transformer models: an introduction and catalog — 2022 Edition](https://xamat.medium.com/transformers-models-an-introduction-and-catalogue-2022-edition-2d1e9039f376)
- [Bayesian Structure Learning with Generative Flow Networks (2022)](https://arxiv.org/abs/2202.13903) ([Code](https://github.com/tristandeleu/jax-dag-gflownet))
- [Neural Networks with Recurrent Generative Feedback (2020)](https://arxiv.org/abs/2007.09200) ([Code](https://github.com/yjhuangcd/CNNF))
- [Coursera Machine Learning MOOC by Andrew Ng](https://www.coursera.org/learn/machine-learning) ([Code](https://github.com/dibgerge/ml-coursera-python-assignments))
- [Chaos is a Ladder: A New Understanding of Contrastive Learning (2022)](https://openreview.net/pdf?id=ECvgmYVyeUz) ([Code](https://github.com/zhangq327/ARC))
- [Efficient-VDVAE: Less is more (2022)](https://arxiv.org/abs/2203.13751) ([Code](https://github.com/Rayhane-mamah/Efficient-VDVAE))
- [Transformer Quality in Linear Time (2022)](https://arxiv.org/abs/2202.10447) ([Code](https://github.com/lucidrains/FLASH-pytorch))
- [Machine Learning for Big Code and Naturalness](https://ml4code.github.io/) - Survey of Machine Learning for Big Code and Naturalness. ([Code](https://github.com/ml4code/ml4code.github.io))
- [Randomized Smoothing of All Shapes and Sizes (2020)](https://decentdescent.org/rs4a1.html) ([Code](https://github.com/tonyduan/rs4a))
- [Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems (2021)](https://arxiv.org/abs/2109.15142) ([Code](https://github.com/LCS2-IIITD/TransEvolve))
- [Deep Maths - machine learning and mathematics (2022)](https://www.youtube.com/watch?v=wbJQTtjlM_w)
- [Manim Machine Learning](https://github.com/helblazer811/ManimMachineLearning) - Focused on providing animations and visualizations of common machine learning concepts with the Manim Community Library.
- [Anyscale](https://www.anyscale.com/) - Effortlessly develop, scale and deploy AI, at any scale. ([GitHub](https://github.com/anyscale))
- [Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting (2021)](https://arxiv.org/abs/2106.13008) ([Code](https://github.com/thuml/Autoformer))
- [On the Bottleneck of Graph Neural Networks and its Practical Implications (2021)](https://arxiv.org/abs/2006.05205) ([Code](https://github.com/tech-srl/bottleneck))
- [ML Notebooks](https://github.com/dair-ai/ML-Notebooks) - Series of code examples for all sorts of machine learning tasks and applications.
- [Awesome Semi-Supervised Learning](https://github.com/yassouali/awesome-semi-supervised-learning)
- [FedScale: Benchmarking Model and System Performance of Federated Learning at Scale (2021)](https://arxiv.org/abs/2105.11367) ([Code](https://github.com/SymbioticLab/FedScale))
- [Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting (2021)](https://arxiv.org/abs/2010.04456) ([Code](https://github.com/yuan-yin/APHYNITY))
- [Understand transformer architectures (2022)](https://twitter.com/michael_nielsen/status/1511853865150287873)
- [The Future of Machine Learning Tools (2021)](https://skok.ai/machine%20learning/tools/2021/12/06/the-future-of-machine-learning-tools.html)
- [Transformers Are All You Need: Quick tour through the most popular Neural Net architecture (2022)](https://www.pinecone.io/learn/transformers/)
- [Transformers in Time Series](https://github.com/qingsongedu/time-series-transformers-review) - Curated list of awesome resources (paper, code, data, etc.) on transformers in time series.
- [SRBench: A Living Benchmark for Symbolic Regression (2022)](https://cavalab.org/srbench/) ([Code](https://github.com/cavalab/srbench))
- [How FAANG etc. architect their recommendation systems at scale](https://blog.fennel.ai/p/real-world-recommendation-system)
- [BigScience Research Workshop](https://bigscience.huggingface.co/)
- [SmallScience](https://github.com/SeanNaren/SmallScience) - My journey to training a large(ish) transformer model.
- [Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks (TSSL-BP)](https://proceedings.neurips.cc/paper/2020/hash/8bdb5058376143fa358981954e7626b8-Abstract.html) ([Code](https://github.com/stonezwr/TSSL-BP))
- [Recommender Systems, Not Just Recommender Models (2022)](https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e)
- [Reading Lists of Machine Learning, Natural Language Processing and etc.](https://github.com/IsaacChanghau/DL-NLP-Readings)
- [Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions (2021)](https://arxiv.org/abs/2102.05379) ([Code](https://github.com/didriknielsen/argmax_flows)) ([Code](https://github.com/ehoogeboom/multinomial_diffusion))
- [The Principles of Deep Learning Theory (2021)](https://arxiv.org/abs/2106.10165) ([HN](https://news.ycombinator.com/item?id=31051540))
- [Understanding the Limitations of Variational Mutual Information Estimators (2019)](https://arxiv.org/abs/1910.06222) ([Code](https://github.com/ermongroup/smile-mi-estimator))
- [Tensor Puzzles](https://github.com/srush/Tensor-Puzzles) - Solve puzzles. Improve your PyTorch. ([Tweet](https://twitter.com/srush_nlp/status/1516066504885915655))
- [ACM FAccT - 2022 Accepted Papers](https://facctconference.org/2022/acceptedpapers.html)
- [How Attention works, in the field of artificial intelligence](https://github.com/lucidrains/attention)
- [Awesome Weak-Shot Learning](https://github.com/bcmi/Awesome-Weak-Shot-Learning)
- [Ultimate Awesome Transformer Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)
- [What are Diffusion Models? (2022)](https://www.youtube.com/watch?v=fbLgFrlTnGU)
- [Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization (2020)](https://arxiv.org/abs/2009.13586)
- [Awesome Conformal Prediction](https://github.com/valeman/awesome-conformal-prediction)
- [The Machine Learning Job Market (2022)](https://evjang.com/2022/04/25/rome.html) ([HN](https://news.ycombinator.com/item?id=31155782))
- [Admin-Torch](https://github.com/microsoft/admin-torch) - Understanding the Difficulty of Training Transformers.
- [Sampling with Mirrored Stein Operators (2022)](https://arxiv.org/abs/2106.12506) ([Code](https://github.com/thjashin/mirror-stein-samplers)) ([Tweet](https://twitter.com/thjashin/status/1518973853678153728))
- [data2vec and the future of multimodal learning (2022)](https://towardsdatascience.com/data2vec-and-the-future-of-multimodal-learning-f33f9c781f48)
- [Mapping Fair ML](https://github.com/summerscope/mapping-fair-ml) - Curated list of links and resources for Fair ML and Data Ethics.
- [Open Source MLOps](https://github.com/fuzzylabs/awesome-open-mlops) - Fuzzy Labs guide to the universe of free and open source MLOps tools.
- [Why train when you can optimize?](https://justinmeiners.github.io/why-train-when-you-can-optimize/) ([HN](https://news.ycombinator.com/item?id=31205689)) ([Code](https://github.com/justinmeiners/why-train-when-you-can-optimize))
- [Data Engineering & Machine Learning Knowledge Hub](https://github.com/abhishek-ch/around-dataengineering)
- [Graph Contrastive Learning with Augmentations (2020)](https://arxiv.org/abs/2010.13902) ([Code](https://github.com/Shen-Lab/GraphCL))
- [Pseudo Numerical Methods for Diffusion Models on Manifolds (2022)](https://openreview.net/forum?id=PlKWVd2yBkY) ([Code](https://github.com/luping-liu/PNDM))
- [Practical MLOps Book (2021)](https://www.oreilly.com/library/view/practical-mlops/9781098103002/) ([Code](https://github.com/paiml/practical-mlops-book))
- [Disco Diffusion](https://github.com/alembics/disco-diffusion) - Notebooks, models and techniques for the generation of AI Art and Animations.
- [The Annotated Transformer: Attention is All You Need](http://nlp.seas.harvard.edu/annotated-transformer/) ([Code](https://github.com/harvardnlp/annotated-transformer))
- [Metaseq](https://github.com/facebookresearch/metaseq) - Codebase for working with Open Pre-trained Transformers.
- [Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders (2022)](https://arxiv.org/abs/2203.12742) ([Code](https://github.com/samuelstanton/lambo))
- [Learning with Noisy Labels](https://github.com/weijiaheng/Advances-in-Label-Noise-Learning)
- [Pathways: Asynchronous Distributed Dataflow for ML (2022)](https://arxiv.org/abs/2203.12533) ([Pathways: Google's New ML System](https://www.bodunhu.com/blog/posts/pathways-googles-new-ml-system/))
- [Google AI Blog: Alpa: Automated Model-Parallel Deep Learning (2022)](https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html)
- [Compositional Attention: Disentangling Search and Retrieval (2021)](https://arxiv.org/abs/2110.09419) ([Code](https://github.com/sarthmit/Compositional-Attention)) ([Code](https://github.com/lucidrains/compositional-attention-pytorch)) ([Code](https://github.com/Rishit-dagli/Compositional-Attention))
- [Awesome Active Learning](https://github.com/baifanxxx/awesome-active-learning)
- [Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning (2022)](https://arxiv.org/abs/2205.05638) ([Code](https://github.com/r-three/t-few))
- [Introduction to Diffusion Models for Machine Learning (2022)](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/) ([HN](https://news.ycombinator.com/item?id=31355812))
- [BGU-CS-VIL/DeepDPM: "DeepDPM: Deep Clustering With An Unknown Number of Clusters" (2022)](https://arxiv.org/abs/2203.14309) ([Code](https://github.com/BGU-CS-VIL/DeepDPM))
- [Towards a Learning-Based Query Optimizer (2022)](https://engineering.databloom.ai/2022/05/towards-learning-based-query-optimizer.html) ([HN](https://news.ycombinator.com/item?id=31376141))
- [Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework (2021)](https://arxiv.org/abs/2106.09121)
- [Data Distributional Properties Drive Emergent Few-Shot Learning in Transformers (2022)](https://arxiv.org/abs/2205.05055) ([Tweet](https://twitter.com/scychan_brains/status/1526514761579614209))
- [Machine Learning Specialization - DeepLearning.AI](https://www.deeplearning.ai/program/machine-learning-specialization/) ([HN](https://news.ycombinator.com/item?id=31435801))
- [MLU-Explain](https://mlu-explain.github.io/) - Visual explanations of core machine learning concepts. ([HN](https://news.ycombinator.com/item?id=31455919))
- [Planning with Diffusion for Flexible Behavior Synthesis (2022)](https://diffusion-planning.github.io/) ([Code](https://github.com/jannerm/diffuser))
- [Solutions to Recommender Systems competitions](https://github.com/NVIDIA-Merlin/competitions)
- [Recipe for a General, Powerful, Scalable Graph Transformer (2022)](https://arxiv.org/abs/2205.12454) ([Code](https://github.com/rampasek/GraphGPS))
- [How to properly handle hyperparameter configs in ML repos (2022)](https://twitter.com/karpathy/status/1528808361558306817)
- [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness (2022)](https://arxiv.org/abs/2205.14135) ([Code](https://github.com/HazyResearch/flash-attention))
- [Machine Learning Design patterns](https://github.com/msaroufim/ml-design-patterns) - Software Architecture for ML engineers.
- [Hopular: Modern Hopfield Networks for Tabular Data (2022)](https://arxiv.org/abs/2206.00664) ([Code](https://github.com/ml-jku/hopular))
- [Some thoughts on machine learning with small data (2022)](https://niklasriewald.com/2022/06/02/some-thoughts-on-machine-learning-with-small-data/) ([HN](https://news.ycombinator.com/item?id=31592769))
- [Most elegant/beautiful ideas in ML? (2022)](https://twitter.com/banburismus_/status/1532747777280593920)
- [Apple Silicon DL benchmarks](https://github.com/tcapelle/apple_m1_pro_python) - Collection of ML scripts to test the M1 Pro MacBook Pro.
- [Post-Modern ML Stack](https://github.com/jacopotagliabue/post-modern-stack)
- [Improving Discrete Latent Representations With Differentiable Approximation Bridges (2019)](https://arxiv.org/abs/1905.03658) ([Code](https://github.com/apple/ml-dab))
- [Semantic Search and GIFs](https://www.pinecone.io/learn/gif-search/) ([HN](https://news.ycombinator.com/item?id=31652839))
- [Materials for workshops on the Hugging Face ecosystem](https://github.com/huggingface/workshops)
- [Deploying Transformers on the Apple Neural Engine (2022)](https://machinelearning.apple.com/research/neural-engine-transformers) ([HN](https://news.ycombinator.com/item?id=31666476))
- [A comprehensive review of Binary Neural Network (2022)](https://arxiv.org/abs/2110.06804)
- [Self-organising Systems from Google](https://github.com/google-research/self-organising-systems)
- [Improved Denoising Diffusion Probabilistic Models (2021)](https://arxiv.org/abs/2102.09672) ([Code](https://github.com/openai/improved-diffusion))
- [What topics to learn to get 'cutting edge AI' (2022)](https://twitter.com/dan_abramov/status/1536095971779788802)
- [Probability flow solution of the Fokker-Planck equation (2022)](https://arxiv.org/abs/2206.04642)
- [Review of latest Score Based Generative Modeling papers](https://scorebasedgenerativemodeling.github.io/) - All diffusion papers reverse chronological.
- [Intro resources on diffusion/score-matching models (2022)](https://twitter.com/Thom_Wolf/status/1536263780568547328)
- [Meta Optimal Transport (2022)](https://arxiv.org/abs/2206.05262) ([Code](https://github.com/facebookresearch/meta-ot))
- [envd](https://github.com/tensorchord/envd) - Development environment for machine learning.
- [Awesome Open Source MLOps](https://github.com/gaocegege/awesome-open-source-mlops)
- [Generalised Implicit Neural Representations (2022)](https://arxiv.org/abs/2205.15674) ([Code](https://github.com/danielegrattarola/GINR))
- [Diffusers](https://github.com/huggingface/diffusers) - Provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models. ([Fork](https://github.com/ShivamShrirao/diffusers))
- [Lightning AI](https://lightning.ai/) - Use Lightning Apps to build everything from production-ready, multi-cloud ML systems to simple research demos.
- [Latent World Models For Intrinsically Motivated Exploration (2020)](https://arxiv.org/abs/2010.02302) ([Code](https://github.com/htdt/lwm))
- [Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt (2022)](https://arxiv.org/abs/2206.07137) ([Code](https://github.com/OATML/RHO-Loss))
- [Self-Supervised Learning from Images: Up-to-date reading list](https://github.com/wvangansbeke/Self-Supervised-Learning-Overview)
- [How robust are pre-trained models to distribution shift? (2022)](https://arxiv.org/abs/2206.08871)
- [MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge (2022)](https://arxiv.org/abs/2206.08853) ([Code](https://github.com/MineDojo/MineDojo)) ([Web](https://minedojo.org/))
- [MLOPs Primer](https://github.com/dair-ai/MLOPs-Primer) - Collection of resources to learn about MLOPs.
- [Are wider nets better given the same number of parameters? (2020)](https://arxiv.org/abs/2010.14495) ([Code](https://github.com/google-research/wide-sparse-nets))
- [Brandon Amos's presentation slides](https://github.com/bamos/presentations)
- [Ethical Principles for Web Machine Learning](https://webmachinelearning.github.io/ethical-webmachinelearning/) ([Code](https://github.com/webmachinelearning/ethical-webmachinelearning))
- [MLC](https://github.com/mlc-ai/mlc-en) - Machine Learning Compiler.
- [Golan Levin's lectures](https://github.com/golanlevin/lectures)
- [RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network (2022)](https://arxiv.org/abs/2206.14098) ([Code](https://github.com/CerebrasResearch/RevBiFPN))
- [Pen and paper exercises in machine learning](https://github.com/michaelgutmann/ml-pen-and-paper-exercises) ([Paper](https://arxiv.org/abs/2206.13446)) ([HN](https://news.ycombinator.com/item?id=31913057))
- [Dual Curriculum Design](https://github.com/facebookresearch/dcd) - Implementations of robust Dual Curriculum Design (DCD) algorithms for unsupervised environment design.
- [gDDIM: Generalized denoising diffusion implicit models (2022)](https://arxiv.org/abs/2206.05564) ([Code](https://github.com/qsh-zh/gDDIM))
- [Awesome Active Learning](https://github.com/SupeRuier/awesome-active-learning)
- [Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/) ([Code](https://github.com/chiphuyen/dmls-book))
- [The Berkeley Crossword Solver](https://bair.berkeley.edu/blog/2022/05/20/crosswords/)
- [MLC](https://github.com/mlc-ai/mlc-zh) - Machine Learning Compiler.
- [Recommender System on MovieLens dataset](https://github.com/rposhala/Recommender-System-on-MovieLens-dataset)
- [Awesome Radar Perception](https://github.com/ZHOUYI1023/awesome-radar-perception) - Curated list of radar datasets, detection, tracking and fusion.
- [MLGO: A Machine Learning Framework for Compiler Optimization (2022)](https://ai.googleblog.com/2022/07/mlgo-machine-learning-framework-for.html) ([HN](https://news.ycombinator.com/item?id=32007695))
- [Supporting GPU-accelerated Machine Learning with Kubernetes and Nix (2022)](https://canvatechblog.com/supporting-gpu-accelerated-machine-learning-with-kubernetes-and-nix-7c1da8e42f61)
- [Transfer Learning with Deep Tabular Models (2022)](https://arxiv.org/abs/2206.15306) ([Code](https://github.com/LevinRoman/tabular-transfer-learning))
- [Speech Denoising in the Waveform Domain with Self-Attention (2022)](https://arxiv.org/abs/2202.07790) ([Code](https://github.com/NVIDIA/CleanUNet))
- [SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data (2021)](https://arxiv.org/abs/2103.15619) ([Code](https://github.com/jw9730/setvae))
- [MIT: Deep Learning for Art, Aesthetics, and Creativity (2022)](https://ali-design.github.io/deepcreativity/)
- [500 AI Machine learning Deep learning Computer vision NLP Projects with code](https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code)
- [Deep Learning Curriculum](https://github.com/jacobhilton/deep_learning_curriculum)
- [Diffusion models](https://github.com/InFoCusp/diffusion_models) - Minimal standalone example of diffusion model.
- [Perceiver IO: A General Architecture for Structured Inputs & Outputs (2021)](https://arxiv.org/abs/2107.14795) ([Code](https://github.com/minqukanq/perceiver-io))
- [ML code generation vs. coding by hand: what we think programming will look like (2022)](https://wasp-lang.dev/blog/2022/06/24/ML-code-gen-vs-coding-by-hand-future) ([HN](https://news.ycombinator.com/item?id=32098144))
- [Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning (2021)](https://arxiv.org/abs/2106.02584) ([Code](https://github.com/OATML/non-parametric-transformers))
- [Recommender Systems course at Polimi](https://github.com/MaurizioFD/RecSys_Course_AT_PoliMi)
- [A General Recipe for Likelihood-free Bayesian Optimization (2022)](https://arxiv.org/abs/2206.13035) ([Code](https://github.com/lfbo-ml/lfbo))
- [Generative Coarse-Graining of Molecular Conformations (2022)](https://arxiv.org/abs/2201.12176) ([Code](https://github.com/wwang2/CoarseGrainingVAE))
- [Thoughts on ML Engineering After a Year of My PhD (2022)](https://www.shreya-shankar.com/phd-year-one/) ([HN](https://news.ycombinator.com/item?id=32147219))
- [Towards a General Purpose CNN for Long Range Dependencies in ND (2022)](https://arxiv.org/abs/2206.03398) ([Code](https://github.com/david-knigge/ccnn))
- [Formal Algorithms for Transformers (2022)](https://arxiv.org/abs/2207.09238) ([HN](https://news.ycombinator.com/item?id=32163324))
- [Practical Deep Learning for Coders 2022](https://www.fast.ai/2022/07/21/dl-coders-22/) ([HN](https://news.ycombinator.com/item?id=32186647))
- [ML is not that good at predicting consumers' choices (2022)](https://statmodeling.stat.columbia.edu/2022/07/21/predicting-consumers-choices-in-the-age-of-the-internet-ai-and-almost-perfect-tracking-some-things-change-the-key-challenges-do-not/) ([HN](https://news.ycombinator.com/item?id=32181974))
- [TabTransformer: Tabular Data Modeling Using Contextual Embeddings (2020)](https://arxiv.org/abs/2012.06678) ([Code](https://github.com/lucidrains/tab-transformer-pytorch))
- [Automatic Symmetry Discovery with Lie Algebra Convolutional Network (2021)](https://arxiv.org/abs/2109.07103) ([Code](https://github.com/nimadehmamy/L-conv-code))
- [Awesome Time Series Papers](https://github.com/cure-lab/Awesome-time-series)
- [Deep Learning setup made easy with EC2 Remote Runner and Habana Gaudi (2022)](https://www.philschmid.de/habana-gaudi-ec2-runner)
- [Efficient Deep Learning Book](https://efficientdlbook.com/) ([Code](https://github.com/EfficientDL/book))
- [DALLE2 LAION](https://github.com/LAION-AI/dalle2-laion) - Collection of resources and tools for LAION's pre-trained DALLE-2 model.
- [Awesome Novel Class Discovery](https://github.com/JosephKJ/Awesome-Novel-Class-Discovery)
- [Harvard ML Course (2019)](https://harvard-iacs.github.io/2019-CS109A/pages/materials.html)
- [Transformers as Meta-Learners for Implicit Neural Representations (2022)](https://arxiv.org/abs/2208.02801) ([Code](https://github.com/yinboc/trans-inr))
- [AdaCat: Adaptive Categorical Discretization for Autoregressive Models (2022)](https://arxiv.org/abs/2208.02246) ([Code](https://github.com/ColinQiyangLi/AdaCat))
- [Awesome Decision Tree Research Papers](https://github.com/benedekrozemberczki/awesome-decision-tree-papers)
- [Why do tree-based models still outperform deep learning on tabular data? (2022)](https://arxiv.org/abs/2207.08815) ([HN](https://news.ycombinator.com/item?id=32333565))
- [Improving Sample Efficiency in Model-Free Reinforcement Learning from Images (2020)](https://arxiv.org/abs/1910.01741) ([Code](https://github.com/denisyarats/pytorch_sac_ae))
- [Robust Robotic Control from Pixels using Contrastive Recurrent State-Space Models (2021)](https://arxiv.org/abs/2112.01163) ([Code](https://github.com/apple/ml-core))
- [First Italian School on Geometric Deep Learning (2022)](https://www.youtube.com/playlist?list=PLn2-dEmQeTfRQXLKf9Fmlk3HmReGg3YZZ)
- [DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting (2022)](https://arxiv.org/abs/2207.06046) ([Code](https://github.com/salesforce/DeepTIMe))
- [Stable Diffusion Akashic Records](https://github.com/Maks-s/sd-akashic) - Compendium of informations regarding Stable Diffusion (SD).
- [Ask HN: In 2022, what is the proper way to get into machine/deep learning? (2022)](https://news.ycombinator.com/item?id=32480009)
- [1 week of Stable Diffusion](https://multimodal.art/news/1-week-of-stable-diffusion) ([HN](https://news.ycombinator.com/item?id=32650432))
- [What are Diffusion Models? (2021)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) ([Lobsters](https://lobste.rs/s/n9rd5p/what_are_diffusion_models))
- [Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models (2022)](https://arxiv.org/abs/2208.06677) ([Code](https://github.com/sail-sg/Adan))
- [Awesome AI image synthesis](https://github.com/altryne/awesome-ai-art-image-synthesis)
- [First-Time Machine Learning Playbook (2022)](https://twitter.com/DSaience/status/1566054660791738368)
- [Grokking Stable Diffusion](https://twitter.com/johnowhitaker/status/1565710033463156739)
- [Notes for prompt engineering](https://github.com/sw-yx/prompt-eng)
- [Course content and resources for the AIAIART course](https://github.com/johnowhitaker/aiaiart)
- [Stable Diffusion UI](https://github.com/cmdr2/stable-diffusion-ui)
- [Score-Based Generative Modeling with Critically-Damped Langevin Diffusion (2022)](https://nv-tlabs.github.io/CLD-SGM/) ([Code](https://github.com/nv-tlabs/CLD-SGM))
- [Fast Sampling of Diffusion Models with Exponential Integrator (2022)](https://arxiv.org/abs/2204.13902) ([Code](https://github.com/qsh-zh/deis))
- [Frozen️ in Time](https://github.com/m-bain/frozen-in-time) - Joint Video and Image Encoder for End-to-End Retrieval.
- [A Short Chronology Of Deep Learning For Tabular Data (2022)](https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html) ([HN](https://news.ycombinator.com/item?id=32711082))
- [Diverse Title Generation for Stack Overflow Posts with Multiple Sampling Enhanced Transformer (2022)](https://arxiv.org/abs/2208.11523) ([Tweet](https://twitter.com/DynamicWebPaige/status/1566657897257267201))
- [Stat.ML Papers Twitter](https://twitter.com/StatMLPapers) - Unofficial updates of statistical machine learning papers on arXiv.
- [Machine Learning authors/titles recent submissions](https://arxiv.org/list/stat.ML/recent)
- [Are Transformers Effective for Time Series Forecasting? (2022)](https://arxiv.org/abs/2205.13504) ([Code](https://github.com/cure-lab/LTSF-Linear))
- [Motiflets -- Fast and Accurate Detection of Motifs in Time Series (2022)](https://arxiv.org/abs/2206.03735)
- [Exploring Differential Geometry in Neural Implicits](https://github.com/dsilvavinicius/differential_geometry_in_neural_implicits)
- [REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer (2022)](https://arxiv.org/abs/2202.05244) ([Code](https://github.com/xingyul/revolver))
- [The AI Epiphany - YouTube](https://www.youtube.com/c/TheAIEpiphany/videos)
- [A Review of Sparse Expert Models in Deep Learning (2022)](https://arxiv.org/abs/2209.01667)
- [Conformal Prediction](https://github.com/aangelopoulos/conformal-prediction) - Lightweight, useful implementation of conformal prediction on real data.
- [Collection of papers on divergence and quality diversity](https://github.com/DanieleGravina/divergence-and-quality-diversity)
- [TACTiS: Transformer-Attentional Copulas for Time Series (2022)](https://proceedings.mlr.press/v162/drouin22a.html) ([Code](https://github.com/ServiceNow/tactis))
- [Deep Learning Systems: Algorithms and Implementation](https://dlsyscourse.org/)
- [Git Re-Basin: Merging Models modulo Permutation Symmetries (2022)](https://arxiv.org/abs/2209.04836) ([Code](https://github.com/samuela/git-re-basin))
- [Awesome-Machine-Unlearning](https://github.com/tamlhp/awesome-machine-unlearning)
- [sample-generator](https://github.com/Harmonai-org/sample-generator) - Tools to train a generative model on arbitrary audio samples.
- [Neural Set Function Extensions: Learning with Discrete Functions in High Dimensions (2022)](https://arxiv.org/abs/2208.04055)
- [Start Here with Machine Learning](https://machinelearningmastery.com/start-here/)
- [ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and Acquisition at Inference Time (2022)](https://arxiv.org/abs/2206.15049)
- [Learning to Accelerate Partial Differential Equations via Latent Global Evolution (2022)](https://arxiv.org/abs/2206.07681)
- [Intro to Transformers (2022)](https://docs.google.com/presentation/d/1ZXFIhYczos679r70Yu8vV9uO6B1J0ztzeDxbnBxD1S0/edit#slide=id.g31364026ad_3_2) ([Tweet](https://twitter.com/giffmana/status/1570152923233144832))
- [Maximum Likelihood Training of Implicit Nonlinear Diffusion Models (2022)](https://arxiv.org/abs/2205.13699) ([Code](https://github.com/byeonghu-na/INDM))
- [On the Paradox of Learning to Reason from Data (2022)](http://starai.cs.ucla.edu/papers/ZhangArxiv22.pdf)
- [Mega: Moving Average Equipped Gated Attention (2022)](https://arxiv.org/abs/2209.10655) ([Code](https://github.com/lucidrains/Mega-pytorch))
- [Toy Models of Superposition (2022)](https://transformer-circuits.pub/2022/toy_model/index.html) ([Tweet](https://twitter.com/ch402/status/1574801733187821568))
- [Learning to Learn with Generative Models of Neural Network Checkpoints (2022)](https://arxiv.org/abs/2209.12892) ([Code](https://github.com/wpeebles/G.pt)) ([Web](https://www.wpeebles.com/Gpt)) ([Tweet](https://twitter.com/billpeeb/status/1574850991001772032))
- [Didact AI: The anatomy of an ML-powered stock picking engine (2022)](https://principiamundi.com/posts/didact-anatomy/)
- [Deep Learning Examples](https://github.com/LambdaLabsML/examples)
- [Variational Inference for Infinitely Deep Neural Networks (2022)](https://arxiv.org/abs/2209.10091) ([Code](https://github.com/ANazaret/unbounded-depth-neural-networks))
- [First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization (2022)](https://arxiv.org/abs/2205.12381) ([Code](https://github.com/rddy/mimi))
- [Gradient Gating for Deep Multi-Rate Learning on Graphs (2022)](https://arxiv.org/abs/2210.00513) ([Code](https://github.com/tk-rusch/gradientgating))
- [Collective Intelligence for Deep Learning: A Survey of Recent Developments (2022)](https://blog.otoro.net/2022/10/01/collectiveintelligence/)
- [TT-NF: Tensor Train Neural Fields (2022)](https://www.obukhov.ai/ttnf) ([Code](https://github.com/toshas/ttnf))
- [Forecasting Future World Events with Neural Networks (2022)](https://arxiv.org/abs/2206.15474) ([Code](https://github.com/andyzoujm/autocast))
- [NeuML](https://neuml.com/) - Applying machine learning to solve everyday problems. ([GitHub](https://github.com/neuml))
- [ML founder starter stack (2022)](https://twitter.com/erikdoingthings/status/1580616858679578647)
- [Build AI product MVP quickly with HuggingFace (2022)](https://twitter.com/1littlecoder/status/1580555066791972866)
- [Efficient and Scalable Parallel Functional Programming Through Disentanglement (2022)](https://www.youtube.com/watch?v=IMPF-Vz1YqI) ([Tweet](https://twitter.com/shwestrick/status/1580571734218264577))
- [What's New In Machine Learning? (2022)](https://www.youtube.com/watch?v=QgpzNWMawU4)
- [Shervine Amidi's ML Cheat Sheets](https://stanford.edu/~shervine/teaching/)
- [Complete Machine Learning Package](https://github.com/Nyandwi/machine_learning_complete) - Comprehensive machine learning repository containing 30+ notebooks on different concepts, algorithms and techniques.
- [TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second (2022)](https://arxiv.org/abs/2207.01848) ([Code](https://github.com/automl/TabPFN)) ([Summary](https://www.automl.org/tabpfn-a-transformer-that-solves-small-tabular-classification-problems-in-a-second/)) ([HN](https://news.ycombinator.com/item?id=33337329))
- [Matérn Gaussian Processes on Graphs (2021)](https://arxiv.org/abs/2010.15538) ([Code](https://github.com/spbu-math-cs/Graph-Gaussian-Processes))
- [How to model and predict churn using deep learning (2016)](https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/) ([Tweet](https://twitter.com/bernhardsson/status/1584260214986985474))
- [Poisson Flow Generative Models (2022)](https://arxiv.org/abs/2209.11178) ([Code](https://github.com/Newbeeer/Poisson_flow))
- [Latent Space Smoothing for Individually Fair Representations (2021)](https://arxiv.org/abs/2111.13650) ([Tweet](https://twitter.com/DeepMind/status/1584853867950665728))
- [Volodymyr Kuleshov - YouTube](https://www.youtube.com/user/vkuleshov/videos)
- [VectorAdam for Rotation Equivariant Geometry Optimization (2022)](https://arxiv.org/abs/2205.13599) ([Code](https://github.com/iszihan/VectorAdam))
- [Learning Fast and Slow for Online Time Series Forecasting (2022)](https://arxiv.org/abs/2202.11672) ([Code](https://github.com/salesforce/fsnet))
- [What Makes Convolutional Models Great on Long Sequence Modeling? (2022)](https://arxiv.org/abs/2210.09298) ([Code](https://github.com/ctlllll/SGConv))
- [Machine Learning Specialization by Andrew Ng notes (2022)](https://dair-ai.notion.site/Course-1-Supervised-Machine-Learning-3a200719f58145dc8a701a2545bdf9f4)
- [Deep Generalized Schrödinger Bridge (2022)](https://arxiv.org/abs/2209.09893) ([Code](https://github.com/ghliu/DeepGSB))
- [Awesome Full Stack Machine Learning Engineering Courses](https://github.com/leehanchung/awesome-full-stack-machine-courses)
- [Monolith: Real Time Recommendation System With Collisionless Embedding Table (2022)](https://arxiv.org/abs/2209.07663) ([Tweet](https://twitter.com/xamat/status/1587124786487906304))
- [GENIE: Higher-Order Denoising Diffusion Solvers (2022)](https://arxiv.org/abs/2210.05475) ([Web](https://nv-tlabs.github.io/GENIE/))
- [PDEBENCH: An Extensive Benchmark for Scientific Machine Learning (2022)](https://arxiv.org/abs/2210.07182) ([Code](https://github.com/pdebench/PDEBench))
- [Broken Neural Scaling Laws (2022)](https://arxiv.org/abs/2210.14891) ([Code](https://github.com/ethancaballero/broken_neural_scaling_laws))
- [Failed Machine Learning](https://github.com/kennethleungty/Failed-ML) - Compilation of high-profile real-world examples of failed machine learning projects.
- [Thoughts on my first machine learning project (2022)](https://www.holovaty.com/writing/machine-learning-thoughts/)
- [Are You A Cat? ML learning project](https://github.com/MarinaWyss/are-you-a-cat)
- [The gap between theory and practice in function approximation with deep neural networks (2020)](https://arxiv.org/abs/2001.07523) ([Code](https://github.com/ndexter/MLFA))
- [Bayesian neural network papers](https://github.com/ssydasheng/Bayesian_neural_network_papers)
- [Understanding Bayesian Deep Learning](https://github.com/sjchoi86/bayes-nn)
- [Disentangled Image Colorization via Global Anchors](https://github.com/MenghanXia/DisentangledColorization)
- [Estimating High Order Gradients of the Data Distribution by Denoising (2021)](https://arxiv.org/abs/2111.04726) ([Code](https://github.com/chenlin9/high_order_dsm))
- [Sharpness-Aware Minimization for Efficiently Improving Generalization (2020)](https://arxiv.org/abs/2010.01412) ([Code](https://github.com/google-research/sam))
- [Closed-form Continuous-time Neural Models (2021)](https://arxiv.org/abs/2106.13898) ([Code](https://github.com/raminmh/CfC))
- [Creative AI](https://github.com/sony/creativeai)
- [ZenBytes](https://github.com/zenml-io/zenbytes) - Simple guide to MLOps through ZenML and its various integrations.
- [Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting (2022)](https://arxiv.org/abs/2205.14415) ([Code](https://github.com/thuml/Nonstationary_Transformers))
- [Deep Image Processing](https://github.com/t-kuha/deep-image-processing)
- [Uni-Perceiver models](https://github.com/fundamentalvision/Uni-Perceiver)
- [Compiler Provenance Recovery for Multi-CPU Architectures Using a Centrifuge Mechanism (2022)](https://arxiv.org/abs/2211.13110)
- [Efficient AI Backbones](https://github.com/huawei-noah/Efficient-AI-Backbones) - Including GhostNet, TNT (Transformer in Transformer), AugViT, WaveMLP and ViG developed by Huawei Noah's Ark Lab.
- [Some Math behind Neural Tangent Kernel (2022)](https://lilianweng.github.io/posts/2022-09-08-ntk/)
- [Evolution through Large Models (2022)](https://arxiv.org/abs/2206.08896) ([Code](https://github.com/CarperAI/OpenELM))
- [Causal Confounds in Sequential Decision Making (2022)](https://blog.ml.cmu.edu/2022/11/28/causal-confounds-in-sequential-decision-making/)
- [MIP Workshop 2023 Computational Competition](https://github.com/ambros-gleixner/MIPcc23)
- [Statistical vs. Deep Learning forecasting methods](https://github.com/Nixtla/statsforecast/tree/main/experiments/m3) ([HN](https://news.ycombinator.com/item?id=33818531))
- [USB: A Unified Semi-supervised Learning Benchmark for Classification (2022)](https://arxiv.org/abs/2208.07204) ([Code](https://github.com/microsoft/Semi-supervised-learning))
- [Walk with fastai - the missing pieces for success](https://thezachmueller.gumroad.com/l/walkwithfastai) ([Code](https://github.com/muellerzr/Walk-with-fastai-revisited))
- [Awesome NVIDIA Isaac Gym](https://github.com/wangcongrobot/awesome-isaac-gym) - Curated list of awesome NVIDIA Issac Gym frameworks, papers, software, and resources.
- [Deep Learning Fundamentals - Lightning AI](https://lightning.ai/pages/courses/deep-learning-fundamentals/)
- [Transformers for software engineers (2022)](https://blog.nelhage.com/post/transformers-for-software-engineers/)
- [A Generalist Neural Algorithmic Learner (2022)](https://arxiv.org/abs/2209.11142)
- [AlphaCode Attention Visualization](https://alphacode.deepmind.com/) ([HN](https://news.ycombinator.com/item?id=33914122))
- [The Illustrated Transformer (2018)](https://jalammar.github.io/illustrated-transformer/)
- [Ask HN: How to get back into AI? (2022)](https://news.ycombinator.com/item?id=33932594)
- [Semi-Discrete Normalizing Flows through Differentiable Tessellation (2022)](https://arxiv.org/abs/2203.06832) ([Code](https://github.com/facebookresearch/semi-discrete-flow))
- [Learning the Travelling Salesperson Problem Requires Rethinking Generalization (2021)](https://arxiv.org/abs/2006.07054) ([Code](https://github.com/chaitjo/learning-tsp))
- [Learn Machine Learning in 3 Months (PyTorch Curriculum)](https://github.com/llSourcell/LearnML)
- [Transformers for software engineers (2022)](https://blog.nelhage.com/post/transformers-for-software-engineers/)
- [Measuring Data (2022)](https://arxiv.org/abs/2212.05129) ([Tweet](https://twitter.com/mmitchell_ai/status/1602503631441272833))
- [Learning to generate line drawings that convey geometry and semantics (2022)](https://carolineec.github.io/informative_drawings/) ([Code](https://github.com/carolineec/informative-drawings))
- [Data2vec 2.0: Highly efficient self-supervised learning for vision, speech and text (2022)](https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/)
- [X-modaler](https://github.com/YehLi/xmodaler) - Versatile and high-performance codebase for cross-modal analytics.
- [Normconf](https://normconf.com/) - Tech conference about all the stuff that matters in data and machine learning. ([Awesome](https://github.com/normconf/awesome-normconf)) ([Twitter](https://twitter.com/normconf)) ([Videos](https://www.youtube.com/@normconf/videos))
- [Machine Learning for Engineers Course - YouTube (2022)](https://www.youtube.com/playlist?list=PLUrb9ObKDCj-zuzSYKpFONf3JE4W7NHLE)
- [Uncertain: Modern Topics in Uncertainty Quantification](https://www.cis.upenn.edu/~aaroth/uncertain.html)
- [Learn ML yourself - resources (2020)](https://dauparas.github.io/post/learning/)
- [MEMIT: Mass-Editing Memory in a Transformer](https://github.com/kmeng01/memit) - Editing thousands of facts into a transformer memory at once.
- [Lightning fast recommendation with Birdland](https://www.thetypicalset.com/blog/drafts/introducing-birdland.html)
- [Pythia: Interpreting Autoregressive Transformers Across Time and Scale](https://github.com/EleutherAI/pythia)
- [Thinking like Transformers](https://srush.github.io/raspy/) ([HN](https://news.ycombinator.com/item?id=27528004)) ([Code](https://github.com/srush/raspy))
- [OLLA: Optimizing the Lifetime and Location of Arrays to Reduce the Memory Usage of Neural Networks (2022)](https://arxiv.org/abs/2210.12924) ([Code](https://github.com/facebookresearch/OLLA))
- [Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning (2022)](https://arxiv.org/abs/2207.09081) ([Code](https://github.com/GilgameshD/GRADER))
- [Extremely Simple Activation Shaping for Out-of-Distribution Detection (2022)](https://arxiv.org/abs/2209.09858) ([Code](https://github.com/andrijazz/ash))
- [Nice personal ML/DS blogs](https://github.com/alexmolas/ml-blogs)
- [Ask HN: Which are your favorite machine learning blogs? (2022)](https://news.ycombinator.com/item?id=34198427)
- [Liquid Structural State-Space Models (2022)](https://arxiv.org/abs/2209.12951) ([Code](https://github.com/raminmh/liquid-s4))
- [OpenXLA](https://github.com/openxla/xla) - Community-driven and modular open source compiler for ML.
- [Graph-based Fraud Detection Papers and Resources](https://github.com/safe-graph/graph-fraud-detection-papers)
- [Trustworthy AI related projects](https://github.com/huawei-noah/trustworthyAI)
- [Paper List for In-context Learning](https://github.com/dqxiu/ICL_PaperList)
- [Awesome Domain Generalization](https://github.com/junkunyuan/Awesome-Domain-Generalization)
- [Editing Models with Task Arithmetic (2022)](https://arxiv.org/abs/2212.04089) ([Code](https://github.com/mlfoundations/task_vectors))
- [POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging (2022)](https://arxiv.org/abs/2207.07697) ([Code](https://github.com/ShishirPatil/poet))
- [Amortized Inference for Causal Structure Learning (2022)](https://arxiv.org/abs/2205.12934) ([Code](https://github.com/larslorch/avici))
- [Awesome Machine Learning for Combinatorial Optimization Resources](https://github.com/Thinklab-SJTU/awesome-ml4co)
- [Magick](https://github.com/Oneirocom/MagickML) - Visual IDE for no-code data pipelines and multimodal agents.
- [Rigging the Lottery: Making All Tickets Winners (2019)](https://arxiv.org/abs/1911.11134) ([Code](https://github.com/google-research/rigl))
- [Ask HN: What are the foundational texts for learning about AI/ML/NN? (2023)](https://news.ycombinator.com/item?id=34312248)
- [ML Papers of The Week](https://github.com/dair-ai/ML-Papers-of-the-Week)
- [Efficient Deep Learning](https://github.com/MingSun-Tse/Efficient-Deep-Learning) - Collection of recent methods on (deep) neural network compression and acceleration.
- [Geoffrey Hinton publishes new deep learning algorithm (2023)](https://www.infoq.com/news/2023/01/hinton-forward-algorithm/) ([HN](https://news.ycombinator.com/item?id=34350662))
- [ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained) - Explanations to key concepts in ML.
- [Tracr: Compiled Transformers as a Laboratory for Interpretability (2023)](https://arxiv.org/abs/2301.05062) ([Code](https://github.com/deepmind/tracr))
- [Understanding Deep Learning Book (2022)](https://udlbook.github.io/udlbook/) ([Code](https://github.com/udlbook/udlbook))
- [Riemannian Score-Based Generative Modelling (2022)](https://arxiv.org/abs/2202.02763) ([Code](https://github.com/oxcsml/riemannian-score-sde))
- [Techniques to improve reliability of LLMs](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md) ([HN](https://news.ycombinator.com/item?id=34462926))
- [Learning Compressed Transforms with Low Displacement Rank (2018)](https://arxiv.org/abs/1810.02309) ([Code](https://github.com/HazyResearch/structured-nets))
- [Ask HN: ML Papers to Implement (2023)](https://news.ycombinator.com/item?id=34503362)
- [Hungry Hungry Hippos: Towards Language Modeling with State Space Models (2022)](https://arxiv.org/abs/2212.14052) ([Code](https://github.com/HazyResearch/H3))
- [Intuitive Tutorial to Gaussian Processes Regression](https://github.com/jwangjie/Gaussian-Processes-Regression-Tutorial)
- [MPCFormer: fast, performant and private Transformer inference with MPC (2022)](https://arxiv.org/abs/2211.01452) ([Code](https://github.com/MccRee177/MPCFormer))
- [Deep Equilibrium Approaches to Diffusion Models (2022)](https://arxiv.org/abs/2210.12867) ([Code](https://github.com/locuslab/deq-ddim))
- [Causal Transformer Decoder](https://github.com/alex-matton/causal-transformer-decoder)
- [Illustrated Machine Learning](https://illustrated-machine-learning.github.io/) ([Code](https://github.com/illustrated-machine-learning/illustrated-machine-learning.github.io))
- [The Transformer Family (2023)](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/) ([HN](https://news.ycombinator.com/item?id=34566275))
- [Just know stuff (or, how to achieve success in a machine learning PhD) (2023)](https://kidger.site/thoughts/just-know-stuff/) ([HN](https://news.ycombinator.com/item?id=34547358))
- [Deep invariant networks with differentiable augmentation layers (2022)](https://arxiv.org/abs/2202.02142) ([Code](https://github.com/cedricrommel/augnet))
- [Weakly-supervised Anomaly Detection: A Survey](https://github.com/yzhao062/WSAD)
- [Awesome Federated Machine Learning](https://github.com/innovation-cat/Awesome-Federated-Machine-Learning)
- [Transformer Grammars: Augmenting Transformer Language Models with Syntactic Inductive Biases at Scale (2022)](https://github.com/deepmind/transformer_grammars)
- [Impactful and widely cited papers and literature on ML](https://github.com/tirthajyoti/Papers-Literature-ML-DL-RL-AI)
- [Resources of deep learning for mathematical reasoning](https://github.com/lupantech/dl4math)
- [Homomorphic Learning study](https://github.com/redhat-et/homomorphic-learning)
- [Speculative Sampling (2023)](https://jaykmody.com/blog/speculative-sampling/)
- [Numerically Stable Softmax and Cross Entropy (2022)](https://jaykmody.com/blog/stable-softmax/)
- [An Intuition for Attention (2022)](https://jaykmody.com/blog/attention-intuition/)
- [Latent State Marginalization as a Low-cost Approach for Improving Exploration (2023)](https://arxiv.org/abs/2210.00999) ([Code](https://github.com/zdhNarsil/Stochastic-Marginal-Actor-Critic))
- [The Little Learner (2023)](https://mitpress.mit.edu/9780262546379/the-little-learner/) - Highly accessible, step-by-step introduction to deep learning, written in an engaging, question-and-answer style. ([HN](https://news.ycombinator.com/item?id=34810332))
- [Paper list of RGBD semantic segmentation](https://github.com/Yangzhangcst/RGBD-semantic-segmentation)
- [Infinitely Deep Bayesian Neural Networks with Stochastic Differential Equations (2022)](https://arxiv.org/abs/2102.06559) ([Code](https://github.com/xwinxu/bayeSDE))
- [Auxiliary Learning as an Asymmetric Bargaining Game (2023)](https://arxiv.org/abs/2301.13501) ([Code](https://github.com/AvivSham/auxinash))
- [Block-Recurrent Transformers (2022)](https://arxiv.org/abs/2203.07852) ([Code](https://github.com/lucidrains/block-recurrent-transformer-pytorch))
- [Awesome Causality Algorithms](https://github.com/rguo12/awesome-causality-algorithms)
- [Transformer learning explained: Coinductive guide to inductive transformer heads (2023)](https://arxiv.org/abs/2302.01834) ([HN](https://news.ycombinator.com/item?id=34970877))
- [MultiViz: Towards Visualizing and Understanding Multimodal Models](https://multivizweb.github.io/) ([Code](https://github.com/pliang279/MultiViz)) ([Paper](https://arxiv.org/abs/2207.00056))
- [Awesome Transformers](https://github.com/abacaj/awesome-transformers) - Curated list of awesome transformer models.
- [Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models (2022)](https://arxiv.org/abs/2201.06503) ([Code](https://github.com/baofff/Analytic-DPM))
- [Dropout Reduces Underfitting (2023)](https://arxiv.org/abs/2303.01500) ([Code](https://github.com/facebookresearch/dropout))
- [Consistency Models (2023)](https://arxiv.org/abs/2303.01469) ([Code](https://github.com/cloneofsimo/consistency_models)) ([Code](https://github.com/openai/consistency_models)) ([Code](https://github.com/junhsss/consistency-models))
- [Online active learning in 80 lines of Python (2023)](https://maxhalford.github.io/blog/online-active-learning-river-databutton/)
- [Prismer: A Vision-Language Model with An Ensemble of Experts (2023)](https://arxiv.org/abs/2303.02506) ([Code](https://github.com/NVlabs/prismer))
- [Compose & Embellish: Well-Structured Piano Performance Generation via A Two-Stage Approach (2022)](https://arxiv.org/abs/2209.08212) ([Code](https://github.com/slSeanWU/Compose_and_Embellish))
- [Clifford Layers](https://github.com/microsoft/cliffordlayers) - Neural Network layers inspired by Clifford / Geometric Algebras.
- [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers (2022)](https://arxiv.org/abs/2210.17323) ([Code](https://github.com/IST-DASLab/gptq))
- [Precise Zero-Shot Dense Retrieval without Relevance Labels (2022)](https://arxiv.org/abs/2212.10496) ([Code](https://github.com/texttron/hyde))
- [Superposition, Memorization, and Double Descent (2023)](https://transformer-circuits.pub/2023/toy-double-descent/index.html)
- [Teaching material for Causal ML](https://github.com/MCKnaus/causalML-teaching)
- [Symbolic Execution Papers](https://github.com/XMUsuny/symbolic-execution-papers)
- [Programming Machine Learning: From Coding to Deep Learning - Elixir Livebooks](https://github.com/nickgnd/programming-machine-learning-livebooks)
- [Introduction to Autoencoders (2023)](https://www.pinecone.io/learn/autoencoders/)
- [Awesome Uncertainty Deep Learning](https://github.com/ENSTA-U2IS/awesome-uncertainty-deeplearning)
- [RFdiffusion](https://github.com/RosettaCommons/RFdiffusion) - Open source method for structure generation, with or without conditional information.
- [Advances in Foundation Models Course (2023)](https://stanford-cs324.github.io/winter2023/syllabus/)
- [Hello Deep Learning (2023)](https://berthub.eu/articles/posts/hello-deep-learning/)
- [AI Alignment Forum](https://www.alignmentforum.org/)
- [Infinity-Diff: Infinite Resolution Diffusion with Subsampled Mollified States (2023)](https://arxiv.org/abs/2303.18242) ([Code](https://github.com/samb-t/infty-diff))
- [Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling (2021)](https://arxiv.org/abs/2111.02434) ([Code](https://github.com/gregversteeg/esh_dynamics))
- [Convolutions for Sequence Modeling](https://github.com/HazyResearch/safari)
- [What Can Transformers Learn In-Context? A Case Study of Simple Function Classes (2022)](https://proceedings.neurips.cc/paper_files/paper/2022/file/c529dba08a146ea8d6cf715ae8930cbe-Paper-Conference.pdf)
- [TRAK: Attributing Model Behavior at Scale (2023)](https://arxiv.org/abs/2303.14186) ([Code](https://github.com/MadryLab/trak))
- [Building Machine Learning Apps with Hugging Face: LLMs to Diffusion Modeling (2023)](https://www.youtube.com/watch?v=axkCZqngOSc)
- [On Efficient Training of Large-Scale Deep Learning Models: A Literature Review (2023)](https://arxiv.org/abs/2304.03589)
- [Example models using DeepSpeed](https://github.com/microsoft/DeepSpeedExamples)
- [Transformer Deep Dive: Parameter Counting](https://orenleung.com/transformer-parameter-counting)
- [Automatic Gradient Descent](https://github.com/jxbz/agd)
- [Image Restoration with Mean-Reverting Stochastic Differential Equations (2023)](https://arxiv.org/abs/2301.11699) ([Code](https://github.com/Algolzw/image-restoration-sde))
- [Contriever: Unsupervised Dense Information Retrieval with Contrastive Learning](https://github.com/facebookresearch/contriever)
- [Transformer Math 101 (2023)](https://blog.eleuther.ai/transformer-math/)
- [Exploratory Analysis of TRLX RLHF Transformers with TransformerLens (2023)](https://blog.eleuther.ai/trlx-exploratory-analysis/)
- [EleutherAI Second Retrospective: The long version (2023)](https://blog.eleuther.ai/year-two-full/)
- [The Big Dictionary of MLOps](https://www.hopsworks.ai/mlops-dictionary)
- [Learning to Substitute Ingredients in Recipes (2023)](https://arxiv.org/abs/2302.07960) ([Code](https://github.com/facebookresearch/gismo))
- [Mass Editing Memory in a Transformer (2022)](https://memit.baulab.info/)
- [Bridging Discrete and Backpropagation: Straight-Through and Beyond (2023)](https://arxiv.org/abs/2304.08612) ([Code](https://github.com/microsoft/ReinMax))
- [A Cookbook of Self-Supervised Learning (2023)](https://arxiv.org/abs/2304.12210) ([HN](https://news.ycombinator.com/item?id=35702490))
- [Table Transformer: Deep learning model for extracting tables from unstructured documents](https://github.com/microsoft/table-transformer) ([HN](https://news.ycombinator.com/item?id=35720157))
- [What Is ML Compilation](https://mlc.ai/chapter_introduction/index.html#what-is-ml-compilation)
- [The Little Book of Deep Learning](https://fleuret.org/public/lbdl.pdf) ([HN](https://news.ycombinator.com/item?id=35767789))
- [Fun and Hackable Tensors in Rust, From Scratch (2023)](https://getcode.substack.com/p/fun-and-hackable-tensors-in-rust) ([Reddit](https://www.reddit.com/r/rust/comments/134r80q/fun_and_hackable_tensors_in_rust_from_scratch/))
- [Efficient encoder-decoder architecture with top-down attention for speech separation](https://github.com/JusperLee/TDANet)
- [ImageBind](https://github.com/facebookresearch/ImageBind) - One Embedding Space To Bind Them All.
- [COLA: Contextualized Commonsense Causal Reasoning from the Causal Inference Perspective (2023)](https://github.com/HKUST-KnowComp/COLA)
- [Caikit](https://github.com/caikit/caikit) - AI toolkit that enables users to manage models through a set of developer friendly APIs.
- [SAITS: Self-attention-based imputation for time series (2023)](https://www.sciencedirect.com/science/article/abs/pii/S0957417423001203?via%3Dihub) ([Code](https://github.com/WenjieDu/SAITS))
- [SoundStorm: Efficient Parallel Audio Generation (2023)](https://arxiv.org/abs/2305.09636) ([Code](https://github.com/lucidrains/soundstorm-pytorch))
- [OpenFE](https://github.com/IIIS-Li-Group/OpenFE) - Automated feature generation with expert-level performance.
- [MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers (2023)](https://arxiv.org/abs/2305.07185) ([Code](https://github.com/lucidrains/MEGABYTE-pytorch))
- [QLoRA: Efficient Finetuning of Quantized LLMs (2023)](https://arxiv.org/abs/2305.14314) ([Code](https://github.com/artidoro/qlora))
- [PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction (2023)](https://arxiv.org/abs/2301.07945) ([Code](https://github.com/BUAABIGSCity/PDFormer))
- [What Machine Learning Tells Us About the Mathematical Structures of Concepts (2023)](https://www.youtube.com/watch?v=Lqt7TgYk8rU)
- [Visuals and Machine Learning](https://kdimensions.com/)
- [Ask HN: What are some of the best papers on AI, ML, DL and their applications? (2023)](https://news.ycombinator.com/item?id=36092156)
- [ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation (2023)](https://arxiv.org/abs/2305.16213) ([Code](https://github.com/thu-ml/prolificdreamer))
- [Yann LeCun, Chief AI Scientist at Meta AI: From Machine Learning to Autonomous Intelligence (2023)](https://www.youtube.com/watch?v=mViTAXCg1xQ)
- [Minimizing Trajectory Curvature of ODE-based Generative Models (2023)](https://arxiv.org/abs/2301.12003) ([Code](https://github.com/sangyun884/fast-ode))
- [Cross-Modal Fine-Tuning: Align then Refine (2023)](https://arxiv.org/abs/2302.05738) ([Code](https://github.com/sjunhongshen/ORCA))
- [NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from Multiview Images](https://github.com/liuyuan-pal/NeRO)
- [On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline (2022)](https://arxiv.org/abs/2212.05749) ([Code](https://github.com/gemcollector/learning-from-scratch))
- [A Mechanistic Interpretability Analysis of Grokking (2022)](https://www.alignmentforum.org/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking)
- [Tool Learning Papers](https://github.com/thunlp/ToolLearningPapers) - Must-read papers on tool learning with foundation models.
- [Awesome Graph Causal Learning](https://github.com/TimeLovercc/Awesome-Graph-Causal-Learning)
- [Brainformers: Trading Simplicity for Efficiency (2023)](https://arxiv.org/abs/2306.00008) ([HN](https://news.ycombinator.com/item?id=36173327))
- [CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring (2023)](https://arxiv.org/abs/2305.12050) ([HN](https://news.ycombinator.com/item?id=36176584))
- [Learning Transformer Programs (2023)](https://arxiv.org/abs/2306.01128) ([Code](https://github.com/princeton-nlp/TransformerPrograms))
- [Learning Neural Parametric Head Models (2023)](https://simongiebenhain.github.io/NPHM/) ([Code](https://github.com/SimonGiebenhain/NPHM))
- [GGML](http://ggml.ai/) - AI at the Edge. ([HN](https://news.ycombinator.com/item?id=36215651))
- [Transformer Inference Arithmetic (2022)](https://kipp.ly/blog/transformer-inference-arithmetic/)
- [Context is all you need - Multimodal vector search with personalization (2023)](https://www.reddit.com/r/MachineLearning/comments/1445s1k/p_context_is_all_you_need_multimodal_vector/)
- [U-Net CNN in APL: Exploring Zero-Framework, Zero-Library Machine Learning (2023)](https://dl.acm.org/doi/10.1145/3589246.3595371) ([HN](https://news.ycombinator.com/item?id=36256869))
- [LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale (2022)](https://arxiv.org/abs/2208.07339) ([HN](https://news.ycombinator.com/item?id=36271112))
- [OptiML: Optimizing Efficiency in Machine Learning (2022)](https://github.com/Arnav0400/ViT-Slim)
- [Any Deep ReLU Network is Shallow (2023)](https://arxiv.org/abs/2306.11827) ([HN](https://news.ycombinator.com/item?id=36451149))
- [The Little Book of Deep Learning](https://fleuret.org/francois/#lbdl) ([HN](https://news.ycombinator.com/item?id=36467927))
- [The Self-Supervised Learning Cookbook (2023)](https://ai.facebook.com/blog/self-supervised-learning-practical-guide/)
- [Building Autograd Engine & Neural Network Library: An Interactive Guide](https://x0axz.com/blog/autograd.html)
- [Petaflops to the People — with George Hotz of tinycorp (2023)](https://www.youtube.com/watch?v=K5iDUZPx60E)
- [Bayesian Learning](https://ermongroup.github.io/cs228-notes/learning/bayesian/)
- [Learning Neural Constitutive Laws From Motion Observations for Generalizable PDE Dynamics (2023)](https://arxiv.org/abs/2304.14369) ([Code](https://github.com/PingchuanMa/NCLaw))
- [DreamEdit: Subject-driven Image Editing](https://dreameditbenchteam.github.io/) ([Code](https://github.com/DreamEditBenchTeam/DreamEdit))
- [What is currently the best theoretical book (or notes) about Convolutional Neural Networks? (2023)](https://www.reddit.com/r/MachineLearning/comments/14pkcn5/d_what_is_currently_the_best_theoretical_book_or/)
