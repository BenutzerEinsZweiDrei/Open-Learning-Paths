---
title: Automatic differentiation
---

# [Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)

## Links

- [Automatic Differentiation in Machine Learning: a Survey](http://jmlr.org/papers/volume18/17-468/17-468.pdf)
- [autodiff](https://autodiff.github.io/) - C++17 library that uses modern and advanced programming techniques to enable automatic computation of derivatives in an efficient and easy way.
- [Automatic Differentiation via Contour Integration (2020)](https://github.com/AidanRocke/AutoDiff) ([Article](https://keplerlounge.com/neural-computation/2020/01/16/complex-auto-diff.html)) ([HN](https://news.ycombinator.com/item?id=22084670))
- [Taichi](http://taichi.graphics/) - Data-oriented programming language. Decouples computation from data organization. ([Code](https://github.com/taichi-dev/taichi)) ([Article](https://medium.com/@dunfan_magnificent/head-first-taichi-a-beginners-guide-to-high-performance-computing-in-python-be6afc5db93e)) ([Awesome](https://github.com/taichi-dev/awesome-taichi)) ([HN](https://news.ycombinator.com/item?id=35084841))
- [Demystifying Differentiable Programming: Shift/Reset the Penultimate Backpropagator (2019)](https://arxiv.org/abs/1803.10228)
- [Forward-mode Automatic Differentiation for TensorFlow](https://github.com/renmengye/tensorflow-forward-ad)
- [Automatic Differentiation tools for both forward and reverse mode written for R6RS Scheme](https://github.com/qobi/R6RS-AD)
- [From scratch: reverse-mode automatic differentiation (in Python) (2020)](https://sidsite.com/posts/autodiff/) ([HN](https://news.ycombinator.com/item?id=23519700))
- [ADMB Project](https://github.com/admb-project/admb) - Supports the application of automatic differentiation (AD) for solutions to non-linear statistical modeling and optimization problems. ([Web](http://www.admb-project.org/))
- [GTN: Automatic Differentiation with WFSTs (weighted finite-state transducers)](https://github.com/gtn-org/gtn)
- [Differentiation with higher infinitesimals](https://github.com/konn/smooth) - Exploring connections between automatic differentiation and smooth infinitesimal analysis, or smooth algebras.
- [AD4SM.jl](https://github.com/avigliotti/AD4SM.jl) - Automatic Differentiation for Solid Mechanics.
- [ceviche](https://github.com/fancompute/ceviche) - Electromagnetic Simulation Tools + Automatic Differentiation.
- [Tangent](https://github.com/google/tangent) - Source-to-Source Debuggable Derivatives in Pure Python.
- [Symbolic and Automatic Differentiation of Languages (2021)](http://conal.net/papers/language-derivatives/) ([Code](https://github.com/conal/paper-2021-language-derivatives))
- [oxide-enzyme](https://github.com/rust-ml/oxide-enzyme) - Enzyme integration into Rust. State-of-the-art AutoDiff in Rust. ([Reddit](https://www.reddit.com/r/rust/comments/reo75u/enzyme_towards_stateoftheart_autodiff_in_rust/))
- [simplegrad](https://github.com/anvaka/simplegrad) - Simple reverse mode automatic differentiation of scalar values in JS.
- [Downhill](https://github.com/andriusstank/downhill/) - Reverse mode automatic differentiation in Haskell. ([Docs](https://andriusstank.github.io/downhill/)) ([Tweet](https://twitter.com/kmett/status/1474947785434746883))
- [Trade-Offs in Automatic Differentiation: TensorFlow, PyTorch, Jax, and Julia (2021)](http://www.stochasticlifestyle.com/engineering-trade-offs-in-automatic-differentiation-from-tensorflow-and-pytorch-to-jax-and-julia/) ([HN](https://news.ycombinator.com/item?id=29682507))
- [Decomposing reverse-mode automatic differentiation (2021)](https://arxiv.org/abs/2105.09469)
- [RustAD](https://github.com/JonathanWoollett-Light/rust-ad) - Rust Auto-Differentiation.
- [Storchastic](https://github.com/HEmile/storchastic) - PyTorch library for stochastic gradient estimation in Deep Learning.
- [AbstractDifferentiation](https://github.com/JuliaDiff/AbstractDifferentiation.jl) - Abstract interface for automatic differentiation.
- [ad](https://github.com/ekmett/ad) - Package that provides an intuitive API for Automatic Differentiation (AD) in Haskell.
- [Automatic Differentiation: Inverse Accumulation Mode (2019)](https://openreview.net/forum?id=Bygj2Ys6IS)
- [ImplicitDifferentiation.jl](https://github.com/gdalle/ImplicitDifferentiation.jl) - Automatic differentiation of implicit functions.
- [Pymanopt](https://github.com/pymanopt/pymanopt) - Python toolbox for optimization on Riemannian manifolds with support for automatic differentiation.
- [Automatic Differentiation Handbook](https://github.com/bob-carpenter/ad-handbook)
- [Differentiable Programming â€“ A Simple Introduction](https://www.assemblyai.com/blog/differentiable-programming-a-simple-introduction/) ([HN](https://news.ycombinator.com/item?id=31000709))
- [Aude](https://github.com/advancedresearch/aude) - Automated differentiation solver with a Lisp-like functional programming language.
- [PyNeuraLogic](https://github.com/LukasZahradnik/PyNeuraLogic) - Lets you use Python to write Differentiable Logic Programs.
- [dCpp](https://github.com/ZigaSajovic/dCpp) - Automatic differentiation in C++. Infinite differentiability of conditionals, loops, recursion and all things C++.
- [ad-delcont](https://github.com/ocramz/ad-delcont) - Reverse-mode automatic differentiation with delimited continuations.
- [Dynamic Automatic Differentiation in Rust](https://github.com/exbibyte/dynagrad)
- [The simple essence of automatic differentiation](https://github.com/conal/talk-2018-essence-of-ad)
- [TinyAD](https://github.com/patr-schm/TinyAD) - C++ header-only library for second-order automatic differentiation.
- [Betty](https://github.com/leopard-ai/betty) - Automatic differentiation library for generalized meta-learning and multilevel optimization.
- [Randomized Automatic Differentiation (2020)](https://arxiv.org/abs/2007.10412)
- [Differentiable programming from scratch (2022)](https://thenumb.at/Autodiff/) ([HN](https://news.ycombinator.com/item?id=32300351))
- [Discussion on Solving Partial Differential Equations using Neural Networks](https://github.com/timudk/SPDENN)
- [Automatic Differentiation in 38 lines of Haskell](https://gist.github.com/ttesmer/948df432cf46ec6db8c1e83ab59b1b21) ([HN](https://news.ycombinator.com/item?id=32879734))
- [Automatic Differentiation: Forward and Reverse (2022)](https://jingnanshi.com/blog/autodiff.html) ([HN](https://news.ycombinator.com/item?id=31318865))
- [Diffuzers](https://github.com/abhishekkrthakur/diffuzers) - Web UI for diffusers.
- [PT-AD](https://github.com/PTsolvers/PT-AD) - Combine solvers using the Pseudo-Transient Method with Automatic Differentiation (AD) tools.
- [horde-ad](https://github.com/Mikolaj/horde-ad) - Higher Order Reverse Derivatives Efficiently.
- [Beyond automatic differentiation (2023)](https://ai.googleblog.com/2023/04/beyond-automatic-differentiation.html) ([HN](https://news.ycombinator.com/item?id=35570742))
- [FastDifferentiation](https://github.com/brianguenter/FastDifferentiation.jl) - Fast derivative evaluation.
- [picograd](https://github.com/breandan/picograd) - Tiniest possible autograd engine.
