# Computer vision

[LiT (Locked-image Tuning)](https://twitter.com/giffmana/status/1508400604082806785) paper is neat. Trying to understand [Vision Transformers](https://github.com/lucidrains/vit-pytorch). [Kornia](https://github.com/kornia/kornia) & [Scenic](https://github.com/google-research/scenic) seem like great libraries. [Imagen](https://github.com/lucidrains/imagen-pytorch) is fascinating.

[Embedding Methods for Image Search](https://www.pinecone.io/learn/image-search/) & [Computer Vision: Models, Learning, and Inference](http://www.computervisionmodels.com/) are nice reads.

[Rerun](https://www.rerun.io/) is great CV visualization tool.

## Links

- [OpenCV](https://github.com/opencv/opencv) - Open Source Computer Vision Library. ([Web](https://opencv.org/)) ([OpenCV Course](https://www.youtube.com/watch?v=oXlwWbU8l2o))
- [Gluon CV Toolkit](https://github.com/dmlc/gluon-cv) - Provides implementations of the sate-of-the-art (SOTA) deep learning models in computer vision.
- [Pythia](https://github.com/facebookresearch/pythia) - Modular framework for vision and language multimodal research. Built on top of PyTorch.
- [video-object-removal](https://github.com/zllrunning/video-object-removal) - Just draw a bounding box and you can remove the object you want to remove.
- [GoCV](https://github.com/hybridgroup/gocv) - Go package for computer vision using OpenCV 4 and beyond.
- [Sandbox for training convolutional networks for computer vision](https://github.com/osmr/imgclsmob)
- [Get started with Computer Vision, Deep Learning, and OpenCV](https://www.pyimagesearch.com/start-here/)
- [TorchCV](https://github.com/donnyyou/torchcv) - PyTorch-Based Framework for Deep Learning in Computer Vision.
- [AI Habitat](https://github.com/facebookresearch/habitat-sim) - Flexible, high-performance 3D simulator for Embodied AI research.
- [Kornia](https://github.com/kornia/kornia) - Open Source Differentiable Computer Vision Library for PyTorch. ([Web](https://kornia.github.io//))
- [Roboflow](https://roboflow.com/) - Raw images to trained computer vision model. ([Article](https://nickarner.com/notes/roboflow-memo-february-1-2021/))
- [PySlowFast](https://github.com/facebookresearch/SlowFast) - Open source video understanding codebase from FAIR that provides state-of-the-art video classification models.
- [How to Convert a Picture to Numbers](https://brohrer.github.io/images_to_numbers.html)
- [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)
- [The Ancient Secrets of Computer Vision (2018)](https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p)
- [Variational Methods for Computer Vision lectures (2013)](https://www.youtube.com/watch?v=fpw26tpHGr8&list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI)
- [Classy Vision](https://github.com/facebookresearch/ClassyVision) - New end-to-end, PyTorch-based framework for large-scale training of state-of-the-art image and video classification models.
- [Meshroom](https://github.com/alicevision/meshroom) - 3D Reconstruction Software.
- [AliceVision](https://alicevision.org/) - Photogrammetric Computer Vision Framework. ([Code](https://github.com/alicevision/AliceVision)) ([GitHub](https://github.com/alicevision))
- [PyTorch3d](https://github.com/facebookresearch/pytorch3d) - Provides efficient, reusable components for 3D Computer Vision research with PyTorch. ([Web](https://pytorch3d.org/))
- [Face Recognition](https://github.com/ageitgey/face_recognition) - World's simplest facial recognition api for Python and the command line.
- [Deep Hough Voting for 3D Object Detection in Point Clouds](https://github.com/facebookresearch/votenet)
- [Point Cloud Library](https://github.com/PointCloudLibrary/pcl) - Standalone, large scale, open project for 2D/3D image and point cloud processing.
- [Disappearing-People](https://github.com/jasonmayes/Real-Time-Person-Removal) - Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. ([HN](https://news.ycombinator.com/item?id=22353596))
- [Best Practices, code samples, and documentation for Computer Vision](https://github.com/microsoft/computervision-recipes)
- [Computer Vision Basics in Microsoft Excel](https://github.com/amzn/computer-vision-basics-in-microsoft-excel)
- [PolyGen: An Autoregressive Generative Model of 3D Meshes (2020)](https://arxiv.org/abs/2002.10880)
- [Sophus](https://github.com/strasdat/Sophus) - C++ implementation of Lie Groups using Eigen.
- [SOLT](https://github.com/MIPT-Oulu/solt) - Streaming over lightweight data transformations.
- [Awesome Interaction-aware Behavior and Trajectory Prediction](https://github.com/jiachenli94/Awesome-Interaction-aware-Trajectory-Prediction)
- [SynSin: End-to-end View Synthesis from a Single Image (2020)](http://www.robots.ox.ac.uk/~ow/synsin.html) ([Code](https://github.com/facebookresearch/synsin))
- [Pixel2Mesh](https://github.com/nywang16/Pixel2Mesh) - Generating 3D Mesh Models from Single RGB Images.
- [First Order Motion Model for Image Animation](https://aliaksandrsiarohin.github.io/first-order-model-website/) ([Code](https://github.com/AliaksandrSiarohin/first-order-model))
- [PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution](https://github.com/cleardusk/3DDFA)
- [Learning to See Through Obstructions](https://github.com/alex04072000/ObstructionRemoval)
- [Learning to Cluster Faces on an Affinity Graph (LTC)](https://github.com/yl-1993/learn-to-cluster)
- [Avatarify](https://github.com/alievk/avatarify) - Avatars for Zoom and Skype.
- [SPSR](https://github.com/Maclory/SPSR) - PyTorch implementation of Structure-Preserving Super Resolution with Gradient Guidance.
- [OISR-PyTorch](https://github.com/HolmesShuan/OISR-PyTorch) - PyTorch implementation of "ODE-inspired Network Design for Single Image Super-Resolution.
- [3D Photography using Context-aware Layered Depth Inpainting](https://github.com/vt-vl-lab/3d-photo-inpainting)
- [CenterMask : Real-Time Anchor-Free Instance Segmentation](https://github.com/youngwanLEE/CenterMask)
- [Interview with Dmytro Mushkin | Computer Vision Research | Kaggle, ML & Education (2020)](https://www.youtube.com/watch?v=lWwkbiufwNE)
- [Pytorch code for ICLR-20 Paper "Learning to Explore using Active Neural SLAM"](https://github.com/devendrachaplot/Neural-SLAM)
- [FaceTracker](https://github.com/kylemcdonald/FaceTracker) - Real time deformable face tracking in C++ with OpenCV 3.
- [Awesome Super Resolution](https://github.com/ChaofWang/Awesome-Super-Resolution)
- [Adversarial Latent Autoencoders](https://github.com/podgorskiy/ALAE)
- [ElasticFusion](https://github.com/mp3guy/ElasticFusion) - Real-time dense visual SLAM system capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera.
- [StegaStamp: Invisible Hyperlinks in Physical Photographs](https://github.com/tancik/StegaStamp)
- [Pose Animator](https://github.com/yemount/pose-animator/) - Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. ([HN](https://news.ycombinator.com/item?id=23124786))
- [fvcore](https://github.com/facebookresearch/fvcore) - Collection of common code that's shared among different research projects in FAIR computer vision team.
- [Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks (2020)](http://ai.stanford.edu/blog/selfsupervised-multimodal/)
- [ScreenPoint](https://github.com/cyrildiagne/screenpoint) - Project an image centroid to another image using OpenCV.
- [U^2-Net](https://github.com/NathanUA/U-2-Net) - Code for our newly accepted paper in Pattern Recognition 2020: "U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection".
- [TorchIO](https://github.com/fepegar/torchio) - Tools for medical image processing in deep learning.
- [Real time Image Animation in OpenCV using first order model](https://github.com/anandpawara/Real_Time_Image_Animation) ([HN](https://news.ycombinator.com/item?id=23312259))
- [OpenMV (Open-Source Machine Vision)](https://github.com/openmv/openmv) - Aims at making machine vision more accessible to beginners by developing a user-friendly, open-source, low-cost machine vision platform.
- [TSD](https://github.com/Sense-X/TSD) - 1st place models in Google OpenImage Detection Challenge 2019.
- [Training-Time-Friendly Network for Real-Time Object Detection](https://github.com/ZJULearning/ttfnet)
- [Big Transfer (BiT): General Visual Representation Learning](https://github.com/google-research/big_transfer)
- [Fast Human Pose Estimation CVPR2019](https://github.com/ilovepose/fast-human-pose-estimation.pytorch)
- [Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)
- [Background Matting: The World is Your Green Screen](https://github.com/senguptaumd/Background-Matting)
- [DEâ«¶TR: End-to-End Object Detection with Transformers](https://github.com/facebookresearch/detr)
- [PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization](https://github.com/shunsukesaito/PIFu)
- [Tracking Objects as Points](https://github.com/xingyizhou/CenterTrack)
- [VIBE](https://github.com/mkocabas/VIBE) - Video Inference for Human Body Pose and Shape Estimation.
- [SRZoo](https://github.com/idearibosome/srzoo) - Integrated repository for super-resolution using deep learning.
- [mAP (mean Average Precision)](https://github.com/Cartucho/mAP) - Evaluates the performance of your neural net for object recognition.
- [Neural Pose Transfer by Spatially Adaptive Instance Normalization (2020)](https://github.com/jiashunwang/Neural-Pose-Transfer)
- [Awesome Neural Rendering](https://github.com/weihaox/awesome-neural-rendering)
- [Learning To Classify Images Without Labels](https://github.com/wvangansbeke/Unsupervised-Classification)
- [Deep Leakage From Gradients (2019)](https://github.com/mit-han-lab/dlg)
- [3Dflow](https://www.3dflow.net/) - Offers customized computer vision software solutions.
- [labelme](https://github.com/wkentaro/labelme) - Image Polygonal Annotation with Python.
- [imgviz](https://github.com/wkentaro/imgviz) - Image Visualization Tools.
- [Attention-Guided Hierarchical Structure Aggregation for Image Matting](https://github.com/wukaoliu/CVPR2020-HAttMatting)
- [YOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS (2020)](https://blog.roboflow.ai/yolov5-is-here/) ([HN](https://news.ycombinator.com/item?id=23478151)) ([Code](https://github.com/ultralytics/yolov5))
- [DetectoRS](https://github.com/joe-siyuan-qiao/DetectoRS) - Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution.
- [PyTorch implementation of paper Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs](https://github.com/thepowerfuldeez/facemesh.pytorch)
- [VirTex: Learning Visual Representations from Textual Annotations](https://github.com/kdexd/virtex)
- [High-Resolution 3D Human Digitization from A Single Image](https://github.com/facebookresearch/pifuhd)
- [FairMOT](https://github.com/ifzhang/FairMOT) - Simple baseline for one-shot multi-object tracking.
- [Implicit Neural Representations with Periodic Activation Functions (2020)](https://vsitzmann.github.io/siren/)
- [MSeg: A Composite Dataset for Multi-Domain Segmentation](https://github.com/mseg-dataset/mseg-semantic)
- [Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results](https://github.com/CuriousAI/mean-teacher)
- [MMDetection](https://github.com/open-mmlab/mmdetection) - OpenMMLab Detection Toolbox and Benchmark.
- [Fourier Feature Networks in TensorFlow 2](https://github.com/noahtren/Fourier-Feature-Networks-TensorFlow-2)
- [Computer Vision Lab | ETH Zurich](https://vision.ee.ethz.ch/)
- [PyTorch Computer Vision Library for Experts and Beginners (2020)](https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5)
- [Computer Vision Pretrained Models](https://github.com/balavenkatesh3322/CV-pretrained-model)
- [Fawkes: Image âCloakingâ for Personal Privacy](http://sandlab.cs.uchicago.edu/fawkes/) ([HN](https://news.ycombinator.com/item?id=23917337))
- [Motion](https://github.com/Motion-Project/motion) - Software motion detector.
- [Supervised 3D Mesh Reconstruction (2020)](https://nextjournal.com/nirmal-suthar/supervised-3d-mesh-reconstruction)
- [NeRF in the Wild](https://nerf-w.github.io/) - Neural Radiance Fields for Unconstrained Photo Collections.
- [NASA: Neural Articulated Shape Approximation (2020)](https://arxiv.org/abs/1912.03207)
- [An Overview of Deep Learning Architectures in Few-Shot Learning Domain (2020)](https://arxiv.org/abs/2008.06365v2)
- [FutureMapping: The Computational Structure of Spatial AI Systems (2018)](https://arxiv.org/abs/1803.11288) ([Tweet](https://twitter.com/AjdDavison/status/1045617261925543937))
- [Optimal Peanut Butter and Banana Sandwiches (2020)](https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/) ([Twitter](https://twitter.com/eprosenthal/status/1298290961294950401))
- [Gesture Recognition with Line Integrals](https://justinmeiners.github.io/gesture-recognition/) ([Code](https://github.com/justinmeiners/gesture-recognition))
- [Computer Vision: Looking Back to Look Forward (2020)](http://slazebni.cs.illinois.edu/spring20/)
- [DAIN (Depth-Aware Video Frame Interpolation)](https://github.com/baowenbo/DAIN)
- [Picsellia](https://picsellia.com/) - Development platform dedicated to Computer Vision.
- [Official implementation of "PifPaf: Composite Fields for Human Pose Estimation" in PyTorch](https://github.com/vita-epfl/openpifpaf)
- [Object Recognition with Gradient-Based Learning (1999)](https://link.springer.com/chapter/10.1007/3-540-46805-6_19)
- [Imaginaire](https://github.com/NVlabs/imaginaire) - NVIDIA PyTorch GAN library with distributed and mixed precision support. ([Docs](http://imaginaire.cc/))
- [DeepBackSub](https://github.com/floe/deepbacksub) - Virtual Video Device for Background Replacement with Deep Semantic Segmentation.
- [Awesome Tiny Object Detection](https://github.com/kuanhungchen/awesome-tiny-object-detection)
- [Flow-edge Guided Video Completion](https://github.com/vt-vl-lab/FGVC)
- [5 Things to look for in a Computer Vision startup job (2020)](https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/)
- [Transformers for Image Recognition at Scale (2020)](https://www.youtube.com/watch?v=Gl48KciWZp0) ([HN](https://news.ycombinator.com/item?id=24754538))
- [nnU-Net](https://github.com/MIC-DKFZ/nnUNet) - Segmentation method that is designed to deal with the dataset diversity.
- [batchgenerators](https://github.com/MIC-DKFZ/batchgenerators) - Framework for data augmentation for 2D and 3D image classification and segmentation.
- [Lookuq](https://www.lookuq.com/create-your-own-app) - App to create object detection projects without coding. ([HN](https://news.ycombinator.com/item?id=24784680))
- [InsightFace](https://github.com/deepinsight/insightface) - Face Analysis Project on MXNet. ([Web](http://insightface.ai/))
- [PyTorch implementation of SwAV (Swapping Assignments between Views)](https://github.com/facebookresearch/swav)
- [Asymmetric Loss For Multi-Label Classification in PyTorch](https://github.com/Alibaba-MIIL/ASL)
- [Antialiased CNNs](https://github.com/adobe/antialiased-cnns) - Making Convolutional Networks Shift-Invariant Again.
- [Perceptual Similarity Metric and Dataset](https://github.com/richzhang/PerceptualSimilarity) - Unreasonable Effectiveness of Deep Features as a Perceptual Metric.
- [Deep Learning Anime Papers](https://github.com/deeppomf/DeepLearningAnimePapers)
- [Vision Transformer](https://github.com/google-research/vision_transformer) - Models from the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
- [Handsfree.js](https://github.com/MIDIBlocks/handsfree) - Wrapper library around computer vision models for working with face pointers, assistive tech, and creative expression. ([Web](https://handsfreejs.glitch.me/))
- [ZeroQ: A Novel Zero Shot Quantization Framework](https://github.com/amirgholami/ZeroQ)
- [SqueezeNext](https://github.com/amirgholami/SqueezeNext) - Contains the Caffe implementation of SqueezeNext.
- [ANODE: Adjoint Based Neural ODEs](https://github.com/amirgholami/anode)
- [Python Video Stabilization using OpenCV](https://github.com/AdamSpannbauer/python_video_stab)
- [Recent Advances in Vision and Language PreTrained Models (VL-PTMs)](https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers)
- [TorchCV](https://github.com/kuangliu/torchcv) - PyTorch vision library mimics ChainerCV.
- [Vision Transformer in PyTorch](https://github.com/jeonsworld/ViT-pytorch)
- [MedicalTorch](https://github.com/perone/medicaltorch) - Medical imaging framework for PyTorch. ([Docs](https://medicaltorch.readthedocs.io/en/stable/))
- [imagecluster](https://github.com/elcorto/imagecluster) - Cluster images based on image content using a pre-trained deep neural network, optional time distance scaling and hierarchical clustering.
- [Detecto](https://github.com/alankbi/detecto) - Build fully-functioning computer vision models with PyTorch. ([Docs](https://detecto.readthedocs.io/en/latest/))
- [EmoPy](https://github.com/thoughtworksarts/EmoPy) - Deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER).
- [PyTorch Implementation of "NVAE: A Deep Hierarchical Variational Autoencoder"](https://github.com/NVlabs/NVAE)
- [Label Decoupling Framework for Salient Object Detection](https://github.com/weijun88/LDF)
- [MONAI](https://github.com/Project-MONAI/MONAI) - PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. ([Web](https://monai.io/))
- [Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection](https://github.com/implus/GFocal)
- [Faster R-CNN Explained for Object Detection Tasks (2020)](https://blog.paperspace.com/faster-r-cnn-explained-object-detection/)
- [How to Install OpenCV on a Raspberry Pi (2020)](https://www.jeremymorgan.com/tutorials/raspberry-pi/how-to-install-opencv-raspberry-pi/)
- [Contextual Encoder-Decoder Network for Visual Saliency Prediction](https://github.com/alexanderkroner/saliency)
- [PyImageSearch](https://www.pyimagesearch.com/) - Master Computer Vision, Deep Learning, and OpenCV.
- [Natural Adversarial Examples](https://github.com/hendrycks/natural-adv-examples) - Harder ImageNet Test Set.
- [How to upload 50 OpenCV frames into cloud storage within 1 second (2020)](https://medium.com/@venkateshpnk22/how-to-upload-50-opencv-frames-into-cloud-storage-within-1-second-653ee73d7711)
- [Egocentric Videoconferencing (2020)](http://gvv.mpi-inf.mpg.de/projects/EgoChat/) - Method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. ([Video overview](https://www.youtube.com/watch?v=atzPvW95ahQ))
- [gradslam](https://github.com/gradslam/gradslam) - Open source differentiable dense SLAM library for PyTorch.
- [High-Resolution Daytime Translation Without Domain Labels](https://github.com/saic-mdal/HiDT)
- [Holistically-Nested Edge Detection](https://github.com/s9xie/hed)
- [pycls](https://github.com/facebookresearch/pycls) - Image classification codebase, written in PyTorch.
- [PyTorch implementation of High-Fidelity Generative Image Compression + Routines for neural image compression](https://github.com/Justin-Tan/high-fidelity-generative-compression)
- [How Useful is Self-Supervised Pretraining for Visual Tasks?](https://github.com/princeton-vl/selfstudy)
- [PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models](https://github.com/adamian98/pulse)
- [InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image](https://github.com/facebookresearch/InterHand2.6M)
- [Multi-object trackers in Python](https://github.com/adipandas/multi-object-tracker) - Easy to use implementation of various multi-object tracking algorithms.
- [Stanford Vision and Learning Lab](http://svl.stanford.edu/) ([GitHub](https://github.com/StanfordVL))
- [Learning computer vision. Overview of methods and software (2018)](https://towardsdatascience.com/learning-computer-vision-41398ad9941f)
- [Image embeddings. Image similarity and building (2020)](https://medium.com/@rom1504/image-embeddings-ed1b194d113e) ([Code](https://github.com/rom1504/image_embeddings))
- [All You Need to Know About Object Detection Systems (2020)](https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/)
- [Lightly](https://github.com/lightly-ai/lightly) - Computer vision framework for self-supervised learning.
- [DISK: Learning local features with policy gradient (2020)](https://arxiv.org/abs/2006.13566) ([Code](https://github.com/cvlab-epfl/disk))
- [Caer](https://github.com/jasmcaus/caer) - Lightweight Computer Vision library for high-performance AI research. ([Intro](https://towardsdatascience.com/introducing-caer-modern-computer-vision-on-the-fly-1619d7155c15))
- [Awesome Image to Image Translation Papers](https://github.com/weihaox/awesome-image-translation)
- [EfficientDet: Scalable and Efficient Object Detection, in PyTorch](https://github.com/toandaominh1997/EfficientDet.Pytorch)
- [UNet: semantic segmentation with PyTorch](https://github.com/milesial/Pytorch-UNet)
- [Exploring Simple Siamese Representation Learning (2020)](https://arxiv.org/abs/2011.10566) ([Code](https://github.com/PatrickHua/SimSiam)) ([Code](https://github.com/facebookresearch/simsiam))
- [Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions](https://github.com/aimagelab/show-control-and-tell)
- [Nerfies: Deformable Neural Radiance Fields](https://nerfies.github.io/) ([Code](https://github.com/google/nerfies))
- [Timeception for Complex Action Recognition (2019)](https://arxiv.org/abs/1812.01289) ([Code](https://github.com/noureldien/timeception))
- [Programming Computer Vision with Python (2014)](http://programmingcomputervision.com/) ([Code](https://github.com/jesolem/PCV)) ([Notes](https://github.com/nico/cvbook))
- [Fast and Accurate One-Stage Space-Time Video Super-Resolution (2020)](https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020)
- [pixelNeRF: Neural Radiance Fields from One or Few Images (2020)](https://alexyu.net/pixelnerf/) ([Code](https://github.com/sxyu/pixel-nerf))
- [vedadet](https://github.com/Media-Smart/vedadet) - Single stage object detector toolbox based on PyTorch.
- [OneNet: End-to-End One-Stage Object Detection by Classification Cost](https://github.com/PeizeSun/OneNet)
- [Consistent Video Depth Estimation](https://github.com/facebookresearch/consistent_depth) - Estimate dense, flicker-free, geometrically consistent depth from monocular video, for example hand-held cell phone video.
- [Implicit Neural Representations with Periodic Activation Functions](https://github.com/vsitzmann/siren)
- [Computational Imaging Stanford Lab](http://www.computationalimaging.org/)
- [Trimap-Free Solution for Portrait Matting in Real Time](https://github.com/ZHKKKe/MODNet)
- [Local Light Field Fusion](https://github.com/Fyusion/LLFF)
- [Awesome Crowd Counting](https://github.com/gjy3035/Awesome-Crowd-Counting)
- [Neural Sparse Voxel Fields (NSVF)](https://github.com/facebookresearch/NSVF)
- [One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (2020)](https://arxiv.org/abs/2011.15126) ([Tweet](https://twitter.com/goodfellow_ian/status/1333845997697388544))
- [SharpAI DeepCamera](https://github.com/SharpAI/DeepCamera) - Source stack for machine learning engineering with private deployment and AutoML for edge computing. ([HN](https://news.ycombinator.com/item?id=25368272))
- [Contrastive learning of global and local features for medical image segmentation with limited annotations](https://github.com/krishnabits001/domain_specific_cl)
- [Real-Time High-Resolution Background Matting (2020)](https://arxiv.org/abs/2012.07810) ([Code](https://github.com/PeterL1n/BackgroundMattingV2))
- [Torchreid](https://github.com/KaiyangZhou/deep-person-reid) - Deep learning person re-identification in PyTorch.
- [Unsupervised Embedding Learning via Invariant and Spreading Instance Feature](https://github.com/mangye16/Unsupervised_Embedding_Learning)
- [img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation](https://github.com/vitoralbiero/img2pose)
- [SSD: Single Shot MultiBox Detector | a PyTorch Tutorial to Object Detection](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection)
- [PCT: Point Cloud Transformer (2020)](https://arxiv.org/pdf/2012.09688.pdf) ([Code](https://github.com/MenghaoGuo/PCT))
- [Learning Continuous Image Representation with Local Implicit Image Function (2020)](https://arxiv.org/abs/2012.09161) ([Code](https://github.com/yinboc/liif))
- [Computer Vision Annotation Tool (CVAT)](https://github.com/openvinotoolkit/cvat)
- [DeiT: Data-efficient Image Transformers](https://github.com/facebookresearch/deit)
- [Awesome Implicit Neural Representations](https://github.com/vsitzmann/awesome-implicit-representations)
- [ImageAI](https://github.com/OlafenwaMoses/ImageAI) - Python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities. ([Web](http://imageai.org/))
- [RAIVN Lab](https://raivn.cs.washington.edu/) - Reasoning, AI and VisioN (RAIVN) Lab. ([GitHub](https://github.com/RAIVNLab))
- [Norfair](https://github.com/tryolabs/norfair) - Customizable lightweight Python library for real-time 2D object tracking.
- [Universal Style Transfer in PyTorch](https://github.com/sunshineatnoon/PytorchWCT)
- [NVIDIA Deep learning Dataset Synthesizer (NDDS)](https://github.com/NVIDIA/Dataset_Synthesizer)
- [Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization (2020)](https://paulbridger.com/posts/tensorrt-object-detection-quantized/)
- [HTML4Vision](https://github.com/mtli/HTML4Vision) - Simple HTML visualization tool for computer vision research.
- [Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders](https://github.com/taldatech/soft-intro-vae-pytorch)
- [Taming Transformers for High-Resolution Image Synthesis](https://github.com/CompVis/taming-transformers)
- [X-Temporal](https://github.com/Sense-X/X-Temporal) - Easily implement SOTA video understanding methods with PyTorch on multiple machines and GPUs.
- [NanoDet](https://github.com/RangiLyu/nanodet) - Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.
- [PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)
- [Awesome Vision and Language](https://github.com/sangminwoo/awesome-vision-and-language) - Curated list of awesome vision and language resources.
- [DropBlock: A regularization method for convolutional networks (2018)](https://arxiv.org/abs/1810.12890v1) ([Code](https://github.com/miguelvr/dropblock))
- [Glasses](https://github.com/FrancescoSaverioZuppichini/glasses) - Compact, concise and customizable deep learning computer vision library. ([Web](https://francescosaveriozuppichini.github.io/glasses-webapp/))
- [Explorable Super Resolution (2019)](https://github.com/YuvalBahat/Explorable-Super-Resolution)
- [PySceneDetect](https://github.com/Breakthrough/PySceneDetect) - Python and OpenCV-based scene cut/transition detection program & library.
- [Best Practices for Building Computer Vision Models (2021)](https://phaseai.com/resources/computer-vision-best-practices)
- [TIDE](https://github.com/dbolya/tide) - General Toolbox for Identifying Object Detection Errors.
- [Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (2020)](https://arxiv.org/abs/2011.12450) ([Code](https://github.com/PeizeSun/SparseR-CNN))
- [Unsplash Image Search](https://github.com/haltakov/natural-language-image-search) - Search photos on Unsplash using natural language.
- [Kimera Semantics](https://github.com/MIT-SPARK/Kimera-Semantics) - Real-Time 3D Semantic Reconstruction from 2D data.
- [Voxblox++](https://github.com/ethz-asl/voxblox-plusplus) - Volumetric object-level semantic mapping framework.
- [Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Surfaces](https://nv-tlabs.github.io/nglod/) ([Code](https://github.com/nv-tlabs/nglod))
- [Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video (2020)](https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/) ([Code](https://github.com/facebookresearch/nonrigid_nerf))
- [DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation (2019)](https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html) ([Code](https://github.com/facebookresearch/DeepSDF))
- [Awesome Neural Radiance Fields](https://github.com/yenchenlin/awesome-NeRF)
- [D2Det: Towards High Quality Object Detection and Instance Segmentation (2020)](https://github.com/JialeCao001/D2Det)
- [DetCo: Unsupervised Contrastive Learning for Object Detection (2021)](https://arxiv.org/abs/2102.04803) ([Code](https://github.com/xieenze/DetCo)) ([Code](https://github.com/shuuchen/DetCo.pytorch))
- [Computer Vision Video Lectures](https://github.com/kuzand/Computer-Vision-Video-Lectures) - Curated list of free, high-quality, university-level courses with video lectures related to the field of Computer Vision.
- [Cord](https://cord.tech/) - Training data toolbox for computer vision. ([HN](https://news.ycombinator.com/item?id=26104104))
- [Text-Guided Editing of Images (Using CLIP and StyleGAN)](https://github.com/orpatashnik/StyleCLIP)
- [torchvision](https://github.com/pytorch/vision) - Datasets, Transforms and Models specific to Computer Vision. ([Web](https://paperswithcode.com/lib/torchvision))
- [MeInGame: Create a Game Character Face from a Single Portrait (2021)](https://arxiv.org/abs/2102.02371) ([Code](https://github.com/FuxiCV/MeInGame))
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)
- [dataset-tools](https://github.com/dvschultz/dataset-tools) - Tools for quickly normalizing image datasets.
- [Using Streamlit to visualize object detection output (2021)](https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/)
- [Mobile Computer Vision @ Facebook](https://github.com/facebookresearch/mobile-vision)
- [Opening the black box of vision AI algorithms (2021)](https://medium.com/hasty-ai/opening-the-black-box-of-vision-ai-algorithms-466fc3d4bf78)
- [CompreFace](https://github.com/exadel-inc/CompreFace) - Free face recognition solution that can be easily integrated into any IT system without prior machine learning skills.
- [IBRNet: Learning Multi-View Image-Based Rendering (2021)](https://ibrnet.github.io/) ([Code](https://github.com/googleinterns/IBRNet))
- [From Coarse to Fine: Robust Hierarchical Localization at Large Scale (2019)](https://arxiv.org/abs/1812.03506) ([Code](https://github.com/ethz-asl/hfnet))
- [Camera Response Function (2021)](https://roboalgorithms.com/posts/camera-response-function/)
- [I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image (2020)](https://arxiv.org/abs/2008.03713) ([Code](https://github.com/mks0601/I2L-MeshNet_RELEASE))
- [SkipNet: Learning Dynamic Routing in Convolutional Networks (2018)](https://arxiv.org/abs/1711.09485) ([Code](https://github.com/ucbdrive/skipnet))
- [Mrcal](http://mrcal.secretsauce.net/) - Camera Calibrations and More. ([HN](https://news.ycombinator.com/item?id=26300118))
- [Digging Into Self-Supervised Monocular Depth Estimation (2019)](https://arxiv.org/abs/1806.01260) ([Code](https://github.com/nianticlabs/monodepth2)) ([Code](https://github.com/pxl-th/Monodepth2.jl))
- [VISSL](https://github.com/facebookresearch/vissl) - FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. ([Web](https://vissl.ai/))
- [Zumo Labs](https://www.zumolabs.ai/) - Generate custom synthetic data sets that result in more robust and reliable computer vision models. ([GitHub](https://github.com/ZumoLabs))
- [Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors (2020)](https://arxiv.org/abs/2008.07043) ([Code](https://github.com/yijingru/BBAVectors-Oriented-Object-Detection))
- [Perceiver: General Perception with Iterative Attention (2021)](https://arxiv.org/abs/2103.03206) ([Code](https://github.com/lucidrains/perceiver-pytorch))
- [SEER: The start of a more powerful, flexible, and accessible era for computer vision (2021)](https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision)
- [NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction (2021)](https://gafniguy.github.io/4D-Facial-Avatars/)
- [Neural 3D Video Synthesis](https://neural-3d-video.github.io/)
- [Involution: Inverting the Inherence of Convolution for Visual Recognition (2021)](https://arxiv.org/abs/2103.06255) ([Code](https://github.com/d-li14/involution))
- [Awesome Causality in Computer Vision](https://github.com/Wangt-CN/Awesome-Causality-in-CV)
- [Vision Transformers for Dense Prediction (2021)](https://arxiv.org/abs/2103.13413) ([Code](https://github.com/intel-isl/DPT))
- [LoFTR: Detector-Free Local Feature Matching with Transformers (2021)](https://arxiv.org/abs/2104.00680) ([Code](https://github.com/zju3dv/LoFTR))
- [ccv](https://github.com/liuliu/ccv) - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.
- [Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (2020)](https://arxiv.org/abs/2011.13084) ([Code](https://github.com/zhengqili/Neural-Scene-Flow-Fields))
- [AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control (2021)](https://xbpeng.github.io/projects/AMP/) ([Tweet](https://twitter.com/xbpeng4/status/1379465757688352769))
- [Computer Vision and Embroidery (2021)](https://healeycodes.com/computer-vision-and-embroidery/) ([Code](https://github.com/healeycodes/embroidery-vision))
- [mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields (2021)](https://jonbarron.info/mipnerf/)
- [Python libraries I use every day for computer vision work (2021)](https://twitter.com/svpino/status/1379666495811117062)
- [Awesome Temporal Sentence Grounding in Videos](https://github.com/Soldelli/Awesome-Temporal-Language-Grounding-in-Videos)
- [The Affective Growth of Computer Vision](https://authentic.sice.indiana.edu/publications/Su_Crandall-AffectiveGrowthCV-CVPR21.pdf)
- [Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D (2020)](https://arxiv.org/abs/2008.05711) ([Code](https://github.com/nv-tlabs/lift-splat-shoot))
- [End-to-End Video Instance Segmentation with Transformers (2021)](https://arxiv.org/abs/2011.14503) ([Code](https://github.com/Epiphqny/VisTR))
- [SAHI: Slicing Aided Hyper Inference](https://github.com/obss/sahi)
- [FOVO: A new 3D rendering technique based on human vision (2020)](https://www.gamasutra.com/blogs/RobertPepperell/20200527/363615/FOVO_A_new_3D_rendering_technique_based_on_human_vision.php) ([HN](https://news.ycombinator.com/item?id=26795290))
- [Is Space-Time Attention All You Need for Video Understanding? (2021)](https://arxiv.org/abs/2102.05095) ([Code](https://github.com/facebookresearch/TimeSformer))
- [Awesome Visual-Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer) - Transformer with Computer-Vision (CV) papers.
- [PyTorchVideo](https://github.com/facebookresearch/pytorchvideo) - Deep learning library for video understanding research. ([Web](https://pytorchvideo.org/))
- [Self-supervised Video Object Segmentation by Motion Grouping (2021)](https://charigyang.github.io/motiongroup/) ([HN](https://news.ycombinator.com/item?id=26842018)) ([Code](https://github.com/charigyang/motiongrouping))
- [torchvideo](https://github.com/torchvideo/torchvideo) - Datasets, transforms and samplers for video in PyTorch.
- [A General and Adaptive Robust Loss Function (2019)](https://arxiv.org/abs/1701.03077) ([Code](https://github.com/jonbarron/robust_loss_pytorch))
- [Self-supervising Fine-grained Region Similarities for Large-scale Image Localization (2020)](https://geyixiao.com/projects/sfrs) ([Code](https://github.com/yxgeee/OpenIBL))
- [MaX-DeepLab: Dual-Path Transformers for End-to-End Panoptic Segmentation (2021)](https://ai.googleblog.com/2021/04/max-deeplab-dual-path-transformers-for.html)
- [Vizy](https://vizycam.com/) - AI Camera.
- [MMPX Style-Preserving Pixel Art Magnification (2021)](https://casual-effects.com/research/McGuire2021PixelArt/McGuire2021PixelArt.pdf) ([HN](https://news.ycombinator.com/item?id=26934973))
- [Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion](https://hkchengrex.github.io/MiVOS/) ([Code](https://github.com/hkchengrex/Scribble-to-Mask))
- [SuperPoint: Self-Supervised Interest Point Detection and Description (2018)](https://arxiv.org/abs/1712.07629) ([Code](https://github.com/eric-yyjau/pytorch-superpoint))
- [Multi-Stage Progressive Image Restoration (2021)](https://arxiv.org/abs/2102.02808) ([Code](https://github.com/swz30/MPRNet))
- [COLMAP](https://github.com/colmap/colmap) - General-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. ([Docs](https://colmap.github.io/))
- [Awesome Vision-based SLAM / Visual Odometry](https://github.com/tzutalin/awesome-visual-slam)
- [Barlow Twins: Self-Supervised Learning via Redundancy Reduction (2021)](https://arxiv.org/abs/2103.03230) ([Code](https://github.com/facebookresearch/barlowtwins))
- [HIPCL](https://github.com/cpc/hipcl) - OpenCL/SPIR-V implementation of HIP.
- [MMCV](https://github.com/open-mmlab/mmcv) - Foundational library for computer vision research and supports many research projects. ([Docs](https://mmcv.readthedocs.io/en/latest/))
- [MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding (2021)](https://arxiv.org/abs/2104.12763) ([Code](https://github.com/ashkamath/mdetr))
- [Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples (2021)](https://arxiv.org/abs/2104.13963) ([Code](https://github.com/facebookresearch/suncet)) ([Code](https://github.com/facebookresearch/msn))
- [Emerging Properties in Self-Supervised Vision Transformers (2021)](https://arxiv.org/abs/2104.14294) ([Code](https://github.com/facebookresearch/dino)) ([Tweet](https://twitter.com/i/lists/1351120526220152839)) ([Tweet](https://twitter.com/schrep/status/1388189398496202752))
- [Geometry-Free View Synthesis: Transformers and no 3D Priors (2021)](https://arxiv.org/abs/2104.07652) ([Code](https://github.com/CompVis/geometry-free-view-synthesis))
- [Easily Transform Portraits of People into AI Aberrations Using StyleCLIP (2021)](https://minimaxir.com/2021/04/styleclip/)
- [DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates (2021)](https://arxiv.org/abs/2102.09105) ([Code](https://github.com/Colin97/DeepMetaHandles))
- [Onepanel](https://github.com/onepanelio/onepanel) - Open and extensible integrated development environment (IDE) for computer vision. ([Web](https://docs.onepanel.ai/))
- [Vector Neurons: A General Framework for SO(3)-Equivariant Networks (2021)](https://arxiv.org/abs/2104.12229) ([Code](https://github.com/FlyingGiraffe/vnn))
- [ISTR: End-to-End Instance Segmentation with Transformers (2021)](https://arxiv.org/abs/2105.00637) ([Code](https://github.com/hujiecpp/ISTR))
- [MLP-Mixer: An all-MLP Architecture for Vision (2021)](https://arxiv.org/abs/2105.01601) ([Code](https://github.com/lucidrains/mlp-mixer-pytorch)) ([Code](https://github.com/rishikksh20/MLP-Mixer-pytorch))
- [Self-attention building blocks for computer vision applications in PyTorch](https://github.com/The-AI-Summer/self-attention-cv)
- [LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference](https://github.com/facebookresearch/LeViT)
- [Text2Video: Text-driven Talking-head Video Synthesis with Phonetic Dictionary (2021)](https://arxiv.org/abs/2104.14631) ([Web](https://sites.google.com/view/sibozhang/text2video)) ([Code](https://github.com/sibozhang/Text2Video))
- [Neural Rendering: How Low Can You Go in Terms of Input? (2021)](https://www.unite.ai/neural-rendering-low-resolution-input-intel/)
- [Enhancing Photorealism Enhancement (2021)](https://intel-isl.github.io/PhotorealismEnhancement/) ([Paper](https://arxiv.org/abs/2105.04619)) ([Code](https://github.com/intel-isl/PhotorealismEnhancement))
- [DeepFaceEditing: Deep Face Generation and Editing with Disentangled Geometry and Appearance Control (2021)](http://www.geometrylearning.com/DeepFaceEditing/) ([Code](https://github.com/IGLICT/DeepFaceEditing-Jittor))
- [Omnimatte: Associating Objects and Their Effects in Video (2021)](https://omnimatte.github.io/)
- [Rethinking "Batch" in BatchNorm (2021)](https://arxiv.org/abs/2105.07576)
- [Most popular metrics used to evaluate object detection algorithms](https://github.com/rafaelpadilla/Object-Detection-Metrics)
- [UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation (2020)](https://arxiv.org/abs/2002.06353) ([Code](https://github.com/microsoft/UniVL))
- [Synthetic for Computer Vision](https://github.com/unrealcv/synthetic-computer-vision) - List of synthetic dataset and tools for computer vision.
- [vision_blender](https://github.com/Cartucho/vision_blender) - Blender addon for generating synthetic ground truth data for Computer Vision applications.
- [Easy Few-Shot Learning](https://github.com/sicara/easy-few-shot-learning) - Ready-to-use code and tutorial notebooks to boost your way into few-shot image classification.
- [BasicSR (Basic Super Restoration)](https://github.com/xinntao/BasicSR) - Open source image and video restoration toolbox based on PyTorch, such as super-resolution, denoise, deblurring, JPEG artifacts removal, etc.
- [Intriguing Properties of Vision Transformers (2021)](https://arxiv.org/abs/2105.10497) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/njm2ru/r_intriguing_properties_of_vision_transformers/))
- [DIY Amazon Go â computer vision tutorial for cashierless checkout](https://www.sbxrobotics.com/tutorial)
- [Image Retrieval in the Wild (2020)](https://matsui528.github.io/cvpr2020_tutorial_retrieval/)
- [Awesome Transformer in CV papers](https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV)
- [Sensor Calibration from Scratch with Rust (2021)](https://www.tangramvision.com/blog/calibration-from-scratch-using-rust-part-1-of-3)
- [Tangram Vision](https://www.tangramvision.com/) - Integrate, Calibrate Perception Sensors For Robots, Drones & Automation. ([Blog](https://www.tangramvision.com/blog))
- [Rust CV](https://github.com/rust-cv/cv) - Project to implement computer vision algorithms, abstractions, and systems in Rust.
- [Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control (2021)](http://gvv.mpi-inf.mpg.de/projects/NeuralActor/) ([HN](https://news.ycombinator.com/item?id=27393047))
- [Robust Instance Segmentation through Reasoning about Multi-Object Occlusion (2021)](https://arxiv.org/abs/2012.02107) ([Code](https://github.com/XD7479/Multi-Object-Occlusion))
- [MERLOT: Multimodal Neural Script Knowledge Models (2021)](https://arxiv.org/abs/2106.02636) ([Tweet](https://twitter.com/jmhessel/status/1401983972272345088))
- [Scaling Vision Transformers (2021)](https://arxiv.org/abs/2106.04560)
- [Self-Supervised Scene De-occlusion (2020)](https://arxiv.org/abs/2004.02788) ([Code](https://github.com/XiaohangZhan/deocclusion))
- [Pivotal Tuning for Latent-based Editing of Real Images (2021)](https://arxiv.org/abs/2106.05744) ([Code](https://github.com/danielroich/PTI))
- [FLAME: Articulated Expressive 3D Head Model](https://flame.is.tue.mpg.de/) ([Code](https://github.com/Rubikplayer/flame-fitting))
- [XCiT: Cross-Covariance Image Transformers (2021)](https://arxiv.org/abs/2106.09681) ([Code](https://github.com/facebookresearch/xcit))
- [Robust Consistent Video Depth Estimation (2021)](https://robust-cvd.github.io/) ([Code](https://github.com/facebookresearch/robust_cvd))
- [cvpods](https://github.com/Megvii-BaseDetection/cvpods) - All-in-one Toolbox for Computer Vision Research.
- [CDFI: Compression-Driven Network Design for Frame Interpolation (2021)](https://arxiv.org/abs/2103.10559) ([Code](https://github.com/tding1/CDFI))
- [NeRF--: Neural Radiance Fields Without Known Camera Parameters (2021)](https://nerfmm.active.vision/) ([Code](https://github.com/ActiveVisionLab/nerfmm)) ([Code](https://github.com/ventusff/improved-nerfmm))
- [Oxford Active Vision Laboratory](https://www.robots.ox.ac.uk/ActiveVision/) ([GitHub](https://github.com/ActiveVisionLab))
- [Computer Vision: Algorithms and Applications, 2nd ed.](http://szeliski.org/Book/)
- [motionEyeOS](https://github.com/ccrisan/motioneyeos) - Linux distribution that turns your single board computer into a video surveillance system.
- [Long-Short Transformer: Efficient Transformers for Language and Vision (2021)](https://arxiv.org/abs/2107.02192) ([Code](https://github.com/lucidrains/long-short-transformer))
- [Feature Visualization â How NNs understand images (2017)](https://distill.pub/2017/feature-visualization/)
- [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis (2019)](https://arxiv.org/abs/1904.01906) ([Code](https://github.com/clovaai/deep-text-recognition-benchmark))
- [Convolutional Hough Matching Networks (2021)](https://arxiv.org/abs/2103.16831) ([Code](https://github.com/juhongm999/chm))
- [Efficient Self-Supervised Vision Transformers (EsViT)](https://github.com/microsoft/esvit)
- [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (2021)](https://arxiv.org/abs/2103.10697) ([Code](https://github.com/facebookresearch/convit)) ([Paper Read](https://www.youtube.com/watch?v=QdbieYXn_XM)) ([Article](https://www.marktechpost.com/2021/07/20/facebook-ai-introduces-convit-a-computer-vision-model-that-improves-vision-transformers-vit-with-soft-convolutional-inductive-biases/))
- [CO3D: Common Objects In 3D](https://github.com/facebookresearch/co3d) - Tools for working with the Common Objects in 3D (CO3D) dataset.
- [ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition (2021)](https://arxiv.org/abs/2104.03841) ([Code](https://github.com/microsoft/ORBIT-Dataset))
- [Vision Transformer Architecture Search (2021)](https://arxiv.org/abs/2106.13700) ([Code](https://github.com/xiusu/ViTAS))
- [TSIT: A Simple and Versatile Framework for Image-to-Image Translation (2020)](https://arxiv.org/abs/2007.12072) ([Code](https://github.com/EndlessSora/TSIT))
- [Recognizing People in Photos Through Private On-Device Machine Learning (2021)](https://machinelearning.apple.com/research/recognizing-people-photos)
- [CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (2021)](https://arxiv.org/abs/2012.02047) ([Code](https://github.com/microsoft/CoCosNet-v2))
- [HPNet: Deep Primitive Segmentation Using Hybrid Representations (2021)](https://arxiv.org/abs/2105.10620) ([Code](https://github.com/SimingYan/HPNet))
- [Portal](https://github.com/datature/portal) - Fastest way to load and visualize your deep neural networks on images and videos.
- [Awesome Human Pose Estimation](https://github.com/cbsudux/awesome-human-pose-estimation)
- [Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)](https://arxiv.org/abs/2004.03791) ([Code](https://github.com/LongguangWang/ArbSR))
- [PyTorch implementation for Vision Transformer](https://github.com/omihub777/ViT-CIFAR)
- [Repulsive Curves](https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/index.html) - Model 2D & 3D curves while avoiding self-intersection. ([Tweet](https://twitter.com/keenanisalive/status/1422318272800829440)) ([Code](https://github.com/icethrush/repulsive-curves)) ([HN](https://news.ycombinator.com/item?id=31120139))
- [SDEdit: Image Synthesis and Editing with Stochastic Differential Equations](https://chenlin9.github.io/SDEdit/) ([Code](https://github.com/ermongroup/SDEdit))
- [Region Similarity Representation Learning (2021)](https://arxiv.org/abs/2103.12902) ([Code](https://github.com/Tete-Xiao/ReSim))
- [NeX: Real-time View Synthesis with Neural Basis Expansion (2021)](https://nex-mpi.github.io/) ([Code](https://github.com/nex-mpi/nex-code))
- [Convolutional Occupancy Networks (2020)](https://pengsongyou.github.io/conv_onet) ([Code](https://github.com/autonomousvision/convolutional_occupancy_networks))
- [Learning Optical Flow from a Few Matches (2021)](https://arxiv.org/abs/2104.02166) ([Code](https://github.com/zacjiang/SCV))
- [Visual Parser: Representing Part-whole Hierarchies with Transformers (2021)](https://arxiv.org/abs/2107.05790) ([Code](https://github.com/kevin-ssy/ViP))
- [Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation](http://jianghz.me/projects/superslomo/) ([Code](https://github.com/avinashpaliwal/Super-SloMo))
- [On Generating Transferable Targeted Perturbations (2021)](https://arxiv.org/abs/2103.14641) ([Code](https://github.com/Muzammal-Naseer/TTP))
- [Awesome Scene Understanding](https://github.com/bertjiazheng/awesome-scene-understanding) - List of papers for scene understanding.
- [Align before Fuse: Vision and Language Representation Learning with Momentum Distillation (2021)](https://arxiv.org/abs/2107.07651) ([Code](https://github.com/salesforce/ALBEF))
- [DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks (2021)](https://depthoraclenerf.github.io/) ([Code](https://github.com/facebookresearch/DONERF))
- [Object Detection in an Hour (2021)](https://www.strayrobots.io/blog/object-detection-in-an-hour) ([HN](https://news.ycombinator.com/item?id=28100346))
- [Fixing the train-test resolution discrepancy (2020)](https://arxiv.org/abs/1906.06423) ([Code](https://github.com/facebookresearch/FixRes))
- [Align Deep Features for Oriented Object Detection (2020)](https://arxiv.org/abs/2008.09397) ([Code](https://github.com/csuhan/s2anet))
- [Vision-Language Transformer and Query Generation for Referring Segmentation (2021)](https://arxiv.org/abs/2108.05565) ([Code](https://github.com/henghuiding/Vision-Language-Transformer))
- [Depth-supervised NeRF: Fewer Views and Faster Training for Free (2021)](https://www.cs.cmu.edu/~dsnerf/) ([Code](https://github.com/dunbar12138/DSNeRF))
- [SwinIR: Image Restoration Using Swin Transformer (2021)](https://arxiv.org/abs/2108.10257) ([Code](https://github.com/JingyunLiang/SwinIR))
- [You Only Learn One Representation: Unified Network for Multiple Tasks (2021)](https://arxiv.org/abs/2105.04206) ([Code](https://github.com/WongKinYiu/yolor))
- [Probabilistic Modeling for Human Mesh Recovery (2021)](https://arxiv.org/abs/2108.11944) ([Code](https://github.com/nkolot/ProHMR))
- [BARF: Bundle-Adjusting Neural Radiance Fields (2021)](https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/) ([Code](https://github.com/chenhsuanlin/bundle-adjusting-NeRF))
- [Self-Calibrating Neural Radiance Fields (2021)](https://postech-cvlab.github.io/SCNeRF/) ([Code](https://github.com/POSTECH-CVLab/SCNeRF))
- [Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials) - Demos I made with the Transformers library by HuggingFace.
- [3D Human Texture Estimation from a Single Image with Transformers (2021)](https://arxiv.org/abs/2109.02563) ([Code](https://github.com/xuxy09/Texformer))
- [CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval (2021)](https://arxiv.org/abs/2104.08860) ([Code](https://github.com/ArrowLuo/CLIP4Clip))
- [RAFT: Recurrent All Pairs Field Transforms for Optical Flow (2020)](https://arxiv.org/abs/2003.12039) ([Code](https://github.com/princeton-vl/RAFT))
- [Volume rendering + 3D implicit surface = Neural 3D Reconstruction](https://github.com/ventusff/neurecon)
- [Hierarchical Deep Stereo Matching on High-resolution Images (2019)](http://www.contrib.andrew.cmu.edu/~gengshay/cvpr19stereo) ([Code](https://github.com/gengshan-y/high-res-stereo))
- [Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering (2021)](https://zju3dv.github.io/object_nerf/) ([Code](https://github.com/zju3dv/object_nerf))
- [Image Synthesis via Semantic Composition (2021)](https://shepnerd.github.io/scg/) ([Code](https://github.com/dvlab-research/SCGAN))
- [Awesome-Edge-Detection-Papers](https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers)
- [Awesome-Image-Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization)
- [Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)](https://longguangwang.github.io/Project/ArbSR/) ([Code](https://github.com/LongguangWang/ArbSR))
- [Face Recognition](https://github.com/1adrianb/face-alignment) - 2D and 3D Face alignment library build using PyTorch.
- [Awesome image retrieval papers](https://github.com/willard-yuan/awesome-cbir-papers)
- [PeekingDuck](https://github.com/aimakerspace/PeekingDuck) - Modular framework built to simplify Computer Vision inference workloads.
- [Pri3D: Can 3D Priors Help 2D Representation Learning? (2021)](https://arxiv.org/abs/2104.11225) ([Code](https://github.com/Sekunde/Pri3D))
- [FaceXLib](https://github.com/xinntao/facexlib) - Aims at providing ready-to-use face-related functions based on current STOA open-source methods.
- [MMAction2](https://github.com/open-mmlab/mmaction2) - Open-source toolbox for video understanding based on PyTorch.
- [Awesome Collision Detection](https://github.com/jslee02/awesome-collision-detection)
- [Video Super-Resolution Transformer (2021)](https://arxiv.org/abs/2106.06847) ([Code](https://github.com/caojiezhang/VSR-Transformer))
- [NeRF Atlas](https://github.com/JulianKnodt/nerf_atlas) - Collection of NeRF extensions for fun and experimentation.
- [Training and testing codes for USRNet, DnCNN, FFDNet, SRMD, DPSR, MSRResNet, ESRGAN, BSRGAN, SwinIR](https://github.com/cszn/KAIR)
- [Uformer: A General U-Shaped Transformer for Image Restoration (2021)](https://arxiv.org/abs/2106.03106) ([Code](https://github.com/ZhendongWang6/Uformer)) ([Code](https://github.com/lucidrains/uformer-pytorch))
- [Self-Supervised Pretraining Improves Self-Supervised Pretraining (2021)](https://arxiv.org/abs/2103.12718) ([Code](https://github.com/cjrd/self-supervised-pretraining))
- [SNARF: Differentiable Forward Skinning for Animating Non-Rigid Neural Implicit Shapes (2021)](https://xuchen-ethz.github.io/snarf/) ([Code](https://github.com/xuchen-ethz/snarf))
- [HRFormer: High-Resolution Transformer for Dense Prediction, NeurIPS 2021](https://github.com/HRNet/HRFormer)
- [IceVision](https://github.com/airctic/icevision) - Agnostic Computer Vision Framework - Pluggable to any Training Library: Fastai, Pytorch-Lightning with more to come. ([Docs](https://airctic.com/))
- [e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks (2021)](https://arxiv.org/abs/2105.03761) ([Tweet](https://twitter.com/maximek3/status/1438554571756933127))
- [Attention Gated Networks (Image Classification & Segmentation) in PyTorch](https://github.com/ozan-oktay/Attention-Gated-Networks)
- [Full-Duplex Strategy for Video Object Segmentation (2021)](https://arxiv.org/abs/2108.03151v2) ([Code](https://github.com/GewelsJI/FSNet))
- [YoHa](https://handtracking.io/) - Practical hand tracking engine. ([HN](https://news.ycombinator.com/item?id=28825820)) ([Code](https://github.com/handtracking-io/yoha))
- [Deep Learning for Face Anti-Spoofing: A Survey (2021)](https://arxiv.org/abs/2106.14948) ([Code](https://github.com/ZitongYu/DeepFAS))
- [A-SDF: Learning Disentangled Signed Distance Functions for Articulated Shape Representation (2021)](https://arxiv.org/abs/2104.07645) ([Code](https://github.com/JitengMu/A-SDF))
- [Resolution-robust Large Mask Inpainting with Fourier Convolutions (2021)](https://saic-mdal.github.io/lama-project/) ([Code](https://github.com/saic-mdal/lama))
- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021)](https://arxiv.org/abs/2103.14030) ([Code](https://github.com/microsoft/Swin-Transformer)) ([Code](https://github.com/berniwal/swin-transformer-pytorch)) ([HN](https://news.ycombinator.com/item?id=35504052))
- [ADOP: Approximate Differentiable One-Pixel Point Rendering (2021)](https://arxiv.org/abs/2110.06635) ([Tweet](https://twitter.com/rodolfor/status/1448655222876741634)) ([Tweet](https://twitter.com/keenanisalive/status/1448708734511951879)) ([Code](https://github.com/darglein/ADOP))
- [Patches Are All You Need? (2021)](https://openreview.net/forum?id=TVHS5Y4dNvM) ([Code](https://github.com/tmp-iclr/convmixer))
- [ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation (2020)](https://arxiv.org/abs/2012.05258) ([Code](https://github.com/joe-siyuan-qiao/ViP-DeepLab))
- [Video Panoptic Segmentation (2020)](https://arxiv.org/abs/2006.11339) ([Code](https://github.com/mcahny/vps))
- [Awesome-ICCV2021-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-ICCV2021-Low-Level-Vision) - Collection of Papers and Codes for ICCV2021 Low Level Vision and Image Generation.
- [Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts (2021)](https://arxiv.org/abs/2104.00887) ([Code](https://github.com/clovaai/mxfont))
- [Non-deep Networks (2021)](https://arxiv.org/abs/2110.07641) ([Code](https://github.com/imankgoyal/NonDeepNetworks))
- [receptivefield](https://github.com/fornaxai/receptivefield) - Gradient based receptive field estimation for Convolutional Neural Networks.
- [Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations (2021)](https://igl.ethz.ch/projects/iso-points/) ([Code](https://github.com/yifita/iso-points))
- [Neural Articulated Radiance Field (2021)](https://arxiv.org/abs/2104.03110) ([Code](https://github.com/nogu-atsu/NARF))
- [Efficient Visual Pretraining with Contrastive Detection (2021)](https://arxiv.org/abs/2103.10957) ([Code](https://github.com/deepmind/detcon))
- [VoTT (Visual Object Tagging Tool)](https://github.com/microsoft/VoTT) - Source annotation and labeling tool for image and video assets.
- [FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes (2021)](https://arxiv.org/abs/2110.08059) ([Code](https://github.com/rjbruin/flexconv))
- [ByteTrack: Multi-Object Tracking by Associating Every Detection Box (2021)](https://arxiv.org/abs/2110.06864) ([Code](https://github.com/ifzhang/ByteTrack))
- [Dense Video Captioning with Bi-modal Transformer (2020)](https://iashin.ai/bmt) ([Code](https://github.com/v-iashin/BMT))
- [PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding) - CV toolkit for my papers. ([Docs](https://hangzhang.org/PyTorch-Encoding/))
- [Space Time Recurrent Memory Network (2021)](https://arxiv.org/abs/2109.06474) ([Code](https://github.com/lucidrains/spacetime-recurrent-memory-network))
- [CVNets](https://github.com/apple/ml-cvnets) - Library for training computer vision networks.
- [Scenic](https://github.com/google-research/scenic) - Jax Library for Computer Vision Research and Beyond. ([Paper](https://arxiv.org/abs/2110.11403))
- [CV Arxiv Daily](http://vincentqin.tech/cv-arxiv-daily/) ([Code](https://github.com/Vincentqyw/cv-arxiv-daily))
- [OpenVisionCapsules](https://github.com/opencv/open_vision_capsules) - Set of libraries for encapsulating smart vision algorithms.
- [MedMNIST: Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification](https://medmnist.com/) ([Code](https://github.com/MedMNIST/MedMNIST))
- [Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language (2021)](https://arxiv.org/abs/2110.15358) ([Code](https://github.com/dingmyu/VRDP))
- [Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces (2021)](https://arxiv.org/abs/2011.13495) ([Code](https://github.com/mabaorui/NeuralPull))
- [The 2021 Image Similarity Dataset and Challenge (2021)](https://arxiv.org/abs/2106.09672) ([Code](https://github.com/facebookresearch/isc2021))
- [K-Net: Towards Unified Image Segmentation (2021)](https://arxiv.org/abs/2106.14855) ([Code](https://github.com/ZwwWayne/K-Net))
- [Yolov5 + Deep Sort with PyTorch](https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch)
- [Shape As Points: A Differentiable Poisson Solver (2021)](https://arxiv.org/abs/2106.03452) ([Code](https://github.com/autonomousvision/shape_as_points))
- [Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm (2021)](https://arxiv.org/abs/2110.05208) ([Code](https://github.com/Sense-GVT/DeCLIP))
- [Awesome Vision-Language Navigation](https://github.com/daqingliu/awesome-vln)
- [An Exploration of Embodied Visual Exploration (2021)](http://vision.cs.utexas.edu/projects/exploring-exploration/) ([Code](https://github.com/facebookresearch/exploring_exploration))
- [DVC: An End-to-end Deep Video Compression Framework (2019)](https://arxiv.org/abs/1812.00101) ([Code](https://github.com/GuoLusjtu/DVC))
- [Pixray](https://github.com/dribnet/pixray) - Neural image generation.
- [Unsupervised Learning of Compositional Energy Concepts (2021)](https://arxiv.org/abs/2111.03042) ([Tweet](https://twitter.com/du_yilun/status/1456630363040751616))
- [Learning with Noisy Labels for Robust Point Cloud Segmentation (2021)](https://shuquanye.com/PNAL_website/) ([Code](https://github.com/pleaseconnectwifi/PNAL))
- [Kalidoface](https://github.com/yeemachine/kalidoface) - Become a virtual character with just your webcam. ([Web](https://kalidoface.com/))
- [KalidoKit](https://github.com/yeemachine/kalidokit) - Face, Pose, and Hand Tracking Kinematics.
- [The Ancient Secrets of Computer Vision](https://pjreddie.com/courses/computer-vision/)
- [Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training (2020)](https://arxiv.org/abs/2004.01178) ([Code](https://github.com/ShuhangGu/DASR))
- [PyGaze](https://www.pygaze.org/) - Open source eye-tracking software and more. ([HN](https://news.ycombinator.com/item?id=29171416))
- [Exploring Relational Context for Multi-Task Dense Prediction (2021)](https://arxiv.org/abs/2104.13874) ([Code](https://github.com/brdav/atrc))
- [Neural Scene Graphs for Dynamic Scenes (2021)](https://light.princeton.edu/publication/neural-scene-graphs/) ([Code](https://github.com/princeton-computational-imaging/neural-scene-graphs))
- [Image Super-Resolution via Iterative Refinement](https://iterative-refinement.github.io/) ([HN](https://news.ycombinator.com/item?id=29202899)) ([Code](https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement))
- [UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning (2021)](https://openreview.net/forum?id=nBU_u6DLvoK) ([Code](https://github.com/lucidrains/uniformer-pytorch))
- [Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers (2021)](https://arxiv.org/abs/2106.05392) ([Code](https://github.com/facebookresearch/Motionformer))
- [Multimodal Virtual Point 3D Detection (2021)](https://tianweiy.github.io/mvp/) ([Code](https://github.com/tianweiy/MVP))
- [SiT: Self-supervised vIsion Transformer](https://github.com/Sara-Ahmed/SiT)
- [Attention Mechanisms in Computer Vision: A Survey (2021)](https://arxiv.org/abs/2111.07624)
- [Awesome Vision Attention Papers](https://github.com/MenghaoGuo/Awesome-Vision-Attentions)
- [FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation (2021)](https://arxiv.org/abs/2103.04524) ([Code](https://github.com/ltkong218/FastFlowNet))
- [RenderNet: A deep convolutional network for differentiable rendering from 3D shapes (2018)](https://www.monkeyoverflow.com/#/rendernet-a-cnn-for-differentiable-rendering-from-3d-shapes/) ([Code](https://github.com/thunguyenphuoc/RenderNet))
- [Masked Autoencoders Are Scalable Vision Learners (2021)](https://arxiv.org/abs/2111.06377) ([Code](https://github.com/pengzhiliang/MAE-pytorch)) ([Code](https://github.com/facebookresearch/mae)) ([Code](https://github.com/catalys1/mae-pytorch))
- [BoostingMonocularDepth](https://github.com/compphoto/BoostingMonocularDepth)
- [It's About Time: Analog Clock Reading in the Wild (2021)](https://arxiv.org/abs/2111.09162) ([Tweet](https://twitter.com/giffmana/status/1461249563466022913)) ([Code](https://github.com/charigyang/itsabouttime))
- [Learning to Compose Visual Relations (2021)](https://composevisualrelations.github.io/) ([Code](https://github.com/nanlliu/compose-visual-relations))
- [LF-Net: Learning Local Features from Images (2018)](https://arxiv.org/abs/1805.09662) ([Code](https://github.com/vcg-uvic/lf-net-release))
- [Aligning Pretraining for Detection via Object-Level Contrastive Learning (2021)](https://arxiv.org/abs/2106.02637) ([Code](https://github.com/hologerry/SoCo))
- [Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis (2021)](https://arxiv.org/abs/2111.04138) ([Code](https://github.com/fel-thomas/Sobol-Attribution-Method))
- [Deep unfolding network for image super-resolution (2020)](https://github.com/cszn/USRNet)
- [VOLO: Vision Outlooker for Visual Recognition (2021)](https://arxiv.org/abs/2106.13112) ([Code](https://github.com/sail-sg/volo))
- [Direct Multi-view Multi-person 3D Pose Estimation (2021)](https://arxiv.org/abs/2111.04076) ([Code](https://github.com/sail-sg/mvp))
- [Image2Mesh: A learning framework for single image 3D reconstruction (2019)](https://jhonykaesemodel.com/publication/image2mesh/) ([Code](https://github.com/jhonykaesemodel/image2mesh))
- [GammaCV](https://github.com/PeculiarVentures/GammaCV) - WebGL accelerated Computer Vision library for modern web applications. ([Web](https://gammacv.com/))
- [Localizing Objects with Self-Supervised Transformers and no Labels (2021)](https://arxiv.org/abs/2109.14279) ([Code](https://github.com/valeoai/LOST))
- [Harvester](https://github.com/genicam/harvesters) - GenICam-based Image Acquisition Python Library.
- [NÃWA: Visual Synthesis Pre-training for Neural visUal World creAtion (2021)](https://arxiv.org/abs/2111.12417) ([Code](https://github.com/microsoft/NUWA)) ([PyTorch Code](https://github.com/lucidrains/nuwa-pytorch))
- [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision (2021)](https://arxiv.org/abs/2102.03334) ([Code](https://github.com/dandelin/ViLT))
- [MetaFormer is Actually What You Need for Vision (2021)](https://arxiv.org/abs/2111.11418) ([Code](https://github.com/sail-sg/poolformer))
- [ARAPReg: An As-Rigid-As Possible Regularization Loss for Learning Deformable Shape Generators (2021)](https://arxiv.org/abs/2108.09432) ([Code](https://github.com/GitBoSun/ARAPReg))
- [Mesa: A Memory-saving Training Framework for Transformers (2021)](https://arxiv.org/abs/2111.11124) ([Code](https://github.com/zhuang-group/Mesa))
- [MMPose](https://github.com/open-mmlab/mmpose) - Open-source toolbox for pose estimation based on PyTorch. ([Docs](https://mmpose.readthedocs.io/en/latest/))
- [An Empirical Study of Training End-to-End Vision-and-Language Transformers (2021)](https://arxiv.org/abs/2111.02387) ([Code](https://github.com/zdou0830/METER))
- [Useful computer vision PhD resources](https://github.com/hassony2/useful-computer-vision-phd-resources)
- [Tenyks](https://www.tenyks.ai/) - Data-centric Computer Vision.
- [Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation (2021)](https://bowenc0221.github.io/mask2former/) ([Code](https://github.com/facebookresearch/Mask2Former))
- [GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields (2021)](https://m-niemeyer.github.io/project-pages/giraffe/index.html) ([Code](https://github.com/autonomousvision/giraffe))
- [Learning to See by Looking at Noise (2021)](https://mbaradad.github.io/learning_with_noise/) ([Code](https://github.com/mbaradad/learning_with_noise))
- [iBOT: Image BERT Pre-Training with Online Tokenizer (2021)](https://arxiv.org/abs/2111.07832) ([Code](https://github.com/bytedance/ibot))
- [Grounded Language-Image Pre-training (2021)](https://arxiv.org/abs/2112.03857) ([Code](https://github.com/microsoft/GLIP))
- [3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction (2016)](https://arxiv.org/abs/1604.00449) ([Code](https://github.com/chrischoy/3D-R2N2))
- [Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks](http://proceedings.mlr.press/v97/lee19d.html) ([Code](https://github.com/juho-lee/set_transformer))
- [Awesome Visual Grounding](https://github.com/TheShadow29/awesome-grounding)
- [Are Transformers More Robust Than CNNs? (2021)](https://arxiv.org/abs/2111.05464) ([Code](https://github.com/ytongbai/ViTs-vs-CNNs))
- [Plenoxels: Radiance Fields without Neural Networks (2021)](https://alexyu.net/plenoxels/) ([Code](https://github.com/sxyu/svox2)) ([Code](https://github.com/sarafridov/plenoxels))
- [GFPGAN](https://github.com/TencentARC/GFPGAN) - Developing Practical Algorithms for Real-world Face Restoration.
- [Awesome Video Stabilization](https://github.com/yaochih/awesome-video-stabilization)
- [MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo (2021)](https://apchenstu.github.io/mvsnerf/) ([Code](https://github.com/apchenstu/mvsnerf))
- [Tracking People with 3D Representations (2021)](http://people.eecs.berkeley.edu/~jathushan/T3DP/) ([Code](https://github.com/brjathu/T3DP))
- [Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection (2019:)](https://arxiv.org/abs/1908.09492) ([Code](https://github.com/poodarchu/Det3D))
- [Learning to Stylize Novel Views (2021)](https://hhsinping.github.io/3d_scene_stylization/) ([Code](https://github.com/hhsinping/stylescene))
- [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX) - High-performance anchor-free YOLO. ([Docs](https://yolox.readthedocs.io/en/latest/))
- [PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop (2021)](https://hongwenzhang.github.io/pymaf/) ([Code](https://github.com/HongwenZhang/PyMAF))
- [SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation (2021)](https://arxiv.org/abs/2112.08275) ([Code](https://github.com/wjf5203/SeqFormer))
- [NeRD: Neural Reflectance Decomposition from Image Collections (2021)](https://markboss.me/publication/2021-nerd/) ([Code](https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition))
- [Vector Quantized Diffusion Model for Text-to-Image Synthesis (2021)](https://arxiv.org/abs/2111.14822) ([Code](https://github.com/microsoft/VQ-Diffusion)) ([Code](https://github.com/cientgu/VQ-Diffusion)) ([Code](https://github.com/microsoft/VQ-Diffusion))
- [GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models (2021)](https://arxiv.org/abs/2112.10741) ([Code](https://github.com/openai/glide-text2im))
- [SynthDet](https://github.com/Unity-Technologies/SynthDet) - End-to-end object detection pipeline using synthetic data.
- [MPViT: Multi-Path Vision Transformer for Dense Prediction (2021)](https://arxiv.org/abs/2112.11010) ([Code](https://github.com/youngwanLEE/MPViT))
- [StyleSwin: Transformer-based GAN for High-resolution Image Generation (2021)](https://arxiv.org/abs/2112.10762) ([Code](https://github.com/microsoft/StyleSwin))
- [Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline (2021)](https://arxiv.org/abs/2106.05304) ([Code](https://github.com/princeton-vl/SimpleView))
- [SLIP: Self-supervision meets Language-Image Pre-training (2021)](https://arxiv.org/abs/2112.12750) ([Code](https://github.com/facebookresearch/SLIP))
- [General Facial Representation Learning in a Visual-Linguistic Manner (2021)](https://arxiv.org/abs/2112.03109) ([Code](https://github.com/microsoft/FaRL)) ([Code](https://github.com/FacePerceiver/FaRL))
- [HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields](https://hypernerf.github.io/) ([Code](https://github.com/google/hypernerf)) ([HN](https://news.ycombinator.com/item?id=29698276))
- [Learning to Regress Bodies from Images using Differentiable Semantic Rendering (2021)](https://arxiv.org/abs/2110.03480) ([Code](https://github.com/saidwivedi/DSR))
- [High-Resolution Image Synthesis with Latent Diffusion Models (2021)](https://arxiv.org/abs/2112.10752) ([Code](https://github.com/CompVis/latent-diffusion))
- [Photorealistic Audio-driven Video Portraits (2020)](https://richardt.name/publications/audio-dvp/) ([Code](https://github.com/xinwen-cs/AudioDVP))
- [Awesome Hand Pose Estimation](https://github.com/xinghaochen/awesome-hand-pose-estimation)
- [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers (2021)](https://arxiv.org/abs/2103.15679) ([Code](https://github.com/hila-chefer/Transformer-MM-Explainability))
- [Transformer Interpretability Beyond Attention Visualization (2021)](https://arxiv.org/abs/2012.09838) ([Code](https://github.com/hila-chefer/Transformer-Explainability))
- [StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Synthesis (2021)](https://arxiv.org/abs/2111.03133) ([Code](https://github.com/pschaldenbrand/StyleCLIPDraw))
- [Light Field Image Super-Resolution with Transformers (2021)](https://arxiv.org/abs/2108.07597) ([Code](https://github.com/ZhengyuLiang24/LFT))
- [Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes (2021)](https://arxiv.org/abs/2111.12701) ([Code](https://github.com/samb-t/unleashing-transformers))
- [DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample (2021)](https://www.vision.huji.ac.il/deepsim/) ([Code](https://github.com/eliahuhorwitz/DeepSIM))
- [RAFT-3D: Scene Flow using Rigid-Motion Embeddings (2021)](https://arxiv.org/abs/2012.00726) ([Code](https://github.com/princeton-vl/RAFT-3D))
- [Unsupervised Indoor Depth Estimation (2020)](https://jwbian.net/unsupervised-indoor-depth) ([Code](https://github.com/JiawangBian/Unsupervised-Indoor-Depth))
- [A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose (2021)](https://arxiv.org/abs/2102.06199) ([Code](https://github.com/LemonATsu/A-NeRF))
- [Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective (2021)](https://arxiv.org/abs/2103.17263) ([Code](https://github.com/xvjiarui/VFS#readme))
- [Sara](https://gitlab.com/DO-CV/sara) - Easy-to-Use C++ Computer Vision Library.
- [RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching (2021)](https://arxiv.org/abs/2109.07547) ([Code](https://github.com/princeton-vl/RAFT-Stereo))
- [U-2-Net: Going Deeper with Nested U-Structure for Salient Object Detection (2020)](https://arxiv.org/abs/2005.09007) ([Code](https://github.com/Norod/U-2-Net-StyleTransfer))
- [Language as Queries for Referring Video Object Segmentation (2022)](https://arxiv.org/abs/2201.00487) ([Code](https://github.com/wjn922/ReferFormer))
- [Localization with Sampling-Argmax (2021)](https://arxiv.org/abs/2110.08825) ([Code](https://github.com/Jeff-sjtu/sampling-argmax))
- [VOCA: Voice Operated Character Animation](https://voca.is.tue.mpg.de/) ([Code](https://github.com/TimoBolkart/voca))
- [CVZone](https://github.com/cvzone/cvzone) - Computer vision package that makes its easy to run Image processing and AI functions.
- [Deepface](https://github.com/serengil/deepface) - Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python.
- [Location-aware Single Image Reflection Removal (2021)](https://arxiv.org/abs/2012.07131) ([Code](https://github.com/zdlarr/Location-aware-SIRR))
- [MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement (2021)](https://arxiv.org/abs/2104.08223) ([Code](https://github.com/facebookresearch/meshtalk))
- [Detecting Twenty-thousand Classes using Image-level Supervision (2022)](https://arxiv.org/abs/2201.02605) ([Code](https://github.com/facebookresearch/Detic))
- [Language-driven Semantic Segmentation (2022)](https://arxiv.org/abs/2201.03546) ([Code](https://github.com/isl-org/lang-seg))
- [Rethinking Nearest Neighbors for Visual Classification (2021)](https://arxiv.org/abs/2112.08459) ([Code](https://github.com/KMnP/nn-revisit))
- [Vision Transformer with Deformable Attention (2022)](https://arxiv.org/abs/2201.00520) ([Code](https://github.com/LeapLabTHU/DAT)) ([Code](https://github.com/lucidrains/deformable-attention))
- [KerasCV](https://github.com/keras-team/keras-cv) - Industry-strength Computer Vision workflows with Keras.
- [Instant Neural Graphics Primitives](https://github.com/NVlabs/instant-ngp) - Lightning fast NeRF and more.
- [Dynamic Head: Unifying Object Detection Heads with Attentions (2021)](https://arxiv.org/abs/2106.08322) ([Code](https://github.com/microsoft/DynamicHead))
- [ELSA: Enhanced Local Self-Attention for Vision Transformer (2021)](https://arxiv.org/abs/2112.12786) ([Code](https://github.com/damo-cv/ELSA))
- [FFCV](https://github.com/libffcv/ffcv) - Fast Forward Computer Vision (and other ML workloads!) ([Web](https://ffcv.io/))
- [Awesome Vit](https://github.com/open-mmlab/awesome-vit) - Curated list and survey of awesome Vision Transformers.
- [Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (2022)](https://nvlabs.github.io/instant-ngp/) ([Code](https://github.com/ashawkey/torch-ngp)) ([Code](https://github.com/yashbhalgat/HashNeRF-pytorch)) ([Video Summary](https://www.youtube.com/watch?v=j8tMk-GE8hY)) ([HN](https://news.ycombinator.com/item?id=30408898))
- [Road Extraction by Deep Residual U-Net (2017)](https://arxiv.org/abs/1711.10684) ([Code](https://github.com/nikhilroxtomar/Deep-Residual-Unet))
- [Single-Stage 6D Object Pose Estimation (2019)](https://arxiv.org/abs/1911.08324) ([Code](https://github.com/cvlab-epfl/single-stage-pose))
- [Visual Task Adaptation Benchmark (VTAB)](https://github.com/google-research/task_adaptation)
- [TAda! Temporally-Adaptive Convolutions for Video Understanding (2022)](https://tadaconv-iclr2022.github.io/) ([Code](https://github.com/alibaba-mmai-research/TAdaConv))
- [UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction (2021)](https://moechsle.github.io/unisurf/) ([Code](https://github.com/autonomousvision/unisurf))
- [Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects (2020)](http://visual.cs.ucl.ac.uk/pubs/cofusion/index.html) ([Code](https://github.com/martinruenz/co-fusion))
- [VRT: A Video Restoration Transformer (2021)](https://arxiv.org/abs/2201.12288) ([Code](https://github.com/JingyunLiang/VRT))
- [Unknown Object Segmentation from Stereo Images (2021)](https://arxiv.org/abs/2103.06796) ([Code](https://github.com/DLR-RM/instr))
- [Stacked Cross Attention for Image-Text Matching (2018)](https://arxiv.org/abs/1803.08024) ([Code](https://github.com/kuanghuei/SCAN))
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (2022)](https://arxiv.org/abs/2201.12086) ([Code](https://github.com/salesforce/BLIP))
- [DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows (2021)](https://arxiv.org/abs/2101.05796) ([Code](https://github.com/volflow/DeFlow))
- [DocFormer: End-to-End Transformer for Document Understanding (2022)](https://arxiv.org/abs/2106.11539) ([Code](https://github.com/shabie/docformer))
- [SeMask: Semantically Masked Transformers for Semantic Segmentation (2021)](https://arxiv.org/abs/2112.12782) ([Code](https://github.com/Picsart-AI-Research/SeMask-Segmentation))
- [Image Quality Assessment: Unifying Structure and Texture Similarity (2020)](https://arxiv.org/abs/2004.07728) ([Code](https://github.com/dingkeyan93/DISTS))
- [Learning Super-Features for Image Retrieval (2022)](https://github.com/naver/fire)
- [YOLOv7](https://github.com/jinfagang/yolov7) - Framework Beyond Detection.
- [A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model (2021)](https://arxiv.org/abs/2112.14757) ([Code](https://github.com/MendelXu/zsseg.baseline))
- [Single/Multiple Object Tracking and Segmentation](https://github.com/JudasDie/SOTS)
- [Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection (2021)](https://arxiv.org/abs/2109.07950) ([Code](https://github.com/meilfang/LMFD-PAD))
- [HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping (2021)](https://arxiv.org/abs/2106.09965) ([Code](https://github.com/mindslab-ai/hififace))
- [Scalable Large Scene Neural View Synthesis (2022)](https://waymo.com/research/block-nerf/) ([HN](https://news.ycombinator.com/item?id=30299498))
- [Transformer Recipe](https://github.com/dair-ai/Transformers-Recipe) - Quick recipe to learn all about Transformers.
- [NeROIC: Neural Rendering of Objects from Online Image Collections (2022)](https://arxiv.org/abs/2201.02533) ([Code](https://github.com/snap-research/NeROIC))
- [DiffusionNet: Discretization Agnostic Learning on Surfaces (2022)](https://arxiv.org/abs/2012.00888) ([Code](https://github.com/nmwsharp/diffusion-net))
- [FILM: Frame Interpolation for Large Motion (2022)](https://film-net.github.io/) ([Code](https://github.com/google-research/frame-interpolation)) ([HN](https://news.ycombinator.com/item?id=32659679))
- [Learning Signed Distance Field for Multi-view Surface Reconstruction (2021)](https://arxiv.org/abs/2108.09964) ([Code](https://github.com/jzhangbs/MVSDF))
- [Deep Metric Learning in PyTorch](https://github.com/bnu-wangxun/Deep_Metric)
- [ICON: Implicit Clothed humans Obtained from Normals (2021)](https://icon.is.tue.mpg.de/) ([Code](https://github.com/YuliangXiu/ICON))
- [CLIPasso: Semantically-Aware Object Sketching (2022)](https://clipasso.github.io/clipasso/) ([Code](https://github.com/yael-vinker/CLIPasso))
- [BANMo: Building Animatable 3D Neural Models from Many Casual Videos (2022)](https://banmo-www.github.io/) ([Code](https://github.com/facebookresearch/banmo))
- [How Do Vision Transformers Work?](https://github.com/xxxnell/how-do-vits-work)
- [Top 10 Computer Vision Papers of 2021](https://github.com/louisfb01/top-10-cv-papers-2021)
- [Exploring Sparsity in Image Super-Resolution for Efficient Inference (2021)](https://arxiv.org/abs/2006.09603) ([Code](https://github.com/The-Learning-And-Vision-Atelier-LAVA/SMSR))
- [AutoInt: Automatic Integration for Fast Neural Volume Rendering (2021)](https://github.com/computational-imaging/automatic-integration)
- [Learning to Prompt for Vision-Language Models (2021)](https://arxiv.org/abs/2109.01134) ([Code](https://github.com/KaiyangZhou/CoOp))
- [Summarizing Videos with Attention (2019)](https://arxiv.org/abs/1812.01969) ([Code](https://github.com/ok1zjf/VASNet))
- [vkit](https://github.com/vkit-dev/vkit) - Toolkit designed for CV (Computer Vision) developers. ([Docs](https://vkit-dev.github.io/))
- [Generative Adversarial Graph Convolutional Networks for Human Action Synthesis (2021)](https://arxiv.org/abs/2110.11191) ([Code](https://github.com/DegardinBruno/Kinetic-GAN))
- [Awesome Image Matting](https://github.com/wchstrife/Awesome-Image-Matting)
- [Image-to-Markup Generation with Coarse-to-Fine Attention](http://lstm.seas.harvard.edu/latex/) ([Code](https://github.com/harvardnlp/im2markup))
- [Push-ups with Python, mediapipe and OpenCV](https://aryanvij02.medium.com/push-ups-with-python-mediapipe-open-a544bd9b4351) ([HN](https://news.ycombinator.com/item?id=30402651))
- [Lama-cleaner: Image inpainting tool powered by LaMa](https://github.com/Sanster/lama-cleaner)
- [Vision-Language Pre-Training with Triple Contrastive Learning (2022)](https://arxiv.org/abs/2202.10401) ([Code](https://github.com/uta-smile/TCL))
- [3D Machine Learning resources/papers](https://github.com/timzhang642/3D-Machine-Learning)
- [FiftyOne](https://github.com/voxel51/fiftyone) - Open-source tool for building high-quality datasets and computer vision models.
- [Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut (2022)](https://arxiv.org/abs/2202.11539) ([Code](https://github.com/YangtaoWANG95/TokenCut))
- [Awesome Multiple object Tracking](https://github.com/luanshiyinyang/awesome-multiple-object-tracking)
- [Rethinking Coarse-to-Fine Approach in Single Image Deblurring (2021)](https://arxiv.org/abs/2108.05054) ([Code](https://github.com/chosj95/MIMO-UNet))
- [Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling (2021)](https://arxiv.org/abs/2102.06183) ([Code](https://github.com/jayleicn/ClipBERT))
- [As-ViT: Auto-scaling Vision Transformers without Training (2022)](https://arxiv.org/abs/2202.11921) ([Code](https://github.com/VITA-Group/AsViT))
- [Awesome 3D Body Papers](https://github.com/3DFaceBody/awesome-3dbody-papers)
- [RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth (2021)](https://arxiv.org/abs/2108.00616) ([Code](https://github.com/MengyangPu/RINDNet))
- [Image Similarity Challenge](https://github.com/drivendataorg/image-similarity-challenge)
- [Blended Diffusion for Text-driven Editing of Natural Images (2021)](https://arxiv.org/abs/2111.14818) ([Code](https://github.com/omriav/blended-diffusion))
- [The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization (2021)](https://arxiv.org/abs/2006.16241) ([Code](https://github.com/hendrycks/imagenet-r))
- [Awesome Object Pose](https://github.com/nkalavak/awesome-object-pose)
- [Video Enhancement papers/resources](https://github.com/yulunzhang/video-enhancement)
- [PowerQE: An Open Framework for Quality Enhancement of Compressed Visual Data](https://github.com/ryanxingql/powerqe)
- [Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels (2022)](https://arxiv.org/abs/2203.03884) ([Code](https://github.com/Haochen-Wang409/U2PL))
- [Accurate Image Alignment and Registration Using OpenCV (2022)](https://magamig.github.io/posts/accurate-image-alignment-and-registration-using-opencv/) ([HN](https://news.ycombinator.com/item?id=30613745))
- [Video Grounding and Captioning](https://github.com/facebookresearch/grounded-video-description)
- [Awesome Detection Transformer](https://github.com/IDEACVR/awesome-detection-transformer)
- [StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis (2021)](https://arxiv.org/abs/2110.08985) ([Code](https://github.com/facebookresearch/StyleNeRF)) ([Web](http://jiataogu.me/style_nerf/)) ([HN](https://news.ycombinator.com/item?id=30637403))
- [Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition (2020)](https://arxiv.org/abs/2006.11538) ([Code](https://github.com/iduta/pyconv))
- [MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation (2021)](https://arxiv.org/abs/2111.12707) ([Code](https://github.com/Vegetebird/MHFormer))
- [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (2022)](https://arxiv.org/abs/2203.03605) ([Code](https://github.com/IDEACVR/DINO))
- [Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation (2022)](https://github.com/zubair-irshad/CenterSnap)
- [CycleMLP: A MLP-like Architecture for Dense Prediction (2022)](https://arxiv.org/abs/2107.10224) ([Code](https://github.com/ShoufaChen/CycleMLP))
- [Image Quality Assessment Benchmark](https://github.com/weizhou-geek/Image-Quality-Assessment-Benchmark)
- [StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation (2021)](https://arxiv.org/abs/2112.11427) ([Code](https://github.com/royorel/StyleSDF))
- [Transformers, originally designed to handle language, are taking on vision (2022)](https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/) ([HN](https://news.ycombinator.com/item?id=30629214))
- [Fast Image Processing with Fully-Convolutional Networks (2017)](https://arxiv.org/abs/1709.00643) ([Code](https://github.com/nrupatunga/Fast-Image-Filters))
- [Efficient Attention: Attention with Linear Complexities (2020)](https://arxiv.org/abs/1812.01243) ([Code](https://github.com/cmsflash/efficient-attention))
- [Label-Efficient Semantic Segmentation with Diffusion Models (2022)](https://yandex-research.github.io/ddpm-segmentation/) ([Code](https://github.com/yandex-research/ddpm-segmentation))
- [hloc](https://github.com/cvg/Hierarchical-Localization) - Modular toolbox for state-of-the-art 6-DoF visual localization.
- [All Tokens Matter: Token Labeling for Training Better Vision Transformers (2021)](https://arxiv.org/abs/2104.10858) ([Code](https://github.com/zihangJiang/TokenLabeling))
- [Deformable ConvNets v2: More Deformable, Better Results (2018)](https://arxiv.org/abs/1811.11168) ([Code](https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch))
- [Restormer: Efficient Transformer for High-Resolution Image Restoration (2021)](https://arxiv.org/abs/2111.09881) ([Code](https://github.com/swz30/Restormer))
- [Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice (2022)](https://openreview.net/forum?id=O476oWmiNNp) ([Code](https://github.com/VITA-Group/ViT-Anti-Oversmoothing))
- [NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video (2021)](https://zju3dv.github.io/neuralrecon/) ([Code](https://github.com/zju3dv/NeuralRecon))
- [Awesome 3D Human Reconstruction](https://github.com/rlczddl/awesome-3d-human-reconstruction)
- [Awesome 3D Human Resources List](https://github.com/lijiaman/awesome-3d-human)
- [A ConvNet for the 2020s (2022)](https://arxiv.org/abs/2201.03545) ([Code](https://github.com/facebookresearch/ConvNeXt)) ([Code](https://github.com/FrancescoSaverioZuppichini/ConvNext))
- [Remote-sensing-image-semantic-segmentation](https://github.com/TachibanaYoshino/Remote-sensing-image-semantic-segmentation) - Uses Unet-based improved networks to study Remote sensing image semantic segmentation, which is based on keras.
- [Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies (2021)](https://arxiv.org/abs/2105.02872) ([Code](https://github.com/zju3dv/animatable_nerf))
- [TensoRF: Tensorial Radiance Fields (2022)](https://arxiv.org/abs/2203.09517) ([Code](https://github.com/apchenstu/TensoRF))
- [Autoregressive Image Generation using Residual Quantization (2022)](https://arxiv.org/abs/2203.01941) ([Code](https://github.com/lucidrains/RQ-Transformer)) ([Code](https://github.com/kakaobrain/rq-vae-transformer))
- [Pix2Pix Timbre Transfer](https://github.com/hmartelb/Pix2Pix-Timbre-Transfer)
- [One-Shot Adaptation of GAN in Just One CLIP (2022)](https://arxiv.org/abs/2203.09301) ([Code](https://github.com/submission6378/OneshotCLIP))
- [PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds (2021)](https://arxiv.org/abs/2103.14635) ([Code](https://github.com/CVMI-Lab/PAConv))
- [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training (2022)](https://arxiv.org/abs/2203.12602) ([Code](https://github.com/MCG-NJU/VideoMAE))
- [Awesome Masked Image Modeling](https://github.com/ucasligang/awesome-MIM)
- [BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training (2022)](https://arxiv.org/abs/2203.13249) ([Code](https://github.com/amazon-research/bigdetection))
- [A Transformer-Based Siamese Network for Change Detection (2022)](https://arxiv.org/abs/2201.01293) ([Code](https://github.com/wgcban/ChangeFormer))
- [Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition (2021)](https://arxiv.org/abs/2103.01486) ([Code](https://github.com/QVPR/Patch-NetVLAD))
- [Robust fine-tuning of zero-shot models (2022)](https://arxiv.org/abs/2109.01903) ([Code](https://github.com/mlfoundations/wise-ft))
- [DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision (2021)](https://arxiv.org/abs/2105.06464) ([Code](https://github.com/NVlabs/DiscoBox))
- [GroupViT: Semantic Segmentation Emerges from Text Supervision (2022)](https://arxiv.org/abs/2202.11094) ([Code](https://github.com/NVlabs/GroupViT))
- [HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening (2022)](https://arxiv.org/abs/2203.02503) ([Code](https://github.com/wgcban/HyperTransformer))
- [TVConv: Efficient Translation Variant Convolution for Layout-aware Visual Processing (2022)](https://arxiv.org/abs/2203.10489) ([Code](https://github.com/JierunChen/TVConv))
- [DeepStream-Yolo](https://github.com/marcoslucianops/DeepStream-Yolo) - NVIDIA DeepStream SDK 6.0.1 configuration for YOLO models.
- [An Empirical Investigation of 3D Anomaly Detection and Segmentation (2022)](https://arxiv.org/abs/2203.05550) ([Code](https://github.com/eliahuhorwitz/3D-ADS))
- [Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation (2021)](https://arxiv.org/abs/2111.04017) ([Code](https://github.com/syguan96/DynaBOA))
- [Layered Neural Atlases for Consistent Video Editing (2021)](https://arxiv.org/abs/2109.11418) ([Code](https://github.com/ykasten/layered-neural-atlases))
- [TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution (2020)](https://github.com/YapengTian/TDAN-VSR-CVPR-2020)
- [Shape from Polarization for Complex Scenes in the Wild (2022)](https://chenyanglei.github.io/sfpwild/index.html) ([Code](https://github.com/ChenyangLEI/sfp-wild))
- [Pix2Seq](https://github.com/google-research/pix2seq) - General framework for turning RGB pixels into semantically meaningful sequences.
- [Gait Recognition in the Wild with Dense 3D Representations and A Benchmark (2022)](https://gait3d.github.io/) ([Code](https://github.com/Gait3D/Gait3D-Benchmark))
- [Ensembling Hugging Face Transformers made easy](https://github.com/jaketae/ensemble-transformers)
- [Relational Knowledge Distillation (2019)](https://arxiv.org/abs/1904.05068) ([Code](https://github.com/lenscloth/RKD))
- [NICE-SLAM: Neural Implicit Scalable Encoding for SLAM (2021)](https://arxiv.org/abs/2112.12130) ([Code](https://github.com/cvg/nice-slam))
- [Neural 3D Mesh Renderer (2017)](https://arxiv.org/abs/1711.07566) ([Code](https://github.com/daniilidis-group/neural_renderer))
- [Large-scale Bilingual Language-Image Contrastive Learning (2022)](https://arxiv.org/abs/2203.14463) ([Code](https://github.com/navervision/KELIP))
- [OpenMVG](https://github.com/openMVG/openMVG) - Open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion.
- [Neural Points: Point Cloud Representation with Neural Fields (2021)](https://arxiv.org/abs/2112.04148) ([Code](https://github.com/WanquanF/NeuralPoints))
- [OpenCV JS Web Worker](https://github.com/vinissimus/opencv-js-webworker) - Getting started with OpenCV compiled to Webassembly and loaded in a worker.
- [Learning Graph Regularisation for Guided Super-Resolution (2022)](https://arxiv.org/abs/2203.14297) ([Code](https://github.com/prs-eth/graph-super-resolution))
- [Video Polyp Segmentation: A Deep Learning Perspective (2022)](https://arxiv.org/abs/2203.14291) ([Code](https://github.com/GewelsJI/VPS))
- [Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images (2022)](https://arxiv.org/abs/2203.13664) ([Code](https://github.com/MathLee/ACCoNet))
- [HybridNets: End-to-End Perception Network (2022)](https://arxiv.org/abs/2203.09035) ([Code](https://github.com/datvuthanh/HybridNets))
- [HDR-NeRF: High Dynamic Range Neural Radiance Fields (2022)](https://xhuangcv.github.io/hdr-nerf/) ([Code](https://github.com/shsf0817/hdr-nerf)) ([HN](https://news.ycombinator.com/item?id=35717106))
- [AdaMixer: A Fast-Converging Query-Based Object Detector (2022)](https://arxiv.org/abs/2203.16507) ([Code](https://github.com/MCG-NJU/AdaMixer))
- [MixFormer: End-to-End Tracking with Iterative Mixed Attention (2022)](https://arxiv.org/abs/2203.11082) ([Code](https://github.com/MCG-NJU/MixFormer))
- [Bringing Old Films Back to Life (2022)](http://raywzy.com/Old_Film/) ([Code](https://github.com/raywzy/Bringing-Old-Films-Back-to-Life))
- [Extracting Triangular 3D Models, Materials, and Lighting From Images (2022)](https://nvlabs.github.io/nvdiffrec/) ([Code](https://github.com/NVlabs/nvdiffrec))
- [LiT: Zero-Shot Transfer with Locked-image text Tuning (2021)](https://arxiv.org/abs/2111.07991) ([Tweet](https://twitter.com/giffmana/status/1508400604082806785))
- [LAFITE: Towards Language-Free Training for Text-to-Image Generation (2021)](https://arxiv.org/abs/2111.13792) ([Code](https://github.com/drboog/Lafite))
- [Neural 3D Video Synthesis from Multi-view Video (2022)](https://neural-3d-video.github.io/) ([Code](https://github.com/facebookresearch/Neural_3D_Video))
- [ToFu: Topologically Consistent Multi-View Face Inference Using Volumetric Sampling (2021)](https://github.com/tianyeli/tofu)
- [Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning (2019)](https://arxiv.org/abs/1904.01786) ([Code](https://github.com/ShichenLiu/SoftRas))
- [FrankMocap: A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator (2021)](https://github.com/facebookresearch/frankmocap)
- [Reddit Place Script 2022](https://github.com/rdeepak2002/reddit-place-script-2022) - Script to draw an image onto r/place.
- [A Unified Objective for Novel Class Discovery (2021)](https://arxiv.org/abs/2108.08536) ([Code](https://github.com/DonkeyShot21/UNO))
- [Papers and Datasets about Point Cloud](https://github.com/zhulf0804/3D-PointCloud)
- [On the Importance of Asymmetry for Siamese Representation Learning (2022)](https://arxiv.org/abs/2204.00613) ([Code](https://github.com/facebookresearch/asym-siam))
- [REGTR: End-to-end Point Cloud Correspondences with Transformers](https://github.com/yewzijian/RegTR)
- [A Closer Look at Local Aggregation Operators in Point Cloud Analysis (2020)](https://arxiv.org/abs/2007.01294) ([Code](https://github.com/zeliu98/CloserLook3D))
- [Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries (2022)](https://arxiv.org/abs/2203.15355) ([Code](https://github.com/clovaai/puridiver))
- [Perception Prioritized Training of Diffusion Models (2022)](https://arxiv.org/abs/2204.00227) ([Code](https://github.com/jychoi118/P2-weighting))
- [VisualBERT: A Simple and Performant Baseline for Vision and Language (2019)](https://arxiv.org/abs/1908.03557) ([Code](https://github.com/uclanlp/visualbert))
- [MultiMAE: Multi-modal Multi-task Masked Autoencoders (2022)](https://arxiv.org/abs/2204.01678) ([Code](https://github.com/EPFL-VILAB/MultiMAE))
- [NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (2021)](https://arxiv.org/abs/2106.10689) ([Code](https://github.com/Totoro97/NeuS))
- [Towards Open World Object Detection (2021)](https://arxiv.org/abs/2103.02603) ([Code](https://github.com/JosephKJ/OWOD))
- [Transformer in Vision](https://github.com/DirtyHarryLYL/Transformer-in-Vision) - Recent Transformer-based CV and related works.
- [Shunted Self-Attention via Multi-Scale Token Aggregation (2021)](https://arxiv.org/abs/2111.15193) ([Code](https://github.com/OliverRensu/Shunted-Transformer))
- [Space-Time Correspondence as a Contrastive Random Walk (2020)](https://ajabri.github.io/videowalk/) ([Code](https://github.com/ajabri/videowalk))
- [MaskGIT: Masked Generative Image Transformer (2022)](https://arxiv.org/abs/2202.04200) ([Code](https://github.com/google-research/maskgit))
- [EasyCV](https://github.com/alibaba/EasyCV) - All-in-one computer vision toolbox based on PyTorch.
- [Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection (2022)](https://arxiv.org/abs/2204.02964) ([Code](https://github.com/hustvl/MIMDet))
- [EMOCA: Emotion Driven Monocular Face Capture and Animation (2022)](https://github.com/radekd91/emoca)
- [Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation (2022)](https://arxiv.org/abs/2203.13161) ([Code](https://github.com/alvinliu0/HA2G))
- [FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset](http://www.liuyebin.com/faceverse/faceverse.html) ([Code](https://github.com/LizhenWangT/FaceVerse))
- [PointCLIP: Point Cloud Understanding by CLIP (2022)](https://arxiv.org/abs/2112.02413) ([Code](https://github.com/ZrrSkywalker/PointCLIP))
- [DaViT: Dual Attention Vision Transformers (2022)](https://arxiv.org/abs/2204.03645) ([Code](https://github.com/dingmyu/davit))
- [DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers (2022)](https://arxiv.org/abs/2202.04053) ([Code](https://github.com/j-min/DallEval))
- [Recovering 3D Human Mesh from Monocular Images: A Survey (2022)](https://arxiv.org/abs/2203.01923) ([Code](https://github.com/tinatiansjz/hmr-survey))
- [Video Diffusion Models (2022)](https://arxiv.org/abs/2204.03458v1) ([Web](https://video-diffusion.github.io/)) ([Code](https://github.com/lucidrains/video-diffusion-pytorch))
- [MaxViT: Multi-Axis Vision Transformer (2022)](https://arxiv.org/abs/2204.01697) ([Code](https://github.com/ChristophReich1996/MaxViT))
- [Unified Contrastive Learning in Image-Text-Label Space (2022)](https://arxiv.org/abs/2204.03610) ([Code](https://github.com/microsoft/UniCL))
- [RePOSE: Fast 6D Object Pose Refinement via Deep Texture Rendering (2021)](https://arxiv.org/abs/2104.00633) ([Code](https://github.com/sh8/RePOSE))
- [MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition (2021)](https://arxiv.org/abs/2103.12579) ([Code](https://github.com/BIT-DA/MetaSAug))
- [Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (2022)](https://arxiv.org/abs/2203.07615) ([Code](https://github.com/chunbolang/BAM))
- [MAXIM: Multi-Axis MLP for Image Processing (2022)](https://arxiv.org/abs/2201.02973) ([Code](https://github.com/google-research/maxim))
- [Tensil tutorial for YOLO v4 Tiny on Ultra96 V2 (2022)](https://k155la3.blog/2022/04/04/tensil-tutorial-for-yolo-v4-tiny-on-ultra96-v2/)
- [UNITER: UNiversal Image-TExt Representation Learning (2020)](https://arxiv.org/abs/1909.11740) ([Code](https://github.com/ChenRocks/UNITER))
- [Consistent Depth of Moving Objects in Video (2021)](https://dynamic-video-depth.github.io/) ([Code](https://github.com/google/dynamic-video-depth))
- [Bridging Video-text Retrieval with Multiple Choice Questions (2022)](https://arxiv.org/abs/2201.04850) ([Code](https://github.com/TencentARC/MCQ))
- [Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation (2020)](https://arxiv.org/abs/2001.08735) ([Code](https://github.com/hytseng0509/CrossDomainFewShot))
- [BACON: Band-limited Coordinate Networks for Multiscale Scene Representation (2022)](https://arxiv.org/abs/2112.04645) ([Code](https://github.com/computational-imaging/bacon))
- [Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results (2022)](https://arxiv.org/abs/2204.03475) ([Code](https://github.com/Alibaba-MIIL/Solving_ImageNet))
- [Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering (2021)](https://www.vincentsitzmann.com/lfns/) ([Code](https://github.com/vsitzmann/light-field-networks))
- [SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image (2022)](https://arxiv.org/abs/2204.00928) ([Code](https://github.com/VITA-Group/SinNeRF))
- [StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions (2021)](https://arxiv.org/abs/2112.01530) ([Code](https://github.com/lukasHoel/stylemesh))
- [Neighborhood Attention Transformer (2022)](https://arxiv.org/abs/2204.07143) ([Code](https://github.com/SHI-Labs/Neighborhood-Attention-Transformer))
- [3D Surface Reconstruction From Multi-Date Satellite Images (2021)](https://arxiv.org/abs/2102.02502) ([Code](https://github.com/SBCV/SatelliteSurfaceReconstruction))
- [Decoupling Makes Weakly Supervised Local Feature Better (2022)](https://arxiv.org/abs/2201.02861) ([Code](https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat))
- [ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic (2022)](https://arxiv.org/abs/2111.14447) ([Code](https://github.com/YoadTew/zero-shot-image-to-text))
- [EasyMocap](https://github.com/zju3dv/EasyMocap) - Open-source toolbox for markerless human motion capture from RGB videos.
- [QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation (2022)](https://arxiv.org/abs/2203.08483) ([Code](https://github.com/sapphire497/query-selected-attention))
- [PolarMask: Single Shot Instance Segmentation with Polar Representation (2019)](https://arxiv.org/abs/1909.13226) ([Code](https://github.com/xieenze/PolarMask))
- [Latent Video Transformer (2020)](https://arxiv.org/abs/2006.10704) ([Code](https://github.com/rakhimovv/lvt))
- [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (2020)](https://arxiv.org/abs/2003.08934) ([JAX Code](https://github.com/unixpickle/learn-nerf))
- [A Latent Transformer for Disentangled Face Editing in Images and Videos (2021)](https://arxiv.org/abs/2106.11895) ([Code](https://github.com/InterDigitalInc/latent-transformer))
- [Photorealistic Style Transfer via Wavelet Transforms (2019)](https://arxiv.org/abs/1903.09760) ([Code](https://github.com/clovaai/WCT2))
- [Probing ViTs](https://github.com/sayakpaul/probing-vits)
- [Dense Depth Priors for Neural Radiance Fields from Sparse Input Views (2021)](https://arxiv.org/abs/2112.03288) ([Code](https://github.com/barbararoessle/dense_depth_priors_nerf))
- [Self-Supervised Models are Continual Learners (2021)](https://arxiv.org/abs/2112.04215) ([Code](https://github.com/DonkeyShot21/cassle))
- [Mask Transfiner for High-Quality Instance Segmentation (2022)](https://www.vis.xyz/pub/transfiner/) ([Code](https://github.com/SysCV/transfiner))
- [An Extendable, Efficient and Effective Transformer-based Object Detector (2022)](https://github.com/naver-ai/vidt)
- [Learned Queries for Efficient Local Attention (2021)](https://arxiv.org/abs/2112.11435) ([Code](https://github.com/moabarar/qna))
- [3D Human Pose Estimation with Spatial and Temporal Transformers (2021)](https://arxiv.org/abs/2103.10455) ([Code](https://github.com/zczcwh/PoseFormer))
- [3D human pose estimation in video with temporal convolutions and semi-supervised training (2019)](https://arxiv.org/abs/1811.11742) ([Code](https://github.com/facebookresearch/VideoPose3D))
- [MC-Calib: A generic and robust calibration toolbox for multi-camera systems (2022)](https://www.sciencedirect.com/science/article/abs/pii/S1077314221001818) ([Code](https://github.com/rameau-fr/MC-Calib))
- [Understanding The Robustness in Vision Transformers (2022)](https://arxiv.org/abs/2204.12451) ([Code](https://github.com/NVlabs/FAN))
- [Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation (2021)](https://arxiv.org/abs/2111.14826) ([Code](https://github.com/liuzechun/Nonuniform-to-Uniform-Quantization))
- [Tackling multiple tasks with a single visual language model (2022)](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model) ([Code](https://github.com/lucidrains/flamingo-pytorch)) ([Tweet](https://twitter.com/DeepMind/status/1519686445258231811))
- [Associating Objects with Transformers for Video Object Segmentation (2021)](https://arxiv.org/abs/2106.02638) ([Code](https://github.com/z-x-yang/AOT))
- [Simple multi-dataset detection](https://github.com/xingyizhou/UniDet) - Object detection on multiple datasets with an automatically learned unified label space.
- [Learning Texture Transformer Network for Image Super-Resolution (2020)](https://arxiv.org/abs/2006.04139) ([Code](https://github.com/researchmm/TTSR))
- [Balanced MSE for Imbalanced Visual Regression (2022)](https://arxiv.org/abs/2203.16427) ([Code](https://github.com/jiawei-ren/BalancedMSE))
- [Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions (2022)](https://arxiv.org/abs/2203.17234) ([Code](https://github.com/nv-nguyen/template-pose))
- [Action-Conditioned 3D Human Motion Synthesis with Transformer VAE (2021)](https://arxiv.org/abs/2104.05670) ([Code](https://github.com/Mathux/ACTOR))
- [CoMoGAN: continuous model-guided image-to-image translation (2021)](https://arxiv.org/abs/2103.06879) ([Code](https://github.com/cv-rits/CoMoGAN))
- [OpenMVS](https://github.com/cdcseacave/openMVS) - Open Multi-View Stereo reconstruction library.
- [Sliced Recursive Transformer (2021)](https://arxiv.org/abs/2111.05297) ([Code](https://github.com/szq0214/SReT))
- [Neural Dual Contouring (2022)](https://arxiv.org/abs/2202.01999) ([Code](https://github.com/czq142857/NDC))
- [Awesome Deblurring](https://github.com/subeeshvasu/Awesome-Deblurring) - Curated list of resources for Image and Video Deblurring.
- [CoCa: Contrastive Captioners are Image-Text Foundation Models (2022)](https://arxiv.org/abs/2205.01917) ([Code](https://github.com/lucidrains/CoCa-pytorch))
- [Sequencer: Deep LSTM for Image Classification (2022)](https://arxiv.org/abs/2205.01972)
- [Language Models Can See: Plugging Visual Controls in Text Generation (2022)](https://arxiv.org/abs/2205.02655) ([Code](https://github.com/yxuansu/MAGIC))
- [flyswot](https://github.com/davanstrien/flyswot) - CLI for Hugging Face Transformers image classification models.
- [Neural 3D Scene Reconstruction with the Manhattan-world Assumption (2022)](https://zju3dv.github.io/manhattan_sdf/) ([Code](https://github.com/zju3dv/manhattan_sdf))
- [PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision (2022)](https://arxiv.org/abs/2203.15625) ([Code](https://github.com/Garfield-kh/PoseTriplet))
- [What do the Vision Transformers learn? How do they encode anything useful for image recognition? (2022)](https://twitter.com/RisingSayak/status/1515918406171914240)
- [Integrative Few-Shot Learning for Classification and Segmentation (2022)](https://arxiv.org/abs/2203.15712) ([Code](https://github.com/dahyun-kang/ifsl))
- [DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus (2022)](https://arxiv.org/abs/2111.08799) ([Code](https://github.com/rubenwiersma/deltaconv))
- [pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis (2021)](https://arxiv.org/abs/2012.00926) ([Code](https://github.com/lucidrains/pi-GAN-pytorch))
- [Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (2022)](https://arxiv.org/abs/2202.03052) ([Code](https://github.com/OFA-Sys/OFA))
- [ConvMAE: Masked Convolution Meets Masked Autoencoders (2022)](https://arxiv.org/abs/2205.03892) ([Code](https://github.com/Alpha-VL/ConvMAE))
- [Deep Kernelized Dense Geometric Matching (2022)](https://arxiv.org/abs/2202.00667) ([Code](https://github.com/Parskatt/DKM))
- [Unsupervised Semantic Segmentation by Distilling Feature Correspondences (2022)](https://arxiv.org/abs/2203.08414) ([Code](https://github.com/mhamilton723/STEGO))
- [RecursiveMix: Mixed Learning with History (2022)](https://arxiv.org/abs/2203.06844) ([Code](https://github.com/implus/RecursiveMix-pytorch))
- [MMDetection3d](https://github.com/open-mmlab/mmdetection3d) - OpenMMLab's next-generation platform for general 3D object detection.
- [Imagen: Text-to-Image Diffusion Models](https://imagen.research.google/) ([Tweet](https://twitter.com/JeffDean/status/1528951937948741632)) ([Code](https://github.com/lucidrains/imagen-pytorch)) ([HN](https://news.ycombinator.com/item?id=31484562)) ([HN](https://news.ycombinator.com/item?id=31513919))
- [An End-to-End Transformer Model for 3D Object Detection (2021)](https://arxiv.org/abs/2109.08141) ([Code](https://github.com/facebookresearch/3detr))
- [Neural 3D Reconstruction in the Wild (2022)](https://arxiv.org/abs/2205.12955) ([Code](https://github.com/zju3dv/NeuralRecon-W))
- [Body shape and pose estimation on 3D scans of people in clothing using Ceres Solver](https://github.com/maria-korosteleva/Body-Shape-Estimation)
- [A Survey of Visual Transformers (2021)](https://arxiv.org/abs/2111.06091) ([Code](https://github.com/liuyang-ict/awesome-visual-transformers))
- [Nerfies: Deformable Neural Radiance Fields (2021)](https://nerfies.github.io/) ([Code](https://github.com/nerfies/nerfies.github.io))
- [Working notes on the role of vision papers in basic science (2022)](https://scienceplusplus.org/visions/index.html) ([Tweet](https://twitter.com/michael_nielsen/status/1530659395453202433))
- [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers (2022)](https://github.com/THUDM/CogVideo) ([HN](https://news.ycombinator.com/item?id=31561845))
- [Prompt-aligned Gradient for Prompt Tuning (2022)](https://arxiv.org/abs/2205.14865) ([Code](https://github.com/BeierZhu/Prompt-align))
- [Text2Human: Text-Driven Controllable Human Image Generation (2022)](https://arxiv.org/abs/2205.15996) ([Code](https://github.com/yumingj/Text2Human))
- [OnePose: One-Shot Object Pose Estimation without CAD Models (2022)](https://arxiv.org/abs/2205.12257) ([Code](https://github.com/zju3dv/OnePose))
- [OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models (2022)](https://zju3dv.github.io/onepose_plus_plus/) ([Code](https://github.com/zju3dv/OnePose_Plus_Plus))
- [PREF: Phasorial Embedding Fields for Compact Neural Representations (2022)](https://arxiv.org/abs/2205.13524) ([Code](https://github.com/hbb1/PREF))
- [Optimizing Relevance Maps of Vision Transformers Improves Robustness (2022)](https://arxiv.org/abs/2206.01161) ([Code](https://github.com/hila-chefer/RobustViT))
- [Exploring Visual Prompts for Adapting Large-Scale Models (2022)](https://arxiv.org/abs/2203.17274) ([Code](https://github.com/hjbahng/visual_prompting))
- [Deepfake Offensive Toolkit](https://github.com/sensity-ai/dot) - Makes real-time, controllable deepfakes ready for virtual cameras injection. ([HN](https://news.ycombinator.com/item?id=31650797))
- [Real-time Object Detection for Streaming Perception (2022)](https://arxiv.org/abs/2203.12338) ([Code](https://github.com/yancie-yjr/StreamYOLO))
- [Volumentations 3D](https://github.com/ZFTurbo/volumentations) - Library for 3D augmentations.
- [Awesome Learning with Label Noise](https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise)
- [LIVE: Towards Layer-wise Image Vectorization (2022)](https://ma-xu.github.io/LIVE/) ([Code](https://github.com/ma-xu/LIVE))
- [BEVT: BERT Pretraining of Video Transformers (2021)](https://arxiv.org/abs/2112.01529) ([Code](https://github.com/xyzforever/BEVT))
- [Variable Bitrate Neural Fields (2022)](https://nv-tlabs.github.io/vqad/) ([Code](https://github.com/nv-tlabs/vqad))
- [Gated-SCNN: Gated Shape CNNs for Semantic Segmentation (2019)](https://arxiv.org/abs/1907.05740) ([Code](https://github.com/nv-tlabs/GSCNN))
- [Masked Unsupervised Self-training for Zero-shot Image Classification (2022)](https://arxiv.org/abs/2206.02967) ([Code](https://github.com/salesforce/MUST))
- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video (2022)](https://arxiv.org/abs/2201.04127) ([Code](https://github.com/chungyiweng/humannerf))
- [Awesome Implicit NeRF Robotics](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)
- [EfficientFormer: Vision Transformers at MobileNet Speed (2022)](https://arxiv.org/abs/2206.01191) ([Code](https://github.com/snap-research/EfficientFormer))
- [ARF: Artistic Radiance Fields (2022)](https://www.cs.cornell.edu/projects/arf/) ([Code](https://github.com/Kai-46/ARF-svox2)) ([HN](https://news.ycombinator.com/item?id=31825177))
- [Patch2Pix: Epipolar-Guided Pixel-Level Correspondences (2020)](https://arxiv.org/abs/2012.01909) ([Code](https://github.com/GrumpyZhou/patch2pix))
- [Translating Images into Maps (2022)](https://arxiv.org/abs/2110.00966) ([Code](https://github.com/avishkarsaha/translating-images-into-maps))
- [Instances as Queries (2021)](https://arxiv.org/abs/2105.01928) ([Code](https://github.com/hustvl/QueryInst))
- [OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction (2022)](https://arxiv.org/abs/2203.07977) ([Code](https://github.com/wenbin-lin/OcclusionFusion))
- [CogView: Mastering Text-to-Image Generation via Transformers (2021)](https://arxiv.org/abs/2105.13290) ([Code](https://github.com/THUDM/CogView2))
- [All in One: Exploring Unified Video-Language Pre-training (2022)](https://arxiv.org/abs/2203.07303) ([Code](https://github.com/showlab/all-in-one))
- [Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization (2022)](https://arxiv.org/abs/2203.13167) ([Code](https://github.com/srvCodes/continual_learning_with_vit))
- [Solving Inefficiency of Self-supervised Representation Learning (2021)](https://arxiv.org/abs/2104.08760) ([Code](https://github.com/wanggrun/triplet))
- [NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination (2021)](https://arxiv.org/abs/2106.01970) ([Code](https://github.com/google/nerfactor))
- [Trending in 3D Vision](https://github.com/dragonlong/Trending-in-3D-Vision)
- [ShapeFormer: Transformer-based Shape Completion via Sparse Representation (2022)](https://shapeformer.github.io/) ([Code](https://github.com/QhelDIV/ShapeFormer))
- [Awesome Prompting Papers in Computer Vision](https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision)
- [EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation (2022)](https://arxiv.org/abs/2203.13254) ([Code](https://github.com/tjiiv-cprg/EPro-PnP))
- [GenDR: A Generalized Differentiable Renderer (2022)](https://arxiv.org/abs/2204.13845) ([Code](https://github.com/Felix-Petersen/gendr))
- [Elucidating the Design Space of Diffusion-Based Generative Models (2022)](https://arxiv.org/abs/2206.00364) ([Code](https://github.com/crowsonkb/k-diffusion)) ([Code](https://github.com/NVlabs/edm))
- [IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images (2022)](https://kai-46.github.io/IRON-website/) ([Code](https://github.com/Kai-46/IRON))
- [Omnivore: A Single Model for Many Visual Modalities (2022)](https://arxiv.org/abs/2201.08377) ([Code](https://github.com/facebookresearch/omnivore))
- [Benchmarking and Analyzing Point Cloud Classification under Corruptions (2022)](https://arxiv.org/abs/2202.03377) ([Code](https://github.com/ldkong1205/PointCloud-C))
- [DVGO: Direct Voxel Grid Optimization (Super-fast Convergence for Radiance Fields Reconstruction) (2022)](https://sunset1995.github.io/dvgo/) ([Code](https://github.com/sunset1995/DirectVoxGO))
- [RegionCLIP: Region-based Language-Image Pretraining (2021)](https://arxiv.org/abs/2112.09106) ([Code](https://github.com/microsoft/RegionCLIP))
- [Fast Light-Weight Near-Field Photometric Stereo (2022)](https://dlichy.github.io/fastNFPS.github.io/) ([Code](https://github.com/dlichy/FastNFPSCode))
- [ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models (2021)](https://arxiv.org/abs/2108.02938) ([Code](https://github.com/jychoi118/ilvr_adm))
- [RePaint: Inpainting using Denoising Diffusion Probabilistic Models](https://github.com/andreas128/RePaint)
- [The Probabilistic Normal Epipolar Constraint for Frame-To-Frame Rotation Optimization under Uncertain Feature Positions (2022)](https://arxiv.org/abs/2204.02256) ([Code](https://github.com/tum-vision/pnec))
- [3D Moments from Near-Duplicate Photos (2022)](https://arxiv.org/abs/2205.06255) ([Code](https://github.com/google-research/3d-moments))
- [Prototypical Contrastive Language Image Pretraining (2022)](https://arxiv.org/abs/2206.10996) ([Code](https://github.com/megvii-research/protoclip))
- [NeRV: Neural Representations for Videos (2021)](https://haochen-rye.github.io/NeRV/) ([Code](https://github.com/haochen-rye/NeRV))
- [MT-YOLOv6](https://github.com/meituan/YOLOv6) - Single-stage object detection framework dedicated to industrial applications.
- [Fast Point Transformer (2022)](https://arxiv.org/abs/2112.04702) ([Code](https://github.com/POSTECH-CVLab/FastPointTransformer))
- [FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation (2022)](https://arxiv.org/abs/2204.01587) ([Code](https://github.com/sohyun-l/fifo))
- [Nettle Magic Project](https://github.com/nettlep/magic) - Scanner for decks of cards with bar codes printed on card edges. ([HN](https://news.ycombinator.com/item?id=31922682))
- [Image Quality Assessment using Contrastive Learning (2021)](https://arxiv.org/abs/2110.13266) ([Code](https://github.com/pavancm/CONVIQT))
- [Denoised MDPs: Learning World Models Better Than The World Itself (2022)](https://ssnl.github.io/denoised_mdp/) ([Code](https://github.com/facebookresearch/denoised_mdp))
- [Sparse Instance Activation for Real-Time Instance Segmentation (2022)](https://arxiv.org/abs/2203.12827) ([Code](https://github.com/hustvl/SparseInst))
- [Referring Image Matting (2022)](https://arxiv.org/abs/2206.05149) ([Code](https://github.com/JizhiziLi/RIM))
- [Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds (2022)](https://arxiv.org/abs/2206.09900) ([Code](https://github.com/chaytonmin/Voxel-MAE))
- [Contrastive Boundary Learning for Point Cloud Segmentation (2022)](https://arxiv.org/abs/2203.05272) ([Code](https://github.com/LiyaoTang/contrastBoundary))
- [Scaling up Kernels in 3D CNNs (2022)](https://arxiv.org/abs/2206.10555) ([Code](https://github.com/dvlab-research/LargeKernel3D))
- [Oriented RepPoints for Aerial Object Detection (2022)](https://arxiv.org/abs/2105.11111v4) ([Code](https://github.com/LiWentomng/OrientedRepPoints))
- [Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly (2022)](https://arxiv.org/abs/2204.13631) ([Code](https://github.com/facebookresearch/reliable_vqa))
- [EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications (2022)](https://arxiv.org/abs/2206.10589) ([Code](https://github.com/mmaaz60/EdgeNeXt))
- [Awesome Visual Diffusion Models](https://github.com/Xiefan-Guo/Awesome-Visual-Diffusion-Models)
- [Vision Transformer Adapter for Dense Predictions (2022)](https://arxiv.org/abs/2205.08534) ([Code](https://github.com/czczup/ViT-Adapter))
- [Activating More Pixels in Image Super-Resolution Transformer (2022)](https://arxiv.org/abs/2205.04437) ([Code](https://github.com/XPixelGroup/HAT))
- [PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies (2022)](https://arxiv.org/abs/2206.04670) ([Code](https://github.com/guochengqian/PointNeXt))
- [GMFlow: Learning Optical Flow via Global Matching (2022)](https://arxiv.org/abs/2111.13680) ([Code](https://github.com/haofeixu/gmflow))
- [Vector-quantized Image Modeling with Improved VQGAN (2021)](https://arxiv.org/abs/2110.04627) ([JAX Code](https://github.com/patil-suraj/vit-vqgan))
- [Learned Vertex Descent: A New Direction for 3D Human Model Fitting (2022)](https://arxiv.org/abs/2205.06254) ([Code](https://github.com/enriccorona/LVD))
- [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (2022)](https://arxiv.org/abs/2207.02696) ([Code](https://github.com/WongKinYiu/yolov7))
- [AITViewer](https://github.com/eth-ait/aitviewer) - Set of tools to visualize and interact with sequences of 3D data.
- [Object-Compositional Neural Implicit Surfaces](https://wuqianyi.top/objectsdf/) ([Code](https://github.com/QianyiWu/objsdf))
- [Awesome Egocentric Vision](https://github.com/Sid2697/awesome-egocentric-vision)
- [MonoScene: Monocular 3D Semantic Scene Completion (2022)](https://cv-rits.github.io/MonoScene/) ([Code](https://github.com/cv-rits/MonoScene))
- [Visual Prompt Tuning (2022)](https://arxiv.org/abs/2203.12119) ([Code](https://github.com/KMnP/vpt))
- [Unified Implicit Neural Stylization (2022)](https://arxiv.org/abs/2204.01943) ([Code](https://github.com/VITA-Group/INS))
- [3D-Aware Semantic-Guided Generative Model for Human Synthesis (2021)](https://arxiv.org/abs/2112.01422) ([Code](https://github.com/zhangqianhui/3DSGAN))
- [Text2LIVE: Text-Driven Layered Image and Video Editing (2022)](https://text2live.github.io/) ([HN](https://news.ycombinator.com/item?id=32043235))
- [HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction (2022)](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf) ([Code](https://github.com/ZikangZhou/HiVT))
- [Generalization of Otsu's Method and Minimum Error Thresholding (2020)](https://arxiv.org/abs/2007.07350)
- [XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model (2022)](https://arxiv.org/abs/2207.07115) ([Code](https://github.com/hkchengrex/XMem))
- [Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation (2021)](https://arxiv.org/abs/2106.05210) ([Code](https://github.com/hkchengrex/STCN))
- [Deformable Sprites for Unsupervised Video Decomposition (2022)](https://arxiv.org/abs/2204.07151) ([Code](https://github.com/vye16/deformable-sprites))
- [Topologically-Aware Deformation Fields for Single-View 3D Reconstruction (2022)](https://arxiv.org/abs/2205.06267) ([Code](https://github.com/ShivamDuggal4/TARS3D))
- [Multimodal Transformer with Variable-length Memory for Vision-and-Language Navigation (2021)](https://arxiv.org/abs/2111.05759) ([Code](https://github.com/clin1223/MTVM))
- [Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions (2022)](https://arxiv.org/abs/2207.06825) ([Code](https://github.com/brdav/refign))
- [Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry (2021)](https://arxiv.org/abs/2112.08177) ([Code](https://github.com/baegwangbin/MaGNet))
- [Box-supervised Instance Segmentation with Level Set Evolution (2022)](https://github.com/LiWentomng/boxlevelset)
- [Tent: Fully Test-Time Adaptation by Entropy Minimization (2021)](https://openreview.net/forum?id=uXl3bZLkr3c) ([Code](https://github.com/DequanWang/tent))
- [UniFormer: Unifying Convolution and Self-attention for Visual Recognition (2022)](https://arxiv.org/abs/2201.09450) ([Code](https://github.com/Sense-X/UniFormer))
- [MOTR: End-to-End Multiple-Object Tracking with Transformer (2022)](https://arxiv.org/abs/2105.03247) ([Code](https://github.com/megvii-research/MOTR))
- [Towards Grand Unification of Object Tracking (2022)](https://arxiv.org/abs/2207.07078) ([Code](https://github.com/MasterBin-IIAU/Unicorn))
- [Benchmarking Omni-Vision Representation through the Lens of Visual Realms (2022)](https://arxiv.org/abs/2207.07106) ([Code](https://github.com/ZhangYuanhan-AI/OmniBenchmark))
- [Color Histograms in Image Retrieval](https://www.pinecone.io/learn/color-histograms/)
- [SeqTR: A Simple yet Universal Network for Visual Grounding (2022)](https://arxiv.org/abs/2203.16265) ([Code](https://github.com/sean-zhuh/SeqTR))
- [Image Inpainting with External-internal Learning and Monochromic Bottleneck (2021)](https://arxiv.org/abs/2104.09068) ([Code](https://github.com/Tengfei-Wang/external-internal-inpainting))
- [Deep Image Homography Estimation (2016)](https://arxiv.org/abs/1606.03798) ([Code](https://github.com/mazenmel/Deep-homography-estimation-Pytorch))
- [Illumination Adaptive Transformer (2022)](https://arxiv.org/abs/2205.14871) ([Code](https://github.com/cuiziteng/Illumination-Adaptive-Transformer))
- [MotionCLIP: Exposing Human Motion Generation to CLIP Space (2022)](https://arxiv.org/abs/2203.08063) ([Code](https://github.com/GuyTevet/MotionCLIP))
- [Awesome Image Composition](https://github.com/bcmi/Awesome-Image-Composition)
- [Scene Text Recognition with Permuted Autoregressive Sequence Models (2022)](https://arxiv.org/abs/2207.06966) ([Code](https://github.com/baudm/parseq))
- [Multimodal Masked Autoencoders Learn Transferable Representations](https://arxiv.org/abs/2205.14204) ([Code](https://github.com/young-geng/m3ae_public))
- [BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection (2022)](https://arxiv.org/abs/2206.10092) ([Code](https://github.com/Megvii-BaseDetection/BEVDepth))
- [BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving (2022)](https://arxiv.org/abs/2205.09743) ([Code](https://github.com/zhangyp15/BEVerse))
- [AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance Fields (2022)](https://arxiv.org/abs/2207.10312) ([Code](https://github.com/thomasneff/AdaNeRF))
- [Harmonizer: Learning to Perform White-Box Image and Video Harmonization (2022)](https://arxiv.org/abs/2207.01322) ([Code](https://github.com/ZHKKKe/Harmonizer))
- [CVAT](https://www.cvat.ai/) - Computer Vision Annotation Tool. ([Code](https://github.com/cvat-ai/cvat))
- [NeuMesh: Learning Disentangled Neural Mesh-based Implicit Field for Geometry and Texture Editing (2022)](https://github.com/zju3dv/NeuMesh)
- [Monocular 3D Object Detection with Depth from Motion (2022)](https://arxiv.org/abs/2207.12988) ([Code](https://github.com/Tai-Wang/Depth-from-Motion))
- [Masked Discrimination for Self-Supervised Learning on Point Clouds (2022)](https://arxiv.org/abs/2203.11183) ([Code](https://github.com/haotian-liu/MaskPoint))
- [SORT](https://github.com/abewley/sort) - Simple, online, and real time tracking of multiple objects in a video sequence.
- [Local Color Distributions Prior for Image Enhancement (2022)](https://hywang99.github.io/2022/07/09/lcdpnet/) ([Code](https://github.com/hywang99/LCDPNet))
- [S2Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning (2022)](https://eldentse.github.io/s2contact/) ([Code](https://github.com/eldentse/s2contact))
- [Is Attention All NeRF Needs? (2022)](https://arxiv.org/abs/2207.13298) ([Code](https://github.com/VITA-Group/GNT))
- [Camouflaged/Concealed Object Detection](https://github.com/visionxiang/awesome-camouflaged-object-detection)
- [Accelerate Vision Transformer (ViT) with Quantization using Optimum (2022)](https://www.philschmid.de/optimizing-vision-transformer)
- [Optimizing Transformers for GPUs with Optimum (2022)](https://www.philschmid.de/optimizing-transformers-with-optimum-gpu)
- [Photogrammetry Guide](https://github.com/mikeroyal/Photogrammetry-Guide) ([HN](https://news.ycombinator.com/item?id=32284276))
- [Multi-View Mesh Reconstruction with Neural Deferred Shading (2022)](https://fraunhoferhhi.github.io/neural-deferred-shading/) ([Code](https://github.com/fraunhoferhhi/neural-deferred-shading))
- [Initialization and Alignment for Adversarial Texture Optimization (2022)](https://arxiv.org/abs/2207.14289) ([Code](https://github.com/Xiaoming-Zhao/advtex_init_align))
- [DCT-Net: Domain-Calibrated Translation for Portrait Stylization (2022)](https://arxiv.org/abs/2207.02426) ([Code](https://github.com/menyifang/DCT-Net))
- [Pretraining is All You Need for Image-to-Image Translation (2022)](https://arxiv.org/abs/2205.12952) ([Code](https://github.com/PITI-Synthesis/PITI))
- [Vision-Centric BEV Perception: A Survey](https://github.com/4DVLab/Vision-Centric-BEV-Perception)
- [Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency (2022)](https://arxiv.org/abs/2204.10310) ([Code](https://github.com/monniert/unicorn))
- [Awesome Weakly Supervised Semantic Segmentation Papers](https://github.com/PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers)
- [GAUDI: A Neural Architect for Immersive 3D Scene Generation (2022)](https://arxiv.org/abs/2207.13751) ([Code](https://github.com/apple/ml-gaudi)) ([HN](https://news.ycombinator.com/item?id=32344014))
- [Multimodal Image Synthesis and Editing: A Survey (2021)](https://arxiv.org/abs/2112.13592) ([Code](https://github.com/fnzhan/MISE))
- [High-Resolution Image Synthesis with Latent Diffusion Models (2022)](https://arxiv.org/abs/2112.10752) ([Code](https://github.com/pesser/stable-diffusion))
- [ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters (2022)](https://xbpeng.github.io/projects/ASE/index.html) ([Code](https://github.com/nv-tlabs/ASE))
- [3D Vision with Transformers: A Survey (2022)](https://github.com/lahoud/3d-vision-transformers)
- [Optical Flow Processing Stack](https://github.com/h33p/ofps)
- [VideoX - Multi-modal Video Content Understanding](https://github.com/microsoft/VideoX)
- [Simple Baselines for Image Restoration (2022)](https://arxiv.org/abs/2204.04676) ([Code](https://github.com/megvii-research/NAFNet))
- [Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning (2022)](https://arxiv.org/abs/2208.04202)
- [Revisiting the Critical Factors of Augmentation-Invariant Representation Learning (2022)](https://arxiv.org/abs/2208.00275) ([Code](https://github.com/megvii-research/revisitAIRL))
- [Image Quality Related Papers](https://github.com/weizhou-geek/Recent-Image-Quality-Related-Papers)
- [Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution (2022)](https://arxiv.org/abs/2208.03012) ([Code](https://github.com/researchmm/FTVSR))
- [MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation (2022)](https://arxiv.org/abs/2205.09853) ([Code](https://github.com/voletiv/mcvd-pytorch))
- [Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise (2022)](https://arxiv.org/abs/2208.09392) ([Code](https://github.com/arpitbansal297/Cold-Diffusion-Models))
- [Flexible Diffusion Modeling of Long Videos (2022)](https://arxiv.org/abs/2205.11495) ([Code](https://github.com/lucidrains/flexible-diffusion-modeling-videos-pytorch))
- [MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries (2022)](https://arxiv.org/abs/2205.00613) ([Code](https://github.com/a1600012888/MUTR3D))
- [Escaping the Big Data Paradigm with Compact Transformers (2021)](https://arxiv.org/abs/2104.05704) ([Code](https://github.com/SHI-Labs/Compact-Transformers))
- [Towards Layer-wise Image Vectorization (2022)](https://arxiv.org/abs/2206.04655) ([Code](https://github.com/Picsart-AI-Research/LIVE-Layerwise-Image-Vectorization))
- [Awesome Optical Flow](https://github.com/hzwer/Awesome-Optical-Flow)
- [LoRD: Local 4D Implicit Representation for High-Fidelity Dynamic Human Modeling (2022)](https://arxiv.org/abs/2208.08622) ([Code](https://github.com/BoyanJIANG/LoRD))
- [SimpleRecon: 3D Reconstruction Without 3D Convolutions (2022)](https://arxiv.org/abs/2208.14743) ([Code](https://github.com/nianticlabs/simplerecon))
- [Particle Video Revisited: Tracking Through Occlusions Using Point Trajectories (2022)](https://arxiv.org/abs/2204.04153) ([Code](https://github.com/aharley/pips))
- [Lance](https://github.com/eto-ai/lance) - Columnar Data Format for Machine Learning and Computer Vision.
- [Strand-Braid](https://github.com/strawlab/strand-braid) - Live, low-latency 2D and 3D tracking from single or multiple high-speed cameras.
- [Multi-Domain Incremental Learning for Semantic Segmentation (2022)](https://arxiv.org/abs/2110.12205) ([Code](https://github.com/prachigarg23/MDIL-SS))
- [ExpansionNet v2: Block Static Expansion in fast end to end training for Image Captioning (2022)](https://arxiv.org/abs/2208.06551) ([Code](https://github.com/jchenghu/ExpansionNet_v2))
- [Awesome Vision-and-Language Pre-Training](https://github.com/zhjohnchan/awesome-vision-and-language-pretraining)
- [Deep Vision and Graphics course](https://github.com/yandexdataschool/deep_vision_and_graphics)
- [OpenMixup](https://github.com/Westlake-AI/openmixup) - CAIRI Supervised, Semi- and Self-Supervised Visual Representation Learning Toolbox and Benchmark.
- [MMEditing](https://github.com/open-mmlab/mmediting) - Low-level vision toolbox based on PyTorch, supporting super-resolution, inpainting, matting, video interpolation, etc.
- [Accelerating DETR Convergence via Semantic-Aligned Matching (2022)](https://arxiv.org/abs/2203.06883) ([Code](https://github.com/ZhangGongjie/SAM-DETR))
- [The Follower - Using open cameras and AI to find how an Instagram photo is taken](https://driesdepoorter.be/thefollower/) ([Tweet](https://twitter.com/driesdepoorter/status/1569285878089908231))
- [Image Segmentation Using Text and Image Prompts (2022)](https://arxiv.org/abs/2112.10003) ([Code](https://github.com/timojl/clipseg))
- [Knowledge Distillation from A Stronger Teacher (2022)](https://arxiv.org/abs/2205.10536) ([Code](https://github.com/hunto/DIST_KD))
- [Learning Pixel Trajectories with Multiscale Contrastive Random Walks (2022)](https://arxiv.org/abs/2201.08379) ([Code](https://github.com/jasonbian97/flowwalk))
- [Text2Light: Zero-Shot Text-Driven HDR Panorama Generation (2022)](https://frozenburning.github.io/projects/text2light/) ([Code](https://github.com/FrozenBurning/Text2Light))
- [detrex](https://github.com/IDEA-Research/detrex) - Open-source toolbox that provides state-of-the-art Transformer-based detection algorithms.
- [VToonify: Controllable High-Resolution Portrait Video Style Transfer (2022)](https://arxiv.org/abs/2209.11224) ([Code](https://github.com/williamyang1991/VToonify))
- [MMYOLO](https://github.com/open-mmlab/mmyolo) - Open source toolbox for YOLO series algorithms based on PyTorch and MMDetection.
- [Relighting4D: Neural Relightable Human from Videos (2022)](https://arxiv.org/abs/2207.07104) ([Code](https://github.com/FrozenBurning/Relighting4D))
- [GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images (2022)](https://nv-tlabs.github.io/GET3D/) ([Code](https://github.com/nv-tlabs/GET3D))
- [Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer (2019)](https://nv-tlabs.github.io/DIB-R/) ([Code](https://github.com/nv-tlabs/DIB-R))
- [Ask HN: Any good self-hosted image recognition software? (2022)](https://news.ycombinator.com/item?id=32939834)
- [LAVIS](https://github.com/salesforce/LAVIS) - One-stop Library for Language-Vision Intelligence.
- [CATs: Cost Aggregation Transformers for Visual Correspondence (2021)](https://arxiv.org/abs/2106.02520) ([Code](https://github.com/SunghwanHong/Cost-Aggregation-transformers))
- [Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation (2022)](https://seokju-cho.github.io/VAT/) ([Code](https://github.com/Seokju-Cho/Volumetric-Aggregation-Transformer))
- [SetFit](https://github.com/huggingface/setfit) - Efficient Few-shot Learning with Sentence Transformers.
- [Awesome Monocular 3D detection](https://github.com/BigTeacher-777/Awesome-Monocular-3D-detection)
- [Human Motion Diffusion Model (2022)](https://guytevet.github.io/mdm-page/) ([Code](https://github.com/GuyTevet/motion-diffusion-model)) ([HN](https://news.ycombinator.com/item?id=33029522))
- [DreamFusion: Text-to-3D using 2D Diffusion (2022)](https://dreamfusion3d.github.io/) ([HN](https://news.ycombinator.com/item?id=33025446))
- [Recent Advanced in Vision-and-Language Pre-training (2022)](https://vlp-tutorial.github.io/2022/)
- [DeepInteraction: 3D Object Detection via Modality Interaction (2022)](https://arxiv.org/abs/2208.11112) ([Code](https://github.com/fudan-zvg/DeepInteraction))
- [Vision OSC](https://github.com/LingDong-/VisionOSC) - Send (almost) all Apple Vision Framework's detection results via OSC.
- [Synergistic Self-supervised and Quantization Learning (2022)](https://arxiv.org/abs/2207.05432) ([Code](https://github.com/megvii-research/SSQL-ECCV2022))
- [Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models (2022)](https://arxiv.org/abs/2209.06970) ([Code](https://github.com/ChenWu98/Generative-Visual-Prompt))
- [StyleSwap: Style-Based Generator Empowers Robust Face Swapping (2022)](https://hangz-nju-cuhk.github.io/projects/StyleSwap) ([Code](https://github.com/Seanseattle/StyleSwap))
- [IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis (2022)](https://zju3dv.github.io/intrinsic_nerf/) ([Code](https://github.com/zju3dv/IntrinsicNeRF))
- [VMFormer: End-to-End Video Matting with Transformer (2022)](https://arxiv.org/abs/2208.12801) ([Code](https://github.com/SHI-Labs/VMFormer))
- [Image-Based CLIP-Guided Essence Transfer (2021)](https://arxiv.org/abs/2110.12427) ([Code](https://github.com/hila-chefer/TargetCLIP))
- [Equivariant Point Network for 3D Point Cloud Analysis (2022)](https://arxiv.org/abs/2103.14147) ([Code](https://github.com/nintendops/EPN_PointCloud))
- [Computer Vision in the Wild Readings](https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings)
- [Nerfstudio](https://github.com/nerfstudio-project/nerfstudio) - Collaboration friendly studio for NeRFs.
- [Learning Dexterous Manipulation from Exemplar Object Trajectories and Pre-Grasps (2022)](https://pregrasps.github.io/) ([Code](https://github.com/facebookresearch/TCDM))
- [MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction (2022)](https://arxiv.org/abs/2206.00665) ([Code](https://github.com/autonomousvision/monosdf))
- [Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising (2022)](https://nvlabs.github.io/nvdiffrecmc/) ([Code](https://github.com/NVlabs/nvdiffrecmc))
- [2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds (2022)](https://arxiv.org/abs/2207.04397v2) ([Code](https://github.com/yanx27/2DPASS))
- [PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation (2022)](https://arxiv.org/abs/2206.00468) ([Code](https://github.com/NaiyuGao/PanopticDepth))
- [UPIT](https://github.com/tmabraham/UPIT) - FastAI/PyTorch package for unpaired image-to-image translation.
- [On Distillation of Guided Diffusion Models (2022)](https://arxiv.org/abs/2210.03142)
- [Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence (2022)](https://arxiv.org/abs/2210.02689) ([Code](https://github.com/KU-CVLAB/NeMF))
- [MaPLe: Multi-modal Prompt Learning (2022)](https://arxiv.org/abs/2210.03117) ([Code](https://github.com/muzairkhattak/multimodal-prompt-learning))
- [GFNet: Geometric Flow Network for 3D Point Cloud Semantic Segmentation (2022)](https://arxiv.org/abs/2207.02605) ([Code](https://github.com/haibo-qiu/GFNet))
- [End2End Occluded Face Recognition by Masking Corrupted Features (2022)](https://arxiv.org/abs/2108.09468) ([Code](https://github.com/haibo-qiu/FROM))
- [Paint Transformer: Feed Forward Neural Painting with Stroke Prediction (2021)](https://arxiv.org/abs/2108.03798) ([Code](https://github.com/Huage001/PaintTransformer))
- [Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance (2022)](https://arxiv.org/abs/2210.05559) ([Code](https://github.com/ChenWu98/cycle-diffusion))
- [Adaptive Token Sampling For Efficient Vision Transformers (2022)](https://arxiv.org/abs/2111.15667) ([Code](https://github.com/adaptivetokensampling/ATS))
- [Understanding Pure CLIP Guidance for Voxel Grid NeRF Models (2022)](https://arxiv.org/abs/2209.15172) ([Code](https://github.com/hanhung/PureCLIPNeRF))
- [Real-Time Neural Character Rendering with Pose-Guided Multiplane Images (2022)](https://arxiv.org/abs/2204.11820) ([Code](https://github.com/ken-ouyang/PGMPI))
- [Subspace Regularizers for Few-Shot Class Incremental Learning (2022)](https://arxiv.org/abs/2110.07059) ([Code](https://github.com/feyzaakyurek/subspace-reg))
- [Exploring Long-Sequence Masked Autoencoders (2022)](https://arxiv.org/abs/2210.07224) ([Code](https://github.com/facebookresearch/long_seq_mae))
- [Awesome 3D-aware Image Synthesis â Papers, Codes and Datasets](https://github.com/weihaox/awesome-3D-aware-synthesis)
- [An Improved One millisecond Mobile Backbone (2021)](https://arxiv.org/abs/2206.04040) ([Code](https://github.com/apple/ml-mobileone))
- [Fuzzy Metaballs: Approximate Differentiable Rendering with Algebraic Surfaces (2022)](https://leonidk.github.io/fuzzy-metaballs/) ([Code](https://github.com/leonidk/fuzzy-metaballs))
- [Focal Modulation Networks (2022)](https://github.com/microsoft/FocalNet)
- [Monocular Dynamic View Synthesis: A Reality Check (2022)](https://arxiv.org/abs/2210.13445) ([Code](https://github.com/KAIR-BAIR/dycheck))
- [Pose Recognition With Cascade Transformers (2021)](https://openaccess.thecvf.com/content/CVPR2021/html/Li_Pose_Recognition_With_Cascade_Transformers_CVPR_2021_paper.html) ([Code](https://github.com/mlpc-ucsd/PRTR))
- [Terran](https://github.com/terran-project/terran) - Human perception library.
- [Pento](https://www.pento.ai/) - Boost your business with computer vision. ([GitHub](https://github.com/pentoai))
- [HDR-Plenoxels: Self-Calibrating High Dynamic Range Radiance Fields (2022)](https://arxiv.org/abs/2208.06787) ([Code](https://github.com/postech-ami/HDR-Plenoxels))
- [FastestDet](https://github.com/dog-qiuqiu/FastestDet) - Newly designed ultra lightweight anchor free target detection algorithm.
- [Computer Vision, From 3D Reconstruction to Recognition Notes](https://web.stanford.edu/class/cs231a/course_notes.html)
- [Stanford University: Deep Learning for Computer Vision](http://cs231n.stanford.edu/) ([Notes](https://cs231n.github.io/))
- [TAP-Vid: A Benchmark for Tracking Any Point in a Video (2022)](https://arxiv.org/abs/2211.03726) ([Code](https://github.com/deepmind/tapnet))
- [StyleNAT: Giving Each Head a New Perspective (2022)](https://arxiv.org/abs/2211.05770) ([Code](https://github.com/SHI-Labs/StyleNAT))
- [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions (2022)](https://arxiv.org/abs/2211.05778) ([Code](https://github.com/OpenGVLab/InternImage))
- [Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models (2022)](https://arxiv.org/abs/2211.05105) ([Code](https://github.com/ml-research/safe-latent-diffusion))
- [SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery (2022)](https://sustainlab-group.github.io/SatMAE/) ([Code](https://github.com/sustainlab-group/SatMAE))
- [OpenSeeFace](https://github.com/emilianavt/OpenSeeFace) - Robust real time face and facial landmark tracking on CPU with Unity integration.
- [GIT: A Generative Image-to-text Transformer for Vision and Language (2022)](https://arxiv.org/abs/2205.14100) ([Code](https://github.com/microsoft/GenerativeImage2Text))
- [MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis (2022)](https://arxiv.org/abs/2211.09117) ([Code](https://github.com/LTH14/mage))
- [Paddle Detection](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.5/README_en.md) - High-Efficient Development Toolkit for Object Detection based on PaddlePaddle.
- [Instant Neural Surface Reconstruction](https://github.com/bennyguo/instant-nsr-pl)
- [All are Worth Words: A ViT Backbone for Diffusion Models (2022)](https://arxiv.org/abs/2209.12152) ([Code](https://github.com/baofff/U-ViT))
- [OneFormer: One Transformer to Rule Universal Image Segmentation (2022)](https://arxiv.org/abs/2211.06220) ([Code](https://github.com/SHI-Labs/OneFormer))
- [Visual Object Tracking](https://github.com/DavidZhangdw/Visual-Tracking-Development)
- [DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification (2021)](https://arxiv.org/abs/2106.02034) ([Code](https://github.com/raoyongming/DynamicViT))
- [Exploring CLIP for Assessing the Look and Feel of Images (2022)](https://arxiv.org/abs/2207.12396) ([Code](https://github.com/IceClear/CLIP-IQA))
- [RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation (2022)](https://arxiv.org/abs/2211.09869) ([Code](https://github.com/Anciukevicius/RenderDiffusion))
- [Tracking without bells and whistles (2019)](https://arxiv.org/abs/1903.05625) ([Code](https://github.com/phil-bergmann/tracking_wo_bnw))
- [LaTr: Layout-Aware Transformer for Scene-Text VQA (2021)](https://arxiv.org/abs/2112.12494) ([Code](https://github.com/uakarsh/latr))
- [ViewFormer: NeRF-free Neural Rendering from Few Images Using Transformers (2022)](https://github.com/jkulhanek/viewformer)
- [SinDiffusion: Learning a Diffusion Model from a Single Natural Image (2022)](https://arxiv.org/abs/2211.12445) ([Code](https://github.com/WeilunWang/SinDiffusion))
- [CLIP4Cir](https://github.com/ABaldrati/CLIP4Cir) - CLIP for Conditioned image retrieval training code.
- [Physics-based Character Controllers Using Conditional VAEs (2022)](https://research.facebook.com/publications/physics-based-character-controllers-using-conditional-vaes/) ([Code](https://github.com/facebookresearch/PhysicsVAE))
- [Self-Supervised Aggregation of Diverse Experts for Test-Agnostic Long-Tailed Recognition (2021)](https://arxiv.org/abs/2107.09249) ([Code](https://github.com/Vanint/SADE-AgnosticLT))
- [Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention (2022)](https://arxiv.org/abs/2210.09071) ([Code](https://github.com/ashutosh1807/PixelFormer))
- [VLDet: Learning Object-Language Alignments for Open-Vocabulary Object Detection (2022)](https://github.com/clin1223/VLDet)
- [NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360Â° Views (2022)](https://arxiv.org/abs/2211.16431) ([Code](https://github.com/VITA-Group/NeuralLift-360))
- [Vision Transformers (ViT) Explained (2022)](https://www.pinecone.io/learn/vision-transformers/) ([HN](https://news.ycombinator.com/item?id=33786773))
- [Embedding Methods for Image Search | Pinecone](https://www.pinecone.io/learn/image-search/)
- [Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion (2022)](https://arxiv.org/abs/2211.11674) ([Code](https://github.com/google-research/nerf-from-image))
- [Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild (2022)](https://arxiv.org/abs/2207.10660) ([Code](https://github.com/facebookresearch/omni3d))
- [ODaM](https://github.com/LdDl/odam) - Object detection and Monitoring.
- [Token Merging: Your ViT But Faster (2022)](https://arxiv.org/abs/2210.09461) ([Code](https://github.com/facebookresearch/ToMe))
- [NeuralUDF: Learning Unsigned Distance Fields for Multi-view Reconstruction of Surfaces with Arbitrary Topologies (2022)](https://www.xxlong.site/NeuralUDF/) ([Code](https://github.com/xxlong0/NeuralUDF))
- [Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars (2022)](https://mrtornado24.github.io/Next3D/) ([Code](https://github.com/MrTornado24/Next3D))
- [PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF Tracking (2022)](https://arxiv.org/abs/2209.07589) ([Code](https://github.com/nv-nguyen/pizza))
- [Diffusion Models for Medical Image Analysis: A Comprehensive Survey (2022)](https://arxiv.org/abs/2211.07804) ([Code](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging))
- [RSVG: Exploring Data and Models for Visual Grounding on Remote Sensing Data (2022)](https://arxiv.org/abs/2210.12634) ([Code](https://github.com/ZhanYang-nwpu/RSVG-pytorch))
- [Rerun](https://www.rerun.io/) - Open source visualization infrastructure for computer vision and robotics. ([Code](https://github.com/rerun-io/rerun)) ([OSS Release](https://www.rerun.io/blog/oss-beta)) ([HN](https://news.ycombinator.com/item?id=34807038))
- [ECON: Explicit Clothed humans Obtained from Normals (2022)](https://xiuyuliang.cn/econ/) ([Code](https://github.com/YuliangXiu/ECON))
- [Monocular, One-stage, Regression of Multiple 3D People](https://github.com/Arthur151/ROMP)
- [Paint by Example: Exemplar-based Image Editing with Diffusion Models (2022)](https://arxiv.org/abs/2211.13227) ([Code](https://github.com/Fantasy-Studio/Paint-by-Example))
- [Detection Transformers with Assignment (2022)](https://github.com/jozhang97/DETA)
- [Splicing ViT Features for Semantic Appearance Transfer (2022)](https://splice-vit.github.io/) ([Code](https://github.com/omerbt/Splice))
- [Polynomial Neural Fields for Subband Decomposition and Manipulation (2022)](https://github.com/stevenygd/PNF)
- [CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet (2022)](https://arxiv.org/abs/2212.06138) ([Code](https://github.com/LightDXY/FT-CLIP))
- [RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs (2022)](https://github.com/wzhouxiff/RestoreFormer)
- [Vision-and-Language Navigation Resources](https://github.com/YicongHong/Thinking-VLN)
- [HNeRV: A Hybrid Neural Representation for Videos (2022)](https://haochen-rye.github.io/HNeRV/) ([Code](https://github.com/haochen-rye/HNeRV))
- [GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation (2022)](https://arxiv.org/abs/2212.06795) ([Code](https://github.com/ChenhongyiYang/GPViT))
- [Zero Shot Image Restoration Using Denoising Diffusion Null-Space Model (2022)](https://wyhuai.github.io/ddnm.io/) ([Code](https://github.com/wyhuai/DDNM))
- [DifFace: Blind Face Restoration with Diffused Error Contraction](https://github.com/zsyOAOA/DifFace)
- [What do Vision Transformers Learn? A Visual Exploration](https://github.com/hamidkazemi22/vit-visualization)
- [Images Speak in Images: A Generalist Painter for In-Context Visual Learning (2022)](https://arxiv.org/abs/2212.02499) ([Code](https://github.com/baaivision/Painter))
- [ShuffleMixer: An Efficient ConvNet for Image Super-Resolution](https://github.com/sunny2109/ShuffleMixer)
- [SDFStudio: Unified Framework for Surface Reconstruction](https://autonomousvision.github.io/sdfstudio/) ([Code](https://github.com/autonomousvision/sdfstudio))
- [SegViT: Semantic Segmentation with Plain Vision Transformers (2022)](https://arxiv.org/abs/2210.05844) ([Code](https://github.com/zbwxp/SegVit))
- [MMEngine](https://github.com/open-mmlab/mmengine) - Foundational library for training deep learning models based on PyTorch.
- [SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields (2022)](https://arxiv.org/abs/2212.02501) ([Code](https://github.com/astra-vision/SceneRF))
- [Great Computer Vision startups (2022)](https://twitter.com/ai__pub/status/1604251023182163968)
- [CoVA: Context-aware Visual Attention for Webpage Information Extraction (2022)](https://github.com/kevalmorabia97/CoVA-Web-Object-Detection)
- [Awesome 3D Object Detection](https://github.com/TianhaoFu/Awesome-3D-Object-Detection)
- [ProposalContrast: Unsupervised Pre-training for LiDAR-based 3D Object Detection (2022)](https://arxiv.org/abs/2207.12654) ([Code](https://github.com/yinjunbo/ProposalContrast))
- [DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis (2022)](https://arxiv.org/abs/2212.11984) ([Code](https://github.com/snap-research/discoscene))
- [FFNeRV: Flow-Guided Frame-Wise Neural Representations for Videos (2022)](https://maincold2.github.io/ffnerv/) ([Code](https://github.com/maincold2/FFNeRV))
- [SwinFIR: Revisiting the SwinIR with Fast Fourier Convolution and Improved Training for Image Super-Resolution (2022)](https://arxiv.org/abs/2208.11247)
- [Knowledge Condensation Distillation (2022)](https://arxiv.org/abs/2207.05409) ([Code](https://github.com/dzy3/KCD))
- [NeuMan: Neural Human Radiance Field from a Single Video (2022)](https://arxiv.org/abs/2203.12575) ([Code](https://github.com/apple/ml-neuman))
- [ScaleNet: Searching for the Model to Scale (2022)](https://arxiv.org/abs/2207.07267) ([Code](https://github.com/luminolx/ScaleNet))
- [Very Recent Progress in 3D Hand Tasks](https://github.com/SeanChenxy/Hand3DResearch)
- [Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation (2022)](https://arxiv.org/abs/2212.11565) ([Code](https://github.com/showlab/Tune-A-Video)) ([Code](https://github.com/bryandlee/Tune-A-Video))
- [NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields (2022)](https://github.com/ToniRV/NeRF-SLAM)
- [Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures (2022)](https://arxiv.org/abs/2211.07600) ([Code](https://github.com/eladrich/latent-nerf))
- [Deep Architectures for Content Moderation and Movie Content Rating (2022)](https://arxiv.org/abs/2212.04533) ([Code](https://github.com/fcakyon/content-moderation-deep-learning))
- [TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning (2022)](https://arxiv.org/abs/2212.13979) ([Code](https://github.com/ADLab3Ds/TiG-BEV))
- [Magic3D: High-Resolution Text-to-3D Content Creation (2022)](https://arxiv.org/abs/2211.10440) ([Code](https://github.com/lucidrains/magic3d-pytorch))
- [InternVideo: General Video Foundation Models via Generative and Discriminative Learning (2022)](https://arxiv.org/abs/2212.03191) ([Code](https://github.com/OpenGVLab/InternVideo))
- [Exploring Cross-Image Pixel Contrast for Semantic Segmentation (2021)](https://arxiv.org/abs/2101.11939) ([Code](https://github.com/tfzhou/ContrastiveSeg))
- [Towards Robust Blind Face Restoration with Codebook Lookup Transformer (2022)](https://arxiv.org/abs/2206.11253) ([Code](https://github.com/sczhou/CodeFormer))
- [Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction (2022)](https://arxiv.org/abs/2205.15848) ([Code](https://github.com/GhiXu/Geo-Neus))
- [ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders (2023)](https://arxiv.org/abs/2301.00808) ([Code](https://github.com/facebookresearch/ConvNeXt-V2))
- [SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection (2022)](https://arxiv.org/abs/2203.06398) ([Code](https://github.com/CityU-AIM-Group/SIGMA))
- [SCAN: Cross Domain Object Detection with Semantic Conditioned Adaptation (2022)](https://github.com/CityU-AIM-Group/SCAN)
- [Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion (2022)](https://www.robots.ox.ac.uk/~vgg/research/gwm/) ([Code](https://github.com/karazijal/guess-what-moves))
- [Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera (2022)](https://arxiv.org/abs/2206.15258) ([Code](https://github.com/USTC3DV/NDR-code))
- [GaitMixer: Skeleton-based Gait Representation Learning via Wide-spectrum Multi-axial Mixer (2022)](https://arxiv.org/abs/2210.15491) ([Code](https://github.com/exitudio/GaitMixer))
- [Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models (2022)](https://arxiv.org/abs/2212.14704)
- [OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist Models (2022)](https://arxiv.org/abs/2212.04408) ([Code](https://github.com/OFA-Sys/OFASys))
- [Expectation-Maximization Contrastive Learning for Compact Video-and-Language Representations (2022)](https://arxiv.org/abs/2211.11427) ([Code](https://github.com/jpthu17/EMCL))
- [Rethinking Resolution in the Context of Efficient Video Recognition (2022)](https://arxiv.org/abs/2209.12797) ([Code](https://github.com/CVMI-Lab/ResKD))
- [OpenCV Mobile](https://github.com/nihui/opencv-mobile)
- [SINE: SINgle Image Editing with Text-to-Image Diffusion Models (2022)](https://arxiv.org/abs/2212.04489) ([Code](https://github.com/zhang-zx/SINE))
- [PETR: Position Embedding Transformation for Multi-View 3D Object Detection (2022)](https://github.com/megvii-research/PETR)
- [Awesome Deep Optics/End-to-end Optical Design](https://github.com/singer-yang/awesome-deep-optics)
- [HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling (2023)](https://arxiv.org/abs/2301.02238) ([Code](https://github.com/facebookresearch/hyperreel))
- [Image generation with MNIST (2022)](https://liorsinai.github.io/coding/2022/12/29/denoising-diffusion-2-unet.html)
- [CiT: Curation in Training for Effective Vision-Language Data (2023)](https://arxiv.org/abs/2301.02241) ([Code](https://github.com/facebookresearch/CiT))
- [MegaPose: 6D Pose Estimation of Novel Objects via Render & Compare (2022)](https://arxiv.org/abs/2212.06870) ([Code](https://github.com/megapose6d/megapose6d))
- [Bidirectional Projection Network for Cross Dimension Scene Understanding (2021)](https://arxiv.org/abs/2103.14326) ([Code](https://github.com/wbhu/BPNet))
- [Image Distortion Correction](https://github.com/subeeshvasu/Awesome-Image-Distortion-Correction) - Curated list of resources on handling Rolling Shutter effects and Radial Distortions.
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) - YOLOv8 in PyTorch > ONNX > CoreML > TFLite.
- [Neural Density-Distance Fields (2022)](https://arxiv.org/abs/2207.14455) ([Code](https://github.com/ueda0319/neddf))
- [Vision Transformers Are Good Mask Auto-Labelers (2023)](https://arxiv.org/abs/2301.03992) ([Code](https://github.com/NVlabs/mask-auto-labeler))
- [TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition (2022)](https://arxiv.org/abs/2210.11277) ([Code](https://github.com/Gorilla-Lab-SCUT/tango))
- [EVA: Exploring the Limits of Masked Visual Representation Learning at Scale (2022)](https://arxiv.org/abs/2211.07636) ([Code](https://github.com/baaivision/EVA))
- [SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction (2022)](https://arxiv.org/abs/2212.00792) ([Code](https://github.com/zhizdev/sparsefusion))
- [Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling (2023)](https://arxiv.org/abs/2301.03580) ([Code](https://github.com/keyu-tian/SparK))
- [Generalized Decoding for Pixel, Image, and Language (2022)](https://arxiv.org/abs/2212.11270) ([Code](https://github.com/microsoft/X-Decoder))
- [Global Context Vision Transformers (2022)](https://arxiv.org/abs/2206.09959) ([Code](https://github.com/NVlabs/GCVit))
- [Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning (2023)](https://arxiv.org/abs/2301.05219) ([Code](https://github.com/MingSun-Tse/Why-the-State-of-Pruning-so-Confusing))
- [DensePose From WiFi (2022)](https://arxiv.org/abs/2301.00250) ([Tweet](https://twitter.com/nearcyan/status/1615229929825656835)) ([HN](https://news.ycombinator.com/item?id=34423395)) ([HN](https://news.ycombinator.com/item?id=34480760))
- [CHAIRS: Towards Full-Body Articulated Human-Object Interaction (2022)](https://arxiv.org/abs/2212.10621) ([Code](https://github.com/jnnan/chairs))
- [MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels (2023)](https://arxiv.org/abs/2212.05897) ([Code](https://github.com/TaeryungLee/MultiAct_RELEASE))
- [GLIGEN: Open-Set Grounded Text-to-Image Generation (2023)](https://arxiv.org/abs/2301.07093) ([Code](https://github.com/gligen/GLIGEN))
- [T2M-GPT: Generating Human Motion from Textual Descriptions with discrete Representations (2023)](https://arxiv.org/abs/2301.06052) ([Code](https://github.com/Mael-zys/T2M-GPT))
- [Multiview Compressive Coding for 3D Reconstruction (2023)](https://arxiv.org/abs/2301.08247) ([Code](https://github.com/facebookresearch/MCC))
- [Deep Learning Object Detection Paper List](https://github.com/hoya012/deep_learning_object_detection)
- [Efficient Neural Radiance Fields for Interactive Free-viewpoint Video (2022)](https://arxiv.org/abs/2112.01517) ([Code](https://github.com/zju3dv/ENeRF))
- [InstructPix2Pix: Learning to Follow Image Editing Instructions (2022)](https://arxiv.org/abs/2211.09800) ([Code](https://github.com/timothybrooks/instruct-pix2pix))
- [Learned reconstructions for practical mask-based lensless imaging](https://waller-lab.github.io/LenslessLearning/) ([Code](https://github.com/Waller-Lab/LenslessLearning))
- [NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos (2022)](https://arxiv.org/abs/2210.12352) ([Code](https://github.com/gaoalexander/neuphysics))
- [Domain Expansion of Image Generators (2023)](https://arxiv.org/abs/2301.05225) ([Code](https://github.com/adobe-research/domain-expansion))
- [Computer Vision: Models, Learning, and Inference](http://www.computervisionmodels.com/)
- [Reversible Column Networks (2022)](https://arxiv.org/abs/2212.11696) ([Code](https://github.com/megvii-research/RevCol))
- [Rethinking Text Segmentation: A Novel Dataset and A Text-Specific Refinement Approach (2021)](https://arxiv.org/abs/2011.14021) ([Code](https://github.com/SHI-Labs/Rethinking-Text-Segmentation))
- [Long-tail Detection with Effective Class-Margins (2022)](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680684.pdf) ([Code](https://github.com/janghyuncho/ECM-Loss))
- [Diffusion-SDF: Text-to-Shape via Voxelized Diffusion (2022)](https://arxiv.org/abs/2212.03293) ([Code](https://github.com/ttlmh/Diffusion-SDF))
- [Learning 3D-aware Image Synthesis with Unknown Pose Distribution (2023)](https://arxiv.org/abs/2301.07702) ([Code](https://github.com/VivianSZF/pof3d))
- [Video object detection in Elixir using Nx and Bumblebee (2023)](https://culttt.com/2023/01/26/video-object-detection-elixir-nx-bumblebee)
- [K-Planes: Explicit Radiance Fields in Space, Time, and Appearance (2023)](https://arxiv.org/abs/2301.10241) ([Code](https://github.com/sarafridov/K-Planes))
- [Text2LIVE: Text-Driven Layered Image and Video Editing (2022)](https://arxiv.org/abs/2204.02491) ([Code](https://github.com/omerbt/Text2LIVE))
- [Disentangled Representation Learning for Text-Video Retrieval (2022)](https://arxiv.org/abs/2203.07111) ([Code](https://github.com/foolwood/DRL))
- [Text-To-4D Dynamic Scene Generation (2023)](https://arxiv.org/abs/2301.11280) ([HN](https://news.ycombinator.com/item?id=34544630))
- [PhyCV](https://github.com/JalaliLabUCLA/phycv) - Physics-inspired Computer Vision Library.
- [Fast Dynamic Radiance Fields with Time-Aware Neural Voxels (2022)](https://arxiv.org/abs/2205.15285) ([Code](https://github.com/hustvl/TiNeuVox))
- [Learning Customized Visual Models with Retrieval-Augmented Knowledge (2023)](https://arxiv.org/abs/2301.07094) ([Code](https://github.com/microsoft/react))
- [Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models (2022)](https://arxiv.org/abs/2211.17091) ([Code](https://github.com/alsdudrla10/Discriminator-Guidance))
- [Accelerating Guided Diffusion Sampling with Splitting Numerical Methods (2023)](https://arxiv.org/abs/2301.11558) ([Code](https://github.com/sWizad/split-diffusion))
- [SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections (2023)](https://scene-dreamer.github.io/) ([Code](https://github.com/Scene-Dreamer/SceneDreamer))
- [STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth Estimation (2023)](https://arxiv.org/abs/2302.01334) ([Code](https://github.com/ucaszyp/STEPS))
- [Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline (2023)](https://arxiv.org/abs/2301.12511) ([Code](https://github.com/Sense-GVT/Fast-BEV))
- [Awesome Vision Transformer Collection](https://github.com/GuanRunwei/Awesome-Vision-Transformer-Collection)
- [Compressed Vision for Efficient Video Understanding (2022)](https://arxiv.org/abs/2210.02995) ([Code](https://github.com/deepmind/compressed_vision))
- [Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation (2023)](https://arxiv.org/abs/2206.07771) ([Code](https://github.com/L-YeZhu/CDCD))
- [SEGA: Instructing Diffusion using Semantic Dimensions (2023)](https://arxiv.org/abs/2301.12247) ([Code](https://github.com/ml-research/semantic-image-editing))
- [Dreamix: Video Diffusion Models are General Video Editors (2023)](https://arxiv.org/abs/2302.01329) ([Web](https://dreamix-video-editing.github.io/))
- [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis (2023)](https://arxiv.org/abs/2301.13430) ([Code](https://github.com/yerfor/GeneFace))
- [ESP-WHO](https://github.com/espressif/esp-who) - Face detection and recognition framework.
- [Egocentric Video-Language Pretraining (2022)](https://arxiv.org/abs/2206.01670) ([Code](https://github.com/showlab/EgoVLP))
- [EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations (2022)](https://arxiv.org/abs/2207.06635) ([Code](https://github.com/ML-GSAI/EGSDE))
- [Revealing Single Frame Bias for Video-and-Language Learning (2022)](https://arxiv.org/abs/2206.03428) ([Code](https://github.com/jayleicn/singularity))
- [EVA3D: Compositional 3D Human Generation from 2D Image Collections (2022)](https://arxiv.org/abs/2210.04888) ([Code](https://github.com/hongfz16/EVA3D))
- [Zero-shot Image-to-Image Translation (2023)](https://pix2pixzero.github.io/) ([Code](https://github.com/pix2pixzero/pix2pix-zero))
- [MatteFormer: Transformer-Based Image Matting via Prior-Tokens (2022)](https://arxiv.org/abs/2203.15662) ([Code](https://github.com/webtoon/matteformer))
- [minREV](https://github.com/karttikeya/minREV) - Simple minimal implementation of Reversible Vision Transformers.
- [Cut and Learn for Unsupervised Object Detection and Instance Segmentation (2023)](https://arxiv.org/abs/2301.11320) ([Code](https://github.com/facebookresearch/CutLER))
- [T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models (2023)](https://arxiv.org/abs/2302.08453) ([Code](https://github.com/TencentARC/T2I-Adapter))
- [3D-aware Conditional Image Synthesis (2023)](https://arxiv.org/abs/2302.08509) ([Code](https://github.com/dunbar12138/pix2pix3D))
- [Deblur-NeRF: Neural Radiance Fields from Blurry Images (2021)](https://arxiv.org/abs/2111.14292) ([Code](https://github.com/limacv/Deblur-NeRF))
- [Learning When to Say "I Don't Know" (2022)](https://arxiv.org/abs/2209.04944) ([Code](https://github.com/osu-cvl/learning-idk))
- [MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation (2023)](https://arxiv.org/abs/2302.08113)
- [NeRS: Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in the Wild (2021)](https://arxiv.org/abs/2110.07604) ([Code](https://github.com/jasonyzhang/ners))
- [3D Shape Analysis Paper List](https://github.com/yinyunie/3D-Shape-Analysis-Paper-List)
- [Generating Holistic 3D Human Motion from Speech (2022)](https://arxiv.org/abs/2212.04420) ([Code](https://github.com/yhw-yhw/SHOW))
- [SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation (2023)](https://arxiv.org/abs/2301.13156) ([Code](https://github.com/fudan-zvg/SeaFormer))
- [Audio-Visual Face Reenactment (2022)](https://arxiv.org/abs/2210.02755) ([Code](https://github.com/mdv3101/AVFR-Gan))
- [Awesome Distribution Shift](https://github.com/weitianxin/awesome-distribution-shift)
- [Everything at Once -- Multi-modal Fusion Transformer for Video Retrieval (2022)](https://arxiv.org/abs/2112.04446) ([Code](https://github.com/ninatu/everything_at_once))
- [TEXTure: Text-Guided Texturing of 3D Shapes](https://texturepaper.github.io/TEXTurePaper/) ([Code](https://github.com/TEXTurePaper/TEXTurePaper))
- [SIMPLI - Self-improving Multiplane-to-layer Images for Novel View Synthesis (2023)](https://github.com/SamsungLabs/MLI)
- [Awesome Image Registration](https://github.com/Awesome-Image-Registration-Organization/awesome-image-registration) - Image registration related books, papers, videos, and toolboxes.
- [Learning Visual Representations via Language-Guided Sampling (2023)](https://arxiv.org/abs/2302.12248) ([Code](https://github.com/mbanani/lgssl))
- [RealFusion: 360Â° Reconstruction of Any Object from a Single Image (2023)](https://arxiv.org/abs/2302.10663) ([Code](https://github.com/lukemelas/realfusion))
- [Efficient Vision-Language Pretraining with Visual Concepts and Hierarchical Alignment (2022)](https://arxiv.org/abs/2208.13628) ([Code](https://github.com/mshukor/ViCHA))
- [Composer: Creative and Controllable Image Synthesis with Composable Conditions (2023)](https://arxiv.org/abs/2302.09778) ([Code](https://github.com/damo-vilab/composer))
- [Decoupling Human and Camera Motion from Videos in the Wild (2023)](https://arxiv.org/abs/2302.12827) ([Code](https://github.com/vye16/slahmr))
- [ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth (2023)](https://arxiv.org/abs/2302.12288) ([Code](https://github.com/isl-org/ZoeDepth))
- [The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition (2023)](https://openreview.net/forum?id=xLr0I_xYGAs) ([Code](https://github.com/Jun-CEN/Unified_Open_Set_Recognition))
- [Image as Set of Points (2023)](https://arxiv.org/abs/2303.01494) ([Code](https://github.com/ma-xu/Context-Cluster))
- [MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound (2022)](https://rowanzellers.com/merlotreserve/) ([Code](https://github.com/rowanz/merlot_reserve))
- [NeRF2Mesh: Delicate Textured Mesh Recovery from NeRF via Adaptive Surface Refinement (2023)](https://me.kiui.moe/nerf2mesh/) ([Code](https://github.com/ashawkey/nerf2mesh))
- [Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction (2023)](https://arxiv.org/abs/2208.12697) ([Code](https://github.com/wutong16/Voxurf))
- [MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices (2023)](https://arxiv.org/abs/2303.01932) ([Code](https://github.com/ActiveVisionLab/MobileBrick))
- [MetaPortrait: Identity-Preserving Talking Head Generation with Fast Personalized Adaptation (2022)](https://arxiv.org/abs/2212.08062) ([Code](https://github.com/Meta-Portrait/MetaPortrait))
- [FFCV-SSL](https://github.com/facebookresearch/FFCV-SSL) - Fast Forward Computer Vision for Self-Supervised Learning.
- [How computer vision is changing manufacturing in 2023](https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/) ([HN](https://news.ycombinator.com/item?id=35083163))
- [Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation (2023)](https://arxiv.org/abs/2303.00440) ([Code](https://github.com/MCG-NJU/EMA-VFI))
- [NeRFshop: Interactive Editing of Neural Radiance Fields](https://github.com/graphdeco-inria/nerfshop)
- [Blind Video Deflickering by Neural Filtering with a Flawed Atlas (2023)](https://github.com/ChenyangLEI/All-In-One-Deflicker)
- [Universal Instance Perception as Object Discovery and Retrieval (2023)](https://github.com/MasterBin-IIAU/UNINEXT)
- [FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency Regularization (2023)](https://arxiv.org/abs/2303.07418) ([Code](https://github.com/Jiawei-Yang/FreeNeRF))
- [Vid2Seq: a pretrained visual language model for describing multi-event videos (2023)](https://ai.googleblog.com/2023/03/vid2seq-pretrained-visual-language.html) ([HN](https://news.ycombinator.com/item?id=35201667))
- [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models (2023)](https://lukashoel.github.io/text-to-room/) ([Code](https://github.com/lukasHoel/text2room))
- [Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation (2023)](https://arxiv.org/abs/2211.13202) ([Code](https://github.com/noahzn/Lite-Mono))
- [Generative Semantic Segmentation (2023)](https://arxiv.org/abs/2303.11316) ([Code](https://github.com/fudan-zvg/GSS))
- [Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators (2023)](https://arxiv.org/abs/2303.13439) ([Code](https://github.com/Picsart-AI-Research/Text2Video-Zero)) ([HN](https://news.ycombinator.com/item?id=35352452))
- [Diffusion-based Generation, Optimization, and Planning in 3D Scenes (2023)](https://arxiv.org/abs/2301.06015) ([Code](https://github.com/scenediffuser/Scene-Diffuser))
- [Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes (2023)](https://arxiv.org/abs/2302.14348) ([Code](https://github.com/jyunlee/Im2Hands))
- [Pointcept](https://github.com/Pointcept/Pointcept) - Powerful and flexible codebase for point cloud perception research.
- [Conditional Image-to-Video Generation with Latent Flow Diffusion Models (2023)](https://arxiv.org/abs/2303.13744) ([Code](https://github.com/nihaomiao/CVPR23_LFDM))
- [ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model (2023)](https://arxiv.org/abs/2304.01116) ([Code](https://github.com/mingyuan-zhang/ReMoDiffuse))
- [GlueStick](https://github.com/cvg/GlueStick) - Joint Deep Matcher for Points and Lines.
- [GVision](https://github.com/GONZOsint/gvision) - Reverse image search app that use Google Cloud Vision API to detect landmarks and web entities from images.
- [Segment Anything (2023)](https://ai.facebook.com/research/publications/segment-anything/) ([Code](https://github.com/facebookresearch/segment-anything))
- [Detecting and Grounding Multi-Modal Media Manipulation (2023)](https://arxiv.org/abs/2304.02556) ([Code](https://github.com/rshaojimmy/MultiModal-DeepFake))
- [Better Aligning Text-to-Image Models with Human Preference (2023)](https://arxiv.org/abs/2303.14420) ([Code](https://github.com/tgxs002/align_sd))
- [Scaling Language-Image Pre-training via Masking (2022)](https://arxiv.org/abs/2212.00794) ([Code](https://github.com/facebookresearch/flip))
- [From Zero to Hero: Convincing with Extremely Complicated Math (2023)](https://arxiv.org/abs/2304.00399) ([HN](https://github.com/mweiherer/zero2hero))
- [Zero-shot Generative Model Adaptation via Image-specific Prompt Learning (2023)](https://arxiv.org/abs/2304.03119) ([Code](https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation))
- [Awesome Digital Human](https://github.com/weihaox/awesome-digital-human) - Collection of resources on digital human including clothed people digitalization, virtual try-on, and other related directions.
- [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) - Marrying Grounding DINO with Segment Anything - Detect and Segment Anything with Text Inputs.
- [VideoCrafterï¼Toolkit for Text-to-Video Generation and Editing](https://github.com/VideoCrafter/VideoCrafter)
- [DiffMimic: Efficient Motion Mimicking with Differentiable Physics (2023)](https://arxiv.org/abs/2304.03274) ([Code](https://github.com/jiawei-ren/diffmimic))
- [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions (2023)](https://instruct-nerf2nerf.github.io/) ([Code](https://github.com/ayaanzhaque/instruct-nerf2nerf))
- [MetaSeg: Packaged version of the Segment Anything repository](https://github.com/kadirnar/segment-anything-video)
- [Segment Anything with Clip](https://github.com/Curt-Park/segment-anything-with-clip)
- [Hachi](https://github.com/ramanlabs-in/hachi) - Natural Language search for Videos and Images.
- [SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation (2023)](https://sadtalker.github.io/) ([Code](https://github.com/Winfredy/SadTalker))
- [EditAnything](https://github.com/sail-sg/EditAnything) - Segment Anything + ControlNet + BLIP2 + Stable Diffusion. ([HN](https://news.ycombinator.com/item?id=35509429))
- [Segment Anything EO tools](https://github.com/aliaksandr960/segment-anything-eo)
- [PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models (2023)](https://arxiv.org/abs/2303.17546) ([Code](https://github.com/Picsart-AI-Research/PAIR-Diffusion))
- [Awesome-Anything](https://github.com/VainF/Awesome-Anything) - General AI methods for Anything: AnyObject, AnyGeneration, AnyModel, etc.
- [Connect Segment-Anything with CLIP](https://github.com/PengtaoJiang/SAM-CLIP)
- [Semantic Segment Anything](https://github.com/fudan-zvg/Semantic-Segment-Anything) - Automated dense category annotation engine that serves as the initial semantic labeling for the Segment Anything dataset.
- [Segment Anything Labelling Tool (SALT)](https://github.com/anuragxel/salt)
- [CenterCLIP: Token Clustering for Efficient Text-Video Retrieval (2022)](https://arxiv.org/abs/2205.00823) ([Code](https://github.com/mzhaoshuai/CenterCLIP))
- [FateZero: Fusing Attentions for Zero-shot Text-based Video Editing (2023)](https://arxiv.org/abs/2303.09535) ([Code](https://github.com/Doubiiu/CodeTalker))
- [SVDiff: Compact Parameter Space for Diffusion Fine-Tuning (2023)](https://arxiv.org/abs/2303.11305) ([Code](https://github.com/mkshing/svdiff-pytorch))
- [Detection Transformer with Stable Matching (2023)](https://arxiv.org/abs/2304.04742) ([Code](https://github.com/IDEA-Research/Stable-DINO))
- [Caption Anything via Clicking](https://github.com/ttengwang/Caption-Anything)
- [Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition (2023)](https://arxiv.org/abs/2304.04704) ([Code](https://github.com/amazon-science/prompt-pretraining))
- [Prompt-Segment-Anything](https://github.com/RockeyCoss/Prompt-Segment-Anything) - Implementation of zero-shot instance segmentation using Segment Anything.
- [Segment Anything for Stable Diffusion Webui](https://github.com/continue-revolution/sd-webui-segment-anything)
- [Semaphore](https://github.com/everythingishacked/Semaphore) - Full-body keyboard using gestures to type through computer vision. ([HN](https://news.ycombinator.com/item?id=35536550))
- [CleanVision](https://github.com/cleanlab/cleanvision) - Automatically find issues in image datasets and practice data-centric computer vision.
- [NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior (2023)](https://arxiv.org/abs/2212.07388) ([Code](https://github.com/ActiveVisionLab/nope-nerf))
- [Learning to Generate Text-grounded Mask for Open-world Semantic Segmentation from Only Image-Text Pairs (2023)](https://arxiv.org/abs/2212.00785) ([Code](https://github.com/kakaobrain/tcl))
- [FAIR Animated Drawings](https://fairanimateddrawings.com/site/home) ([Code](https://github.com/facebookresearch/AnimatedDrawings)) ([HN](https://news.ycombinator.com/item?id=35561203))
- [Anything-3D](https://github.com/Anything-of-anything/Anything-3D) - Segment-Anything + 3D. Let's lift the anything to 3D.
- [3D-Box via Segment Anything](https://github.com/dvlab-research/3D-Box-Segment-Anything)
- [Rich-Text-to-Image Generation](https://github.com/SongweiGe/rich-text-to-image)
- [SEEM: Segment Everything Everywhere All at Once](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)
- [DinoV2: Metaâs Open Source State-of-the-art computer vision models (2023)](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/) ([HN](https://news.ycombinator.com/item?id=35634419)) ([Code](https://github.com/facebookresearch/dinov2))
- [Dynablox](https://github.com/ethz-asl/dynablox) - Real-time detection of diverse dynamic objects in complex environments.
- [Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning (2023)](https://github.com/kaiwenzha/contrastive-poisoning)
- [Inpaint Anything: Segment Anything Meets Image Inpainting](https://github.com/geekyutao/Inpaint-Anything)
- [Transformer-Based Visual Segmentation: A Survey (2023)](https://github.com/lxtGH/Awesome-Segmenation-With-Transformer)
- [AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation (2023)](https://arxiv.org/abs/2304.09790) ([Code](https://github.com/MCG-NKU/AMT))
- [segment-geospatial](https://github.com/opengeos/segment-geospatial) - Python package for segmenting geospatial data with the Segment Anything Model (SAM).
- [I Hear Your True Colors: Image Guided Audio Generation](https://github.com/RoySheffer/im2wav)
- [Contrastive Audio-Visual Masked Autoencoder (2023)](https://github.com/YuanGongND/cav-mae)
- [F2-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories (2023)](https://arxiv.org/abs/2303.15951) ([Code](https://github.com/Totoro97/f2-nerf))
- [Angler: Helping Machine Translation Practitioners Prioritize Model Improvements (2023)](https://machinelearning.apple.com/research/helping-machine-translation) ([Code](https://github.com/apple/ml-translate-vis))
- [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields (2023)](https://arxiv.org/abs/2304.06706) ([Code](https://github.com/SuLvXiangXin/zipnerf-pytorch))
- [Mask-Free Video Instance Segmentation (2023)](https://arxiv.org/abs/2303.15904) ([Code](https://github.com/SysCV/MaskFreeVIS))
- [Fine-tuned CLIP models are efficient video learners (2023)](https://github.com/muzairkhattak/ViFi-CLIP)
- [Track-Anything](https://github.com/gaomingqi/Track-Anything) - Flexible and interactive tool for video object tracking and segmentation, based on Segment Anything and XMem.
- [Supervision](https://github.com/roboflow/supervision) - Easy-to-use utils that will come in handy in any Computer Vision project.
- [Roboflow Notebooks](https://github.com/roboflow/notebooks) - Examples and tutorials on using SOTA computer vision models and techniques.
- [Speed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations (2023)](https://arxiv.org/abs/2304.11267)
- [Awesome Segment Anything](https://github.com/Hedlen/awesome-segment-anything) - Tracking and collecting papers/projects/others related to Segment Anything.
- [SuperGradients](https://github.com/Deci-AI/super-gradients) - Easily train or fine-tune SOTA computer vision models with one open source training library.
- [VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking (2023)](https://github.com/OpenGVLab/VideoMAEv2)
- [DiffusionDepth: Diffusion Denoising Approach for Monocular Depth Estimation (2023)](https://arxiv.org/abs/2303.05021) ([Code](https://github.com/duanyiqun/DiffusionDepth))
- [Shap-E: Generating Conditional 3D Implicit Functions (2023)](https://arxiv.org/abs/2305.02463) ([Code](https://github.com/openai/shap-e)) ([HN](https://news.ycombinator.com/item?id=35836976))
- [Personalize Segment Anything Model with One Shot (2023)](https://arxiv.org/abs/2305.03048) ([Code](https://github.com/ZrrSkywalker/Personalize-SAM))
- [Segment Anything 3D](https://github.com/Pointcept/SegmentAnything3D)
- [FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention](https://github.com/mit-han-lab/fastcomposer)
- [ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision (2023)](https://gerwang.github.io/shadowneus/) ([Code](https://github.com/gerwang/ShadowNeuS))
- [ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities (2023)](https://arxiv.org/abs/2305.11172) ([Code](https://github.com/OFA-Sys/ONE-PEACE))
- [Denoising Diffusion Models: A Generative Learning Big Bang (2023)](https://cvpr2023-tutorial-diffusion-models.github.io/) ([Code](https://github.com/cvpr2023-tutorial-diffusion-models/papers))
- [LERF: Language Embedded Radiance Fields (2023)](https://www.lerf.io/) ([Code](https://github.com/kerrj/lerf))
- [Masked Diffusion Transformer is a Strong Image Synthesizer (2023)](https://arxiv.org/abs/2303.14389) ([Code](https://github.com/sail-sg/MDT))
- [Decentralization and Acceleration Enables Large-Scale Bundle Adjustment (2023)](https://arxiv.org/abs/2305.07026) ([Code](https://github.com/facebookresearch/DABA))
- [Awesome-Visual-Instruction-Tuning](https://github.com/BradyFU/Awesome-Visual-Instruction-Tuning)
- [Awesome 3D Reconstruction Papers](https://github.com/bluestyle97/awesome-3d-reconstruction-papers)
- [Better Diffusion Models Further Improve Adversarial Training (2023)](https://arxiv.org/abs/2302.04638) ([Code](https://github.com/wzekai99/DM-Improves-AT))
- [Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses (2023)](https://arxiv.org/abs/2305.14059) ([Code](https://github.com/nianticlabs/ace))
- [MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model (2022)](https://arxiv.org/abs/2211.00611) ([Code](https://github.com/lucidrains/med-seg-diff-pytorch))
- [DiM: Distilling Dataset into Generative Model (2023)](https://arxiv.org/abs/2303.04707) ([Code](https://github.com/vimar-gu/DiM))
- [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation (2023)](https://arxiv.org/abs/2303.13873) ([Code](https://github.com/Gorilla-Lab-SCUT/Fantasia3D))
- [Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models (2023)](https://arxiv.org/abs/2305.16223) ([Code](https://github.com/SHI-Labs/Prompt-Free-Diffusion))
- [Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising (2023)](https://arxiv.org/abs/2305.18264) ([Code](https://github.com/G-U-N/Gen-L-Video))
- [Collaborative Diffusion for Multi-Modal Face Generation and Editing (2023)](https://arxiv.org/abs/2304.10530) ([Code](https://github.com/ziqihuangg/Collaborative-Diffusion))
- [Learning Attention as Disentangler for Compositional Zero-shot Learning (2023)](https://arxiv.org/abs/2303.15111) ([Code](https://github.com/haoosz/ade-czsl))
- [GRES: Generalized Referring Expression Segmentation (2023)](https://arxiv.org/abs/2306.00968) ([Code](https://github.com/henghuiding/ReLA))
- [Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles (2023)](https://arxiv.org/abs/2306.00989) ([Code](https://github.com/facebookresearch/hiera))
- [LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day (2023)](https://arxiv.org/abs/2306.00890) ([Code](https://github.com/microsoft/LLaVA-Med))
- [Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models (2023)](https://arxiv.org/abs/2305.16322) ([Code](https://github.com/ShihaoZhaoZSH/Uni-ControlNet))
- [Text2Tex: Text-driven Texture Synthesis via Diffusion Models (2023)](https://daveredrum.github.io/Text2Tex/) ([Code](https://github.com/daveredrum/Text2Tex))
- [Apple releasing segmentation/pose for humans and animals](https://developer.apple.com/wwdc23/topics/ml-vision/) ([HN](https://news.ycombinator.com/item?id=36209014))
- [Real-time 6K Image Rescaling with Rate-distortion Optimization (2023)](https://arxiv.org/abs/2304.01064) ([Code](https://github.com/AbnerVictor/HyperThumbnail))
- [Awesome Talking Head Generation](https://github.com/harlanhong/awesome-talking-head-generation)
- [Tracking Everything Everywhere All at Once (2023)](https://arxiv.org/abs/2306.05422) ([Code](https://github.com/qianqianwang68/omnimotion))
- [Towards Smooth Video Composition (2023)](https://genforce.github.io/StyleSV/) ([Code](https://github.com/genforce/StyleSV))
- [FasterViT: Fast Vision Transformers with Hierarchical Attention](https://github.com/NVlabs/FasterViT)
- [Matting Anything (2023)](https://arxiv.org/abs/2306.05399) ([HN](https://github.com/SHI-Labs/Matting-Anything))
- [ViTMatte](https://github.com/hustvl/ViTMatte) - Boosting Image Matting with Pretrained Plain Vision Transformers.
- [Neural Kernel Surface Reconstruction (2023)](https://github.com/nv-tlabs/NKSR)
- [Inserting Anybody in Diffusion Models via Celeb Basis (2023)](https://arxiv.org/abs/2306.00926) ([Code](https://github.com/ygtxr1997/CelebBasis))
- [SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions (2023)](https://arxiv.org/abs/2306.05178) ([Code](https://github.com/KAIST-Geometric-AI-Group/SyncDiffusion))
- [Temporal Voyage: Code for "Neural Scene Chronology"](https://github.com/zju3dv/NeuSC)
- [DynIBaR: Neural Dynamic Image-Based Rendering (2023)](https://dynibar.github.io/) ([Code](https://github.com/google/dynibar))
- [RelTR: Relation Transformer for Scene Graph Generation (2022)](https://arxiv.org/abs/2201.11460v2) ([Code](https://github.com/yrcong/RelTR))
- [Progressively Optimized Local Radiance Fields for Robust View Synthesis (2023)](https://github.com/facebookresearch/localrf)
- [WebGLM: Towards An Efficient Web-enhanced Question Answering System with Human Preference (2023)](https://github.com/THUDM/WebGLM)
- [MIME: Human-Aware 3D Scene Generation (2023)](https://github.com/yhw-yhw/MIME)
- [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture (2023)](https://arxiv.org/abs/2301.08243) ([Code](https://github.com/facebookresearch/ijepa))
- [Language Segment-Anything](https://github.com/luca-medeiros/lang-segment-anything)
- [Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation (2023)](https://arxiv.org/abs/2303.09119) ([Code](https://github.com/Advocate99/DiffGesture))
- [Awesome Segment Anything](https://github.com/liliu-avril/Awesome-Segment-Anything)
- [Cones 2: Customizable Image Synthesis with Multiple Subjects (2023)](https://arxiv.org/abs/2305.19327) ([Code](https://github.com/damo-vilab/Cones-V2))
- [View Synthesis with Sculpted Neural Points (2022)](https://arxiv.org/abs/2205.05869) ([Code](https://github.com/princeton-vl/SNP))
- [NeMo: 3D Neural Motion Fields from Multiple Video Instances of the Same Action (2022)](https://arxiv.org/abs/2212.13660) ([Code](https://github.com/wangkua1/nemo-cvpr2023))
- [Zero-Shot Video Question Answering via Frozen Bidirectional Language Models (2022)](https://arxiv.org/abs/2206.08155) ([Code](https://github.com/antoyang/FrozenBiLM))
- [DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data (2023)](https://arxiv.org/abs/2306.09344) ([Code](https://github.com/ssundaram21/dreamsim))
- [Matte Anything: Interactive Natural Image Matting with Segment Anything Models (2023)](https://arxiv.org/abs/2306.04121) ([Code](https://github.com/hustvl/Matte-Anything))
- [Infinite Photorealistic Worlds using Procedural Generation (2023)](https://arxiv.org/abs/2306.09310) ([HN](https://news.ycombinator.com/item?id=36376071))
- [VideoComposer: Compositional Video Synthesiswith with Motion Controllability](https://github.com/damo-vilab/videocomposer)
- [Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification & Segmentation (2023)](https://github.com/dahyun-kang/cst)
- [Unpaired Image-to-Image Translation via Neural SchrÃ¶dinger Bridge (2023)](https://arxiv.org/abs/2305.15086) ([Code](https://github.com/cyclomon/UNSB))
- [Symmetry-Informed Geometric Representation for Molecules, Proteins, and Crystalline Materials (2023)](https://arxiv.org/abs/2306.09375) ([Code](https://github.com/chao1224/Geom3D))
- [PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360](https://github.com/SizheAn/PanoHead)
- [OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation (2023)](https://arxiv.org/abs/2301.07525) ([Code](https://github.com/omniobject3d/OmniObject3D))
- [Multi-scale Attention Guided Pose Transfer (2022)](https://arxiv.org/abs/2202.06777) ([Code](https://github.com/prasunroy/pose-transfer))
- [SUDS: Scalable Urban Dynamic Scenes](https://github.com/hturki/suds)
- [PVO: Panoptic Visual Odometry (2022)](https://arxiv.org/abs/2207.01610) ([Code](https://github.com/zju3dv/PVO))
- [Fast Segment Anything](https://github.com/CASIA-IVA-Lab/FastSAM)
- [FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction (2023)](https://arxiv.org/abs/2304.01480) ([Code](https://github.com/apple/ml-finerecon))
- [DISCO: Disentangled Control for Referring Human Dance Generation in Real World (2023)](https://disco-dance.github.io/) ([Code](https://github.com/Wangt-CN/DisCo))
- [StyleDrop: Text-to-Image Generation in Any Style (2023)](https://arxiv.org/abs/2306.00983) ([Code](https://github.com/zideliu/StyleDrop-PyTorch))
- [Segment Anything Meets Point Tracking (2023)](https://arxiv.org/abs/2307.01197) ([Code](https://github.com/SysCV/sam-pt))
- [Denoising Diffusion Models for Plug-and-Play Image Restoration (2023)](https://arxiv.org/abs/2305.08995) ([Code](https://github.com/yuanzhi-zhu/DiffPIR))
- [Final2x](https://github.com/Tohrusky/Final2x) - Enhance Your Images with Effortless Cross-Platform Super-Resolution at Any Scale.
- [nr3d_lib](https://github.com/PJLab-ADG/nr3d_lib) - Modules, operators and utilities for 3D neural rendering in single-object, multi-object, categorical and large-scale scenes.
